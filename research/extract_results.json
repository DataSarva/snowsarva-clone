{"extract_id":"extract_653df718751b47dfa263604272a5220c","results":[{"url":"https://docs.snowflake.com/en/user-guide/ml-functions/anomaly-detection","title":"Anomaly Detection (Snowflake ML Functions) | Snowflake Documentation","publish_date":"2020-01-01","excerpts":["[DOCUMENTATION](https://docs.snowflake.com)\n/\n[Get started](/en/user-guide-getting-started)\n[Guides](/en/guides)\n[Developer](/en/developer)\n[Reference](/en/reference)\n[Release notes](/en/release-notes/overview)\n[Tutorials](/en/tutorials)\n[Status](https://status.snowflake.com)\n[Guides](/en/guides) [Snowflake AI & ML](/en/guides-overview-ai-features) [ML Functions](/en/guides-overview-ml-functions) Anomaly Detection\nSection Title: Anomaly Detection (Snowflake ML Functions) [¶]( \"Link to this heading\") > Overview [¶]( \"Link to this heading\")\nContent:\nAnomaly detection is the process of identifying outliers in data. The anomaly detection function lets you train a model\nto detect outliers in your time-series data. Outliers, which are data points that deviate from the expected range, can\nhave an outsized impact on statistics and models derived from your data. Spotting and removing outliers can therefore\nhelp improve the quality of your results.\nNote\nAnomaly Detection is part of Snowflake’s suite of business analysis tools powered by machine learning.\nDetecting outliers can also be useful in pinpointing the origin of problems or deviations in processes when there is no\nobvious cause. For example:\nDetermining when a problem started to occur with your logging pipeline.\nIdentifying the days when your Snowflake compute costs are higher than expected.\nAnomaly detection works with either single-series or multi-series data. Multi-series data represents multiple\nindependent threads of events. For example, if you have sales data for multiple stores, each store’s sales can be\nchecked separately by a single model based on the store identifier.\nThe data must include:\nA timestamp column.\nA target column representing some quantity of interest at each timestamp.\nNote\nSection Title: Anomaly Detection (Snowflake ML Functions) [¶]( \"Link to this heading\") > Overview [¶]( \"Link to this heading\")\nContent:\nIdeally, the training data for an Anomaly Detection model has time steps at equally spaced intervals (for example,\ndaily). However, model training can handle real-world data that has missing, duplicate, or misaligned time steps.\nFor more information, see [Dealing with real-world data in Time-Series Forecasting](preprocessing) .\nTo detect outliers in time-series data, use the Snowflake built-in class [ANOMALY_DETECTION (SNOWFLAKE.ML)](../../sql-reference/classes/anomaly_detection) ,\nand follow these steps:\n[Create an anomaly detection object](../../sql-reference/classes/anomaly-detection/commands/create-anomaly-detection.html) ,\npassing in a reference to the training data.This object fits a model to the training data that you provide. The model is a schema-level object.\nUsing this anomaly detection model object, call the [<model_name>!DETECT_ANOMALIES](../../sql-reference/classes/anomaly-detection/methods/detect_anomalies) method to\ndetect anomalies, passing in a reference to the data to analyze.The method uses the model to identify outliers in the data.\nAnomaly detection is closely related to [Forecasting](forecasting) . An anomaly detection model\nproduces a forecast for the same time period as the data you’re checking for anomalies, then compares the actual data to\nthe forecast to identify outliers.\nImportant\nSection Title: Anomaly Detection (Snowflake ML Functions) [¶]( \"Link to this heading\") > Overview [¶]( \"Link to this heading\")\nContent:\n**Legal notice.** This Snowflake ML function is powered by machine learning technology, which you, not Snowflake, determine when and how to use. Machine\nlearning technology and results provided may be inaccurate, inappropriate, or biased.\nSnowflake provides you with the machine learning models that you can use within your own workflows. Decisions based on machine\nlearning outputs, including those built into automatic pipelines, should have human oversight and review processes\nto ensure model-generated content is accurate.\nSnowflake provides algorithms (without any pretraining) and you’re responsible for the data that you provide the algorithm (for example, for training and inference) and the decisions you make using the resulting model’s output.\nQueries for this feature or function are treated as any\nother SQL query and may be considered [metadata](../../sql-reference/metadata) .\n**Metadata.** When you use Snowflake ML functions, Snowflake logs generic error messages returned by an ML\nfunction. These error logs help us troubleshoot issues that arise and improve these functions to serve you better.\nFor further information, see [Snowflake AI Trust and Safety FAQ](https://www.snowflake.com/en/legal/snowflake-ai-trust-and-safety/) .\n ... \nSection Title: Anomaly Detection (Snowflake ML Functions) [¶]( \"Link to this heading\") > About the Algorithm for Anomaly Detection [¶]( \"Link to this heading\")\nContent:\nFrom time to time, Snowflake may refine the anomaly detection algorithm. Such improvements roll out\nthrough the regular Snowflake release process. You cannot revert to a previous version of the feature, but models you\ncreated with a previous version continue to use that version for anomaly detection.\nSection Title: Anomaly Detection (Snowflake ML Functions) [¶]( \"Link to this heading\") > ... > Limitations [¶]( \"Link to this heading\")\nContent:\nYou cannot choose or adjust the anomaly detection algorithm. In particular, the algorithm does not provide parameters\nto override trend, seasonality, or seasonal amplitudes; these are inferred from the data. The minimum number of rows for the main anomaly detection algorithm is 12 per time series. For time series with\nbetween 2 and 11 observations, anomaly detection produces a “naive” result in which all predicted values are equal to\nthe last observed target value. For the labeled anomaly detection case, the number of observations used is the number\nof rows where the label column is false. The minimum acceptable granularity of data is one second. (Timestamps must not be less than one second apart.) The minimum granularity of seasonal components is one minute. (The function cannot detect cyclic patterns at smaller\ntime deltas.) The “season length” of autoregressive features is tied to the input frequency (24 for hourly data, 7 for daily data,\nand so on). Anomaly detection models, once trained, are immutable. You cannot update existing models with new data; you must train\nan entirely new model. Models do not support versioning. Generally, you should retrain models on a regular cadence,\nsuch as once a day, once a week, or once a month, depending on how frequently you receive new data, to help the model\nkeep up with changing trends.\n ... \nSection Title: Anomaly Detection (Snowflake ML Functions) [¶]( \"Link to this heading\") > ... > Training an Anomaly Detection Model [¶]( \"Link to this heading\")\nContent:\nCreate a view or design a query that returns the data for training the model for anomaly detection.For this example, execute the [CREATE VIEW](../../sql-reference/sql/create-view) command to create a view named `view_with_training_data` that contains the date and sales information:Copy\nCreate an anomaly detection object, and train its model on the data in that view.For this example, execute the [CREATE SNOWFLAKE.ML.ANOMALY_DETECTION](../../sql-reference/classes/anomaly-detection/commands/create-anomaly-detection.html) command to create an anomaly detection object named `basic_model` . Pass in the following arguments:CopyThis example passes in a reference to a view as the INPUT_DATA argument. The example [uses the TABLE keyword to create the reference](../../developer-guide/stored-procedure/stored-procedures-calling-references.html) . As an alternative, you can call [SYSTEM$REFERENCE](../../sql-reference/functions/system_reference) to create the reference.The purpose of the label column is to tell the model which rows are known anomalies. Because this example uses\nunsupervised training, you do not need to use the label column.\n ... \nSection Title: ... > Using an Anomaly Detection Model to Detect Anomalies [¶]( \"Link to this heading\")\nContent:\nCreating the anomaly detection object trains the model and stores it in the schema. To use the anomaly detection object\nto detect anomalies, call the [<model_name>!DETECT_ANOMALIES](../../sql-reference/classes/anomaly-detection/methods/detect_anomalies.html) method of the object. For example:\nCreate a view or design a query that returns the data for analysis.For this example, execute the [CREATE VIEW](../../sql-reference/sql/create-view) command to create a view named `view_with_data_to_analyze` that contains the date and sales information:Copy\nUsing the object for the anomaly detection model (in this example, `basic_model` , which [you created earlier]() ),\ncall the [<model_name>!DETECT_ANOMALIES](../../sql-reference/classes/anomaly-detection/methods/detect_anomalies.html) method:CopyThe method returns a table that includes rows for the data currently in the view `view_with_data_to_analyze` along with the\nprediction of the detector. For a description of the columns in this table, see [Returns](../../sql-reference/classes/anomaly-detection/methods/detect_anomalies.html) .\n**Output**\nThe results have been rounded for readability.\n ... \nSection Title: ... > Visualizing Anomalies and Interpreting the Results [¶]( \"Link to this heading\")\nContent:\nUse [Snowsight](../ui-snowsight-gs.html) to review and visualize the results of anomaly detection. In Snowsight, when\nyou call the [<model_name>!DETECT_ANOMALIES](../../sql-reference/classes/anomaly-detection/methods/detect_anomalies.html) method, the results are displayed in a table under the worksheet.\nTo visualize the results, you can use the chart feature in Snowsight.\nAfter calling the [<model_name>!DETECT_ANOMALIES](../../sql-reference/classes/anomaly-detection/methods/detect_anomalies.html) method, select Charts above the results table.\nIn the Data section on the right side of the chart:\nSelect the Y column, and under Aggregation , select None .\nSelect the TS column, and under Bucketing , select None .\nAdd the LOWER_BOUND and UPPER_BOUND columns, and under Aggregation , select None .\nTo display the initial visualization, select Chart .\nSelect Add Column on the right side of the page, and select the columns you want to visualize:Results:\nLOWER_BOUND\nUPPER_BOUND\nIS_ANOMALY\nHover over the high spike to see that Y lies outside of the upper bound and is tagged with a 1 in the IS_ANOMALY field.\nTip\nTo better understand your results, try [Top Insights](top-insights) .\n ... \nSection Title: Anomaly Detection (Snowflake ML Functions) [¶]( \"Link to this heading\") > ... > Monitoring with a Snowflake Alert [¶]( \"Link to this heading\")\nContent:\n```\nCREATE OR REPLACE PROCEDURE extract_anomalies () \n  RETURNS TABLE () \n  LANGUAGE SQL \n  AS \n  $$ \n    BEGIN \n      let res RESULTSET := ( SELECT * FROM TABLE ( \n        model_trained_with_labeled_data ! DETECT_ANOMALIES ( \n          INPUT_DATA => TABLE ( view_with_data_to_analyze ), \n          TIMESTAMP_COLNAME => 'date' , \n          TARGET_COLNAME => 'sales' , \n          CONFIG_OBJECT => { 'prediction_interval' :0 . 99 } \n        )) \n        WHERE is_anomaly = TRUE \n      ); \n      RETURN TABLE ( res ); \n    END ; \n  $$ \n  ; \n\n CREATE OR REPLACE ALERT sample_sales_alert \n WAREHOUSE = < your_warehouse_name > \n SCHEDULE = '1 MINUTE' \n IF ( EXISTS ( CALL extract_anomalies ())) \n THEN \n CALL SYSTEM$SEND_EMAIL ( \n  'sales_email_alert' , \n  'your_email@snowflake.com' , \n  'Anomalous Sales Data Detected in data stream' , \n  CONCAT ( \n    'Anomalous Sales Data Detected in data stream \\n' , \n    'Value outside of prediction interval detected in the most recent run at ' , \n    current_timestamp ( 1 ) \n  ));\n```\nCopy\nTo start or resume the alert, execute the [ALTER ALERT … RESUME](../../sql-reference/sql/alter-alert) command:\n```\nALTER ALERT sample_sales_alert RESUME ;\n```\nCopy\nTo pause the alert, execute the [ALTER ALERT … SUSPEND](../../sql-reference/sql/alter-alert) command:\n```\nALTER ALERT sample_sales_alert SUSPEND ;\n```\nCopy\nSection Title: Anomaly Detection (Snowflake ML Functions) [¶]( \"Link to this heading\") > Understanding Feature Importance [¶]( \"Link to this heading\")\nContent:\nAn anomaly detection model can explain the relative importance of all features used in your model, including any exogenous\nvariables that you choose, automatically generated time features (such as day of week or week of year), and\ntransformations of your target variable (such as rolling averages and auto-regressive lags). This information is useful\nin understanding what factors are really influencing your data.\nThe [<model_name>!EXPLAIN_FEATURE_IMPORTANCE](../../sql-reference/classes/anomaly-detection/methods/explain_feature_importance.html) method counts the number of times the\nmodel’s trees used each feature to make a decision. These feature importance scores are then normalized to values\nbetween 0 and 1 so that their sum is 1. The resulting scores represent an approximate ranking of the features in your\ntrained model.\nFeatures that are close in score have similar importance. For extremely simple series (for example, when the target\ncolumn has a constant value), all feature importance scores may be zero.\n ... \nSection Title: Anomaly Detection (Snowflake ML Functions) [¶]( \"Link to this heading\") > ... > Limitations [¶]( \"Link to this heading\")\nContent:\nYou cannot choose the technique used to calculate feature importance.\nFeature importance scores can be helpful for gaining intuition about which features are important to your model’s\naccuracy, but the actual values should be considered estimates.\n ... \nSection Title: Anomaly Detection (Snowflake ML Functions) [¶]( \"Link to this heading\") > Cost Considerations [¶]( \"Link to this heading\")\nContent:\nFor details on costs for using ML functions, see [Cost Considerations](../../guides-overview-ml-functions.html) in the ML functions overview.\nWas this page helpful?\nYes No\n[Visit Snowflake](https://www.snowflake.com)\n[Join the conversation](https://community.snowflake.com/s/)\n[Develop with Snowflake](https://developers.snowflake.com)\n[Share your feedback](/feedback)\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n[Get your own certification](https://learn.snowflake.com)\n[Privacy Notice](https://www.snowflake.com/privacy-policy/) [Site Terms](https://www.snowflake.com/legal/snowflake-site-terms/) Cookies Settings © 2026 Snowflake, Inc. All Rights Reserved.\nLanguage: **English**\n[English](/en/user-guide/ml-functions/anomaly-detection)\n[Français](/fr/user-guide/ml-functions/anomaly-detection)\n[Deutsch](/de/user-guide/ml-functions/anomaly-detection)\n[日本語](/ja/user-guide/ml-functions/anomaly-detection)\n[한국어](/ko/user-guide/ml-functions/anomaly-detection)\n[Português](/pt/user-guide/ml-functions/anomaly-detection)"],"full_content":null},{"url":"https://docs.snowflake.com/en/user-guide/cost-anomalies","title":"Introduction to cost anomalies | Snowflake Documentation","publish_date":null,"excerpts":["[DOCUMENTATION](https://docs.snowflake.com)\n/\n[Get started](/en/user-guide-getting-started)\n[Guides](/en/guides)\n[Developer](/en/developer)\n[Reference](/en/reference)\n[Release notes](/en/release-notes/overview)\n[Tutorials](/en/tutorials)\n[Status](https://status.snowflake.com)\n[Guides](/en/guides) [Cost & Billing](/en/guides-overview-cost) Visibility Cost anomalies\nSection Title: Introduction to cost anomalies [¶]( \"Link to this heading\")\nContent:\nA cost anomaly occurs when daily consumption is above or below the expected range of consumption for the day. Snowflake uses an algorithm to\nautomatically detect these cost anomalies based on prior levels of consumption, which simplifies the process of identifying spikes or dips\nin costs so you can find ways to optimize your spend. Snowflake also provides tools to investigate these cost anomalies to identify root\ncauses.\nNote\nThe algorithm that detects cost anomalies requires at least 30 days of consumption before it can identify anomalies. If your consumption\nin the last seven days was less than 10 credits, Snowflake does not identify changes as an anomaly.\nSection Title: Introduction to cost anomalies [¶]( \"Link to this heading\") > Account-level vs. organization-level cost anomalies [¶]( \"Link to this heading\")\nContent:\nAn account-level cost anomaly occurs when the consumption in a single account falls outside the expected range of consumption for that\naccount.\nAn organization-level cost anomaly occurs when the consumption in the entire organization falls outside the expected range of consumption\nfor the organization. It is based on the aggregate consumption of all accounts in the organization. For example, if there is a significant\nconsumption spike in one account, but a dip in another, the two might offset each other such that it is not flagged as an organization-level\nanomaly. To help investigate organization-level anomalies, Snowflake provides tools to identify which accounts had the biggest increase or\ndecrease in consumption on a specific day.\nTo identify and investigate organization-level cost anomalies, you need to be signed in to the [organization account](organization-accounts) or an [ORGADMIN-enabled account](organization-administrators.html) .\nSection Title: Introduction to cost anomalies [¶]( \"Link to this heading\") > Get started [¶]( \"Link to this heading\")\nContent:\nTo identify and investigate cost anomalies using a user interface:\nSign in to [Snowsight](ui-snowsight-gs.html) as a user with the [required privileges](cost-anomalies-access-control) .\nIn the navigation menu, select Admin » Cost management , and then select Anomalies .\n ... \nSection Title: Introduction to cost anomalies [¶]( \"Link to this heading\") > Run queries against cost anomaly views [¶]( \"Link to this heading\")\nContent:\nYou can run queries against views in the ACCOUNT_USAGE and ORGANIZATION_USAGE schemas to return historical data about account-level cost\nanomalies. Each row in the view includes the consumption on a specific day, and whether that consumption was a cost anomaly.\nCost anomalies for current account\nExecute queries against the [ANOMALIES_DAILY view](../sql-reference/account-usage/anomalies_daily) in the [ACCOUNT_USAGE schema](../sql-reference/account-usage) to gain insights into whether cost anomalies occurred in the current account.\nThis view uses credits as the unit of measure for consumption.\nCost anomalies for all accounts in an organization\nExecute queries against the [ANOMALIES_IN_CURRENCY_DAILY view](../sql-reference/organization-usage/anomalies_in_currency_daily) in the [ORGANIZATION_USAGE schema](../sql-reference/organization-usage) to gain insights into whether cost anomalies occurred in accounts in\nthe organization. Note that not all accounts have access to the ORGANIZATION_USAGE schema.\nUse this view to see currency as the unit of measure rather than credits.\nSection Title: Introduction to cost anomalies [¶]( \"Link to this heading\") > Learn more [¶]( \"Link to this heading\")\nContent:\nFor information about how to work with cost anomalies, see the following:\n[Use Snowsight to work with cost anomalies](cost-anomalies-ui)\n[Programmatically work with cost anomalies](cost-anomalies-class)\nWas this page helpful?\nYes No\n[Visit Snowflake](https://www.snowflake.com)\n[Join the conversation](https://community.snowflake.com/s/)\n[Develop with Snowflake](https://developers.snowflake.com)\n[Share your feedback](/feedback)\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n[Get your own certification](https://learn.snowflake.com)\n[Privacy Notice](https://www.snowflake.com/privacy-policy/) [Site Terms](https://www.snowflake.com/legal/snowflake-site-terms/) Cookies Settings © 2026 Snowflake, Inc. All Rights Reserved.\nOn this page\n[Account-level vs. organization-level cost anomalies]()\n[Get started]()\n[Unit of measure for cost data]()\n[Run queries against cost anomaly views]()\n[Learn more]()\nRelated content\n[Managing cost in Snowflake](/user-guide/cost-management-overview)\nLanguage: **English**\n[English](/en/user-guide/cost-anomalies)\n[Français](/fr/user-guide/cost-anomalies)\n[Deutsch](/de/user-guide/cost-anomalies)\n[日本語](/ja/user-guide/cost-anomalies)\n[한국어](/ko/user-guide/cost-anomalies)\n[Português](/pt/user-guide/cost-anomalies)"],"full_content":null},{"url":"https://www.snowflake.com/en/engineering-blog/anomaly-insights-spending-patterns/","title":"Detect Spending Patterns with Anomaly Insights","publish_date":"2026-02-06","excerpts":["[Skip to content]()\n[](/en/) [](/en/)\nProduct\nSolutions\nWhy Snowflake\nResources\nDevelopers\n[Pricing](/en/pricing-options/)\nFeatured Capabilities\nFeatured Open Source Technologies\nINDUSTRIES\nDEPARTMENTS\nEnablement Solutions\nPARTNER SOLUTIONS\nConnect\nLearn\nBuild\nLearn\nConnect\nCore Platform\nFeb 5, 2026 | 4 min read\nSection Title: Spot Unusual Spending Patterns With Anomaly Insights Without Being an Account Admin\nContent:\nIn a dynamic organization, it’s critical to be aware of overall consumption patterns for your team or business unit. With many simultaneous users, it can be challenging to rein in unanticipated usage costs. To simplify this, Snowflake has developed a powerful deep-dive analysis tool to help you understand and investigate consumption anomalies. This tool provides cost alerting and visibility, enabling you to take action when unforeseen consumption occurs to better manage your Snowflake costs. This tool, which was made available only to account admins in April 2025, is *now open to all Snowflake users through three new access roles that reflect common use cases. * ## Anomaly Insights We released [Anomaly Insights](https://docs.snowflake.com/en/user-guide/cost-anomalies) to help businesses better understand their account and organization spending by flagging anomalous spending days (both high and low). With this information, users can deep-dive into their consumption patterns to identify problematic or unexpected spending patterns. ### How are anomalies calculated? The anomaly algorithm runs daily, analyzing the last 28 days of billing data. It decomposes the time-series data into trend (long‑term movement), and weekly seasonality. For each day, it forecasts the expected usage and flags an anomaly if the actual usage is too far from the expectation.\nSection Title: Spot Unusual Spending Patterns With Anomaly Insights Without Being an Account Admin\nContent:\nSnowflake calculates anomalies separately in both credits and currency; reserving currency access for admin users only. ### Feature review: Investigate a spending anomaly The power of Anomaly Insights lies in its ability to explore broadly across the organization while giving you the ability to deep-dive into consumption when necessary. Let’s say you work for “ *GeoLab* ” and you are very sensitive to unexpected consumption costs. As such, you sign up for Anomaly Insights email alerts to notify you whenever an anomaly occurs. One day you receive an email that your account has experienced a spending anomaly. Here’s what you do: 1. Log in to your GeoLab account, or simply click on the link in the email to take you directly to the Anomalies landing page. 2. Select your desired time frame and see the historical spending for your account. You notice the spending anomaly that was flagged in the email as well as a few past anomalies. 3. To dive deeper, you then click on a specific anomaly, which pops out a deep-dive side panel. 4. From here, you can see hour-by-hour spend, top warehouses by consumption and top queries within a selected warehouse. With this information, you now have a solid understanding of what your consumption anomaly was and what might have caused it. You can use this information to investigate the anomaly further or view other accounts within your organization.\nSection Title: Spot Unusual Spending Patterns With Anomaly Insights Without Being an Account Admin\nContent:\nFigure 1: The anomalies landing page for the example company “GeoLab” shows historical daily consumption over the past three months. During that time, this company experienced four spending anomalies.\nFigure 2: The deep-dive side panel for “GeoLab” for the anomaly that occurred on Oct. 16, 2025. There is a clear consumption spike that occurred at 9 p.m. and might be related to warehouse TOSHEN_MED, which incurred a cost of 273.78 credits on that date.\nSection Title: Spot Unusual Spending Patterns With Anomaly Insights Without Being an Account Admin > ... > Modified email list privileges\nContent:\nVerified users ( [how to verify your email](https://docs.snowflake.com/en/user-guide/cost-anomalies-ui) ) may also sign-up for email notifications to be alerted when an anomaly is detected. To sign-up (or sign-up others), use an `APP_USAGE_ADMIN` role in place of an `APP_USAGE_VIEWER` role. This will enable the Notifications button on the Anomalies landing page. The `APP_USAGE_ADMIN` role has all the same privileges as `APP_USAGE_VIEWER` except with the additional privilege of being able to modify email lists.\nSection Title: ... > Documentation links Use the following links to understand more about Anomaly Insights: * [Introduction To Anomaly Insights](https://docs.snow...\nContent:\n[Anomalies API](https://docs.snowflake.com/en/sql-reference/classes/anomaly_insights)\n[Role Based Access Control](https://docs.snowflake.com/en/user-guide/cost-anomalies-access-control)\nSection Title: Spot Unusual Spending Patterns With Anomaly Insights Without Being an Account Admin > ... > Author\nContent:\n[](/en/blog/authors/spencer-moritz/)\n[Spencer Moritz](/en/blog/authors/spencer-moritz/)\nSection Title: Spot Unusual Spending Patterns With Anomaly Insights Without Being an Account Admin > ... > Author > Share Article\nContent:\n[](https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fwww.snowflake.com%2Fcontent%2Fsnowflake-site%2Fglobal%2Fen%2Fengineering-blog%2Fanomaly-insights-spending-patterns&title=Spot+Unusual+Spending+Patterns+With+Anomaly+Insights+Without+Being+an+Account+Admin+)\n[](https://x.com/intent/post?url=https%3A%2F%2Fwww.snowflake.com%2Fcontent%2Fsnowflake-site%2Fglobal%2Fen%2Fengineering-blog%2Fanomaly-insights-spending-patterns&text=Spot+Unusual+Spending+Patterns+With+Anomaly+Insights+Without+Being+an+Account+Admin+)\n[](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.snowflake.com%2Fcontent%2Fsnowflake-site%2Fglobal%2Fen%2Fengineering-blog%2Fanomaly-insights-spending-patterns)\n[](mailto:?subject=Spot+Unusual+Spending+Patterns+With+Anomaly+Insights+Without+Being+an+Account+Admin+&body=https%3A%2F%2Fwww.snowflake.com%2Fcontent%2Fsnowflake-site%2Fglobal%2Fen%2Fengineering-blog%2Fanomaly-insights-spending-patterns)\nSection Title: Spot Unusual Spending Patterns With Anomaly Insights Without Being an Account Admin > ... > Author > Just For You\nContent:\n[](/en/engineering-blog/Interactive-analytics-tables-warehouses/)\nCore Platform\n[##### Introducing Interactive Analytics, Powered by Interactive Tables and Warehouses](/en/engineering-blog/Interactive-analytics-tables-warehouses/)\n[Brian Hess](/en/blog/authors/brian-hess/)\nDec 3, 2025 | 6 min read\n[](/en/engineering-blog/tag-based-budgets-cost-attribution/)\nCore Platform\n[##### Align Your Budgets with Your Business: A New Approach to Cost Attribution](/en/engineering-blog/tag-based-budgets-cost-attribution/)\n[Dinesh Haridas](/en/blog/authors/-dinesh-haridas/) | [Siyoung Oh](/en/blog/authors/siyoung-oh/)\nAug 25, 2025 | 4 min read\nSubscribe to our blog newsletter\nGet the best, coolest and latest delivered to your inbox each week\nBy submitting this form, I understand Snowflake will process my personal information in accordance with their Privacy Notice.\nSection Title: Spot Unusual Spending Patterns With Anomaly Insights Without Being an Account Admin > Where Data Does More\nContent:\n30-day free trial\nNo credit card required\nCancel anytime\n[start for free](https://signup.snowflake.com/)\n[watch a demo](/en/webinars/demo/)\n**Subscribe to our monthly newsletter** Stay up to date on Snowflake’s latest products, expert insights and resources—right in your inbox!\n[Industries](/en/solutions/industries/) * [Advertising, Media & Entertainment](https://www.snowflake.com/en/solutions/industries/advertising-media-entertainment/)\n[Financial Services](https://www.snowflake.com/en/solutions/industries/financial-services/)\n[Healthcare & Life Sciences](https://www.snowflake.com/en/solutions/industries/healthcare-and-life-sciences/)\n[Manufacturing](https://www.snowflake.com/en/solutions/industries/manufacturing/)\n[Public Sector](https://www.snowflake.com/en/solutions/industries/public-sector/)\n[Retail & Consumer Goods](https://www.snowflake.com/en/solutions/industries/retail-consumer-goods/)\n[Technology](https://www.snowflake.com/en/solutions/industries/technology/)\nLearn * [Resource Library](https://snowflake.com/en/resources/)\nSection Title: Spot Unusual Spending Patterns With Anomaly Insights Without Being an Account Admin > Where Data Does More\nContent:\n[Live Demos](/en/webinars/demo/)\n[Fundamentals](https://www.snowflake.com/en/fundamentals/)\n[Training](https://www.snowflake.com/en/resources/learn/training/)\n[Certifications](https://www.snowflake.com/en/resources/learn/certifications/)\n[Snowflake University](https://learn.snowflake.com/en/)\n[Developer Guides](https://www.snowflake.com/en/developers/guides)\n[Documentation](https://docs.snowflake.com/)\n[](/en/)\n© 2026 Snowflake Inc. All Rights Reserved\n[Privacy Policy](https://www.snowflake.com/en/legal/privacy/privacy-policy/)\n[Site Terms](https://snowflake.com/en/legal/snowflake-site-terms/)\n[Communication Preferences](https://info.snowflake.com/2024-Preference-center.html)\nCookie Settings\n[Do Not Share My Personal Information](https://www.snowflake.com/en/legal/privacy/privacy-policy/)\n[Legal](https://www.snowflake.com/en/legal/)\n[](https://x.com/Snowflake \"X (Twitter)\")\n[](https://www.linkedin.com/company/3653845 \"LinkedIn\")\n[](https://www.facebook.com/snowflakedb/ \"Facebook\")\n[](https://www.youtube.com/user/snowflakecomputing \"YouTube\")"],"full_content":null}],"errors":[],"warnings":null,"usage":[{"name":"sku_extract_excerpts","count":3}]}
