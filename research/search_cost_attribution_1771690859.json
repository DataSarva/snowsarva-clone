{
  "search_id": "search_6f4fd32d014e4fca80688fb52bbb7e1e",
  "results": [
    {
      "url": "https://docs.snowflake.com/en/user-guide/cost-attributing",
      "title": "Attributing cost | Snowflake Documentation",
      "excerpts": [
        "[DOCUMENTATION](https://docs.snowflake.com)\n/\nGet started\nGuides\nDeveloper\nReference\nRelease notes\nTutorials\n[Status](https://status.snowflake.com)\nOverview\nSnowflake Horizon Catalog\nApplications and tools for connecting to Snowflake\nVirtual warehouses\nDatabases, Tables, & Views\nData types\nData Integration\nSnowflake Openflow\nApache Iceberg\u2122\nApache Iceberg\u2122 Tables\nSnowflake Open Catalog\nData engineering\nData loading\nDynamic Tables\nStreams and Tasks\ndbt Projects on Snowflake\nData Unloading\nStorage Lifecycle Policies\nMigrations\nQueries\nListings\nCollaboration\nSnowflake AI & ML\nSnowflake Postgres\nAlerts & Notifications\nSecurity\nData Governance\nPrivacy\nOrganizations & Accounts\nBusiness continuity & data recovery\nPerformance optimization\nCost & Billing\nGuides Cost & Billing Visibility Attributing cost\nSection Title: Attributing cost \u00b6\nContent:\nAn organization can apportion the cost of using Snowflake to logical units within the organization (for example, to different\ndepartments, environments, or projects). This chargeback or showback model is useful for accounting purposes and pinpoints\nareas of the organization that could benefit from controls and optimizations that can reduce costs.\nTo attribute costs to different groups like departments or projects, use the following recommended approach:\nUse object tags to associate resources and users with departments or projects.\nUse query tags to associate individual queries with departments or projects when the queries are\nmade by the same application on behalf of users belonging to multiple departments.\n ... \nSection Title: Attributing cost \u00b6 > Types of cost attribution scenarios \u00b6\nContent:\nIn this case, each query executed by the application is assigned a query tag that identifies\nthe team or cost center of the user on whose behalf the query is being made.\n ... \nSection Title: Attributing cost \u00b6 > Viewing cost by tag in SQL \u00b6\nContent:\nYou can attribute costs within an account or across accounts in an organization:\nSection Title: Attributing cost \u00b6 > Viewing cost by tag in SQL \u00b6\nContent:\n**Attributing costs within an account**You can attribute costs within an account by querying the following views in the ACCOUNT_USAGE schema:\nTAG_REFERENCES view : Identifies objects (for example, warehouses and users) that have tags. WAREHOUSE_METERING_HISTORY view : Provides credit usage for warehouses. QUERY_ATTRIBUTION_HISTORY view : Provides the compute costs for queries. The cost per query is\nthe warehouse credit usage for executing the query.For more information on using this view, see About the QUERY_ATTRIBUTION_HISTORY view . **Attributing costs across accounts in an organization**Within an organization, you can also attribute costs for resources that are used **exclusively by a single department** by\nquerying views in the ORGANIZATION_USAGE schema from the organization account .Note\nIn the ORGANIZATION_USAGE schema, the TAG_REFERENCES view is only available in the organization account.\nSection Title: Attributing cost \u00b6 > Viewing cost by tag in SQL \u00b6\nContent:\nThe QUERY_ATTRIBUTION_HISTORY view is only available in the ACCOUNT_USAGE schema for an account. There is no\norganization-wide equivalent of the view.\nSection Title: Attributing cost \u00b6 > Viewing cost by tag in SQL \u00b6\nContent:\nThe next sections explain how to attribute costs for some of the common cost-attribution scenarios :\nResources not shared by departments\nResources shared by users from different departments\nResources used by applications that need to attribute costs to different departments\nSection Title: Attributing cost \u00b6 > Viewing cost by tag in SQL \u00b6 > Resources not shared by departments \u00b6\nContent:\nSuppose that you want to attribute costs by department and that each department uses a set of dedicated warehouses.\nIf you tag warehouses with a `cost_center` tag to identify the department that owns the warehouse, you can join the\nACCOUNT_USAGE TAG_REFERENCES view with the WAREHOUSE_METERING_HISTORY view on the `object_id` and `warehouse_id` columns to get usage\ninformation by warehouse, and you can use the `tag_value` column to identify the departments that own those warehouses.\nThe following SQL statement performs this join:\nSection Title: Attributing cost \u00b6 > Viewing cost by tag in SQL \u00b6 > Resources not shared by departments \u00b6\nContent:\n```\nSELECT \n    TAG_REFERENCES . tag_name , \n    COALESCE ( TAG_REFERENCES . tag_value , 'untagged' ) AS tag_value , \n    SUM ( WAREHOUSE_METERING_HISTORY . credits_used_compute ) AS total_credits \n  FROM \n    SNOWFLAKE . ACCOUNT_USAGE . WAREHOUSE_METERING_HISTORY \n      LEFT JOIN SNOWFLAKE . ACCOUNT_USAGE . TAG_REFERENCES \n        ON WAREHOUSE_METERING_HISTORY . warehouse_id = TAG_REFERENCES . object_id \n          AND TAG_REFERENCES . domain = 'WAREHOUSE' \n  WHERE \n    WAREHOUSE_METERING_HISTORY . start_time >= DATE_TRUNC ( 'MONTH' , DATEADD ( MONTH , - 1 , CURRENT_DATE )) \n      AND WAREHOUSE_METERING_HISTORY . start_time < DATE_TRUNC ( 'MONTH' ,  CURRENT_DATE ) \n  GROUP BY TAG_REFERENCES . tag_name , COALESCE ( TAG_REFERENCES . tag_value , 'untagged' ) \n  ORDER BY total_credits DESC ;\n```\nCopy\nSection Title: Attributing cost \u00b6 > Viewing cost by tag in SQL \u00b6 > Resources not shared by departments \u00b6\nContent:\n```\n+-------------+-------------+-----------------+ \n | TAG_NAME    | TAG_VALUE   |   TOTAL_CREDITS | \n |-------------+-------------+-----------------| \n | NULL        | untagged    |    20.360277159 | \n | COST_CENTER | Sales       |    17.173333333 | \n | COST_CENTER | Finance     |      8.14444444 | \n +-------------+-------------+-----------------+\n```\nYou can run a similar query to perform the same attribution for all the accounts in your organization using views in the\nORGANIZATION_USAGE schema from the organization account . The rest of the query\ndoes not change.\n ... \nSection Title: Attributing cost \u00b6 > ... > Resources shared by users from different departments \u00b6\nContent:\nSuppose that users in different departments share the same warehouses and you want to break down the credits used by each\ndepartment. You can tag the users with a `cost_center` tag to identify the department that they belong to, and you can join\nthe TAG_REFERENCES view with the QUERY_ATTRIBUTION_HISTORY view .\nNote\nYou can only get this data for a single account at a time. You cannot execute a query that retrieves this data across\naccounts in an organization.\nThe next sections provide examples of SQL statements for attributing costs for shared resources.\nCalculating the cost of user queries for the last month\nCalculating the cost of user queries by department without idle time\nCalculating the cost of queries by users without idle time\nCalculating the cost of queries by users without tags\n ... \nSection Title: ... > Resources used by applications that need to attribute costs to different departments \u00b6\nContent:\nThe examples in this section calculate the costs for one or more applications that are powered by Snowflake.\nThe examples assume that these applications set query tags that identify the application for all queries executed. To set the\nquery tag for queries in a session, execute the ALTER SESSION command. For example:\n```\nALTER SESSION SET QUERY_TAG = 'COST_CENTER=finance' ;\n```\nCopy\nThis associates the `COST_CENTER=finance` tag with all subsequent queries executed during the session.\nYou can then use the query tag to trace back the cost incurred by these queries to the appropriate departments.\nThe next sections provide examples of using this approach.\nCalculating the cost of queries by department\nCalculating the cost of queries (excluding idle time) by query tag\nCalculating the cost of queries (including idle time) by query tag\n ... \nSection Title: Attributing cost \u00b6 > Viewing cost by tag in Snowsight \u00b6\nContent:\nYou can attribute costs by reporting on the use of resources that have the `cost_center` tag. You can access this data in Snowsight .\nSwitch to a role that has access to the ACCOUNT_USAGE schema .\nIn the navigation menu, select Admin \u00bb Cost management .\nSelect Consumption .\nFrom the Tags drop-down, select the `cost_center` tag.\nTo focus on a specific cost center, select a value from the list of the tag\u2019s values.\nSelect Apply .\nFor more details about filtering in Snowsight, see Filter by tag .\nSection Title: Attributing cost \u00b6 > About the QUERY_ATTRIBUTION_HISTORY view \u00b6\nContent:\nYou can use the QUERY_ATTRIBUTION_HISTORY view to attribute cost based on queries. The cost per\nquery is the warehouse credit usage for executing the query. This cost does not include any other credit usage that is incurred\nas a result of query execution. For example, the following are not included in the query cost:\nData transfer costs\nStorage costs\nCloud services costs\nCosts for serverless features\nCosts for tokens processed by AI services\nFor queries that are executed concurrently, the cost of the warehouse is attributed to individual queries based on the weighted\naverage of their resource consumption during a given time interval.\nThe cost per query does not include warehouse *idle time* . Idle time is a period of time in which no queries are running in the\nwarehouse and can be measured at the warehouse level.\nSection Title: Attributing cost \u00b6 > Additional examples of queries \u00b6\nContent:\nThe next sections provide additional queries that you can use for cost attribution:\nGrouping similar queries\nAttributing costs of hierarchical queries\n ... \nSection Title: Attributing cost \u00b6 > Additional examples of queries \u00b6 > Attributing costs of hierarchical queries \u00b6\nContent:\nFor stored procedures that issue multiple hierarchical queries, you can compute the attributed query costs for the\nprocedure by using the root query ID for the procedure.\nTo find the root query ID for a stored procedure, use the ACCESS_HISTORY view . For example,\nto find the root query ID for a stored procedure, set the `query_id` and execute the following statements:CopyFor more information, see Example: Ancestor queries with stored procedures .\nTo sum the query cost for the entire procedure, replace `<root_query_id>` and execute the following statements:Copy\nWas this page helpful?\nYes No\n[Visit Snowflake](https://www.snowflake.com)\n[Join the conversation](https://community.snowflake.com/s/)\n[Develop with Snowflake](https://developers.snowflake.com)\nShare your feedback\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n[Get your own certification](https://learn.snowflake.com)\nSection Title: Attributing cost \u00b6 > Additional examples of queries \u00b6 > Attributing costs of hierarchical queries \u00b6\nContent:\nOn this page\nTypes of cost attribution scenarios\nSetting up object tags for cost attribution\nCreating the tags\nReplicating the tag database\nTagging the resources and users\nViewing cost by tag in SQL\nResources not shared by departments\nResources shared by users from different departments\nResources used by applications that need to attribute costs to different departments\nViewing cost by tag in Snowsight\nAbout the QUERY_ATTRIBUTION_HISTORY view\nAdditional examples of queries\nGrouping similar queries\nAttributing costs of hierarchical queries\nRelated content\nManaging cost in Snowflake\nLanguage: **English**\nEnglish\nFran\u00e7ais\nDeutsch\n\u65e5\u672c\u8a9e\n\ud55c\uad6d\uc5b4\nPortugu\u00eas"
      ]
    },
    {
      "url": "https://medium.com/@jordandhill/a-practical-guide-to-snowflake-notebook-cost-attribution-f1e377244275",
      "title": "A Practical Guide to Snowflake Notebook Cost Attribution | by Jordan Hill | Medium",
      "publish_date": "2025-10-27",
      "excerpts": [
        "Sitemap\n\n[Open in app](https://play.google.com/store/apps/details?id=com.medium.reader&referrer=utm_source%3DmobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)\n\nWrite\n\nSearch\n\n# A Practical Guide to Snowflake Notebook Cost Attribution\n\nJordan Hill\n\n5 min read\n\n\u00b7\n\nOct 27, 2025\n\n\\--\n\n1\n\nListen\n\nShare\n\n## Snowflake Notebook Cost Tracking\n\nAs organizations increasingly adopt Snowflake Notebooks for data science and analytics workflows, a critical question emerges: **How much are these notebooks actually costing us?**\n\nUnlike traditional SQL queries that are more straightforward to track, Snowflake Notebooks present a unique challenge. A single notebook execution spawns multiple queries behind the scenes, and without proper attribution, these costs become hard to attribute. This article will show you how to:\n\n* Identify which notebooks are consuming the most credits\n* Attribute costs to specific teams or projects\n\nThe good news? Snowflake provides the tools to solve this problem. Let me show you how.\n\n## Understanding Notebook Query Attribution\n\nBasics you can rely on: Snowflake tracks all query activity through its `ACCOUNT_USAGE` schema, specifically the `[query_history](https://docs.snowflake.com/en/sql-reference/account-usage/query_history)` and `[query_attribution_history](https://docs.snowflake.com/en/sql-reference/account-usage/query_attribution_history)` views. When a notebook executes, it will create records in these tables as well. Additionally, Snowflake attaches metadata through **query tags** .\n\n## The Anatomy of a Notebook Query Tag\n\nEvery notebook execution creates queries tagged with JSON metadata that looks like this:\n\n```\n{  \n  \"StreamlitEngine\": \"ExecuteStreamlit\",  \n  \"StreamlitName\": \"MY_DATABASE.MY_SCHEMA.\\\"My Notebook\\\"\"  \n}\n```\n\nThis tag structure is your ticket to cost attribution. The `StreamlitName` field contains the fully qualified notebook name (database.schema.notebook), which allows you to trace all related queries back to their source notebook.\n\nCheckout [Snowflake\u2019s documentation on notebook usage monitoring](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-usage) , to understand more deeply what data you have at your disposal.\n\n## Quick Caveats: What You Won\u2019t See in Query Attribution History\n\nBefore diving into the solution, it\u2019s important to understand the limitations of the automatic query cost attribution in Snowflake:\n\n## 1\\. Fast Queries Are Not Cost-Attributed\n\nSnowflake optimizes performance by not attributing credit costs to extremely fast queries. If a query executes in under 100 milliseconds, you may not see it reflected in the `query_attribution_history` view. This is generally acceptable because these queries consume negligible resources.\n\n## 2\\. Idle Time Is Not Attributed\n\nThe attribution system tracks active query execution time, not warehouse idle time. If your notebook keeps a warehouse running between executions, those idle credits won\u2019t appear in attribution reports. This is an important distinction when calculating total notebook costs.\n\n## 3\\. Attribution Latency\n\nQuery attribution data may have a latency of up to 3 hours, so real-time cost monitoring isn\u2019t possible through these views.\n\n## The SQL Solution: DIY Cost Attribution\n\nIf you prefer a SQL-only approach without additional tools, here\u2019s a query that extracts notebook cost data for Warehouse Compute:\n\n```\nWITH notebook_query_tags AS (  \n    -- Step 1: Extract unique notebook names from query tags  \n    SELECT DISTINCT  \n        PARSE_JSON(query_tag):StreamlitName::VARCHAR AS notebook_name  \n    FROM snowflake.account_usage.query_history   \n    WHERE query_text ILIKE 'execute notebook%'  \n      AND query_tag IS NOT NULL  \n      AND start_time >= DATEADD(day, -30, CURRENT_TIMESTAMP())  \n),  \nall_nb_queries AS (  \n    -- Step 2: Find all queries associated with each notebook  \n    SELECT   \n        notebook_name,  \n        qh.*  \n    FROM snowflake.account_usage.query_history qh  \n    JOIN notebook_query_tags qt  \n    WHERE qh.query_tag ILIKE ('%' || notebook_name || '%')  \n      AND start_time >= DATEADD(day, -30, CURRENT_TIMESTAMP())  \n)  \n-- Step 3: Aggregate costs and metadata by notebook  \nSELECT   \n    notebook_name,  \n    COUNT(*) AS total_queries,  \n    SUM(credits_attributed_compute) AS total_credits_used,  \n    MIN(nb.start_time) AS first_execution,  \n    MAX(nb.end_time) AS last_execution,  \n    ARRAY_AGG(DISTINCT nb.warehouse_name) AS warehouses_used,  \n    ARRAY_AGG(DISTINCT nb.user_name) AS users  \nFROM all_nb_queries nb  \nLEFT JOIN snowflake.account_usage.query_attribution_history qah   \n    ON nb.query_id = qah.query_id  \nGROUP BY notebook_name  \nORDER BY total_credits_used DESC;\n```\n\n## How This Query Works\n\n1. **Extract Notebook Names** : The first CTE identifies all notebooks that have executed by looking for queries with text matching `'execute notebook%'` and extracting the `StreamlitName` from the query tag JSON.\n2. **Find Related Queries** : The second CTE joins back to `query_history` to find all queries that contain the notebook name in their query tags. This captures not just the initial execution but all downstream (aka child) queries.\n3. **Attribute Credits** : The final query joins with `query_attribution_history` to sum credits consumed, providing comprehensive cost information along with execution metadata.\n\n## Enhancing with Object Tagging\n\nFor enterprise environments requiring chargeback or showback capabilities, Snowflake\u2019s [object tagging feature](https://docs.snowflake.com/en/user-guide/object-tagging/introduction) provides an additional layer of cost attribution.\n\nYou can create tags like `cost_center` , `project` , or `team` and apply them to notebooks:\n\n```\n-- Create a cost center tag  \nCREATE TAG cost_center;\n```\n\n```\n-- Apply it to a notebook (requires appropriate privileges)  \nALTER NOTEBOOK my_notebook   \n    SET TAG cost_center = 'data_science';\n```\n\nTags support [inheritance and automatic propagation](https://docs.snowflake.com/en/user-guide/object-tagging/introduction) , making them ideal for organizational cost tracking. When combined with query attribution, tags enable multi-dimensional cost analysis across departments, projects, and business units.\n\n## The Streamlit Dashboard Approach\n\nWhile SQL queries are powerful, they require manual execution and lack visual context. For ongoing monitoring, consider deploying a Streamlit dashboard. And, hey, who doesn\u2019t love a little Streamlit in Snowflake.\n\nPress enter or click to view image in full size\n\nI\u2019ve created an open-source **Notebook Cost Attribution Dashboard** that provides:\n\n* Interactive visualizations of notebook costs\n* Time-range filtering (7\u2013180 days)\n* Drill-down by specific notebooks\n* CSV export for further analysis\n* Multi-dimensional charts showing cost distribution\n\n## Quick Deployment\n\nThe streamlit dashboard code is available at: [https://github.com/jordandhill/Notebook\\_Cost\\_Attribution](https://github.com/jordandhill/Notebook_Cost_Attribution)  \nThe core code is in streamlit\\_app.py.\n\nThe dashboard automatically refreshes data based on your selected time range and provides an intuitive interface for cost exploration.\n\n## One More Thing\u2026Container Runtime vs. Warehouse Runtime\n\nSnowflake Notebooks can run on either traditional warehouses or Snowpark Container Services compute pools. The attribution approach differs slightly:\n\n## Warehouse Runtime\n\nUse `query_attribution_history` as demonstrated in this article for SQL executed by any notebook and Notebooks running on Warehouse Runtime.\n\n## Container Runtime\n\nQuery the `notebooks_container_runtime_history` view to get the top-level Notebook compute cost when running on Container Runtime.\n\n```\nSELECT  \n    start_time,   \n    notebook_name,   \n    user_name,   \n    SUM(credits) AS total_container_runtime_credits  \nFROM snowflake.account_usage.notebooks_container_runtime_history  \nWHERE notebook_name = '<your_notebook_name>'  \nGROUP BY ALL;\n```\n\nFor more details, see [Snowflake\u2019s Container Runtime cost monitoring documentation](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-usage) .\n\n## Conclusion: Turning on the Lights\n\nSnowflake Notebook cost attribution transforms from a black box to a crystal-clear picture when you leverage:\n\n1. **Query tags** for notebook identification\n2. **Account usage views** for credit attribution\n3. **Object tags** for organizational cost allocation\n4. **Automated dashboards** for ongoing monitoring\n\nBy implementing these practices, you gain:\n\n* Complete visibility into notebook costs\n* The ability to optimize expensive workflows\n* Data-driven justification for resource allocation\n* Accurate chargeback to business units\n\nRemember the caveats: fast queries and idle time won\u2019t appear in attribution, but the vast majority of your notebook costs will be tracked accurately.\n\nStart with the SQL query, explore the data, and when you\u2019re ready for continuous monitoring, deploy the Streamlit dashboard. Your finance team will thank you.\n\n## Resources\n\n* **GitHub Repository** : [Notebook\\_Cost\\_Attribution](https://github.com/jordandhill/Notebook_Cost_Attribution)\n* **Snowflake Docs** : [Notebook Usage and Cost Monitoring](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-usage)\n* **Snowflake Docs** : [Object Tagging Introduction](https://docs.snowflake.com/en/user-guide/object-tagging/introduction)\n* **Snowflake Docs** : [Query Attribution History](https://docs.snowflake.com/en/sql-reference/account-usage/query_attribution_history)\n\nSnowflake\n\nSnowflake Notebooks\n\nSnowflake Cost Management\n\nNotebook\n\n\\-- \n\n\\--\n\n1\n\n## Written by Jordan Hill\n\n30 followers\n\n\u00b7 4 following\n\nSales Engineer @ Snowflake \u2744\ufe0f \u2022 Solving Data Problems \u2022 Raising 3 Kids\n\n## Responses (1)\n\n[](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--f1e377244275---------------------------------------)\n\nSee all responses\n\n[Help](https://help.medium.com/hc/en-us?source=post_page-----f1e377244275---------------------------------------)\n\n[Status](https://status.medium.com/?source=post_page-----f1e377244275---------------------------------------)\n\nAbout\n\nCareers\n\nPress\n\n[Blog](https://blog.medium.com/?source=post_page-----f1e377244275---------------------------------------)\n\n[Privacy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f1e377244275---------------------------------------)\n\n[Rules](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----f1e377244275---------------------------------------)\n\n[Terms](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f1e377244275---------------------------------------)\n\n[Text to speech](https://speechify.com/medium?source=post_page-----f1e377244275---------------------------------------)"
      ]
    },
    {
      "url": "https://docs.snowflake.com/en/sql-reference/organization-usage",
      "title": "Organization Usage - Snowflake Documentation",
      "excerpts": [
        "Section Title: Organization Usage \u00b6 > ORGANIZATION_USAGE views \u00b6\nContent:\n| View | Type | Latency [1] | Notes |\n| ACCESS_HISTORY | Historical | 24 hours | Premium view (only available in organization account). |\n| ACCOUNTS | Object | 24 hours |  |\n| ALERT_HISTORY | Historical | 24 hours | Premium view (only available in organization account). |\n| ANOMALIES_IN_CURRENCY_DAILY | Historical | 24 hours |  |\n| SEARCH_OPTIMIZATION_HISTORY | Historical | 24 hours | Data retained for 1 year. |\n| SEQUENCES | Object | 24 hours | Premium view (only available in organization account). |\n| SESSION_POLICIES | Object | 24 hours | Premium view (only available in organization account). |\n| SESSIONS | Historical | 24 hours | Premium view (only available in organization account). |\n| SNAPSHOT_OPERATION_HISTORY | Historical | 6 hours | Data retained for 1 year. This view is deprecated. Use the BACKUP_OPERATION_HISTORY view instead. |\nSection Title: Organization Usage \u00b6 > ORGANIZATION_USAGE views \u00b6\nContent:\n| View | Type | Latency [1] | Notes |\n| ACCESS_HISTORY | Historical | 24 hours | Premium view (only available in organization account). |\n| ACCOUNTS | Object | 24 hours |  |\n| ALERT_HISTORY | Historical | 24 hours | Premium view (only available in organization account). |\n| ANOMALIES_IN_CURRENCY_DAILY | Historical | 24 hours |  |\n| SNAPSHOT_POLICIES | Object | 6 hours | This view is deprecated. Use the BACKUP_POLICIES view instead. |\n| SNAPSHOT_SETS | Object | 6 hours | This view is deprecated. Use the BACKUP_SETS view instead. |\n| SNAPSHOTS | Object | 6 hours | This view is deprecated. Use the BACKUPS view instead. |\n| STAGES | Object | 24 hours | Premium view (only available in organization account). |\n| STAGE_STORAGE_USAGE_HISTORY | Historical | 24 hours | Data retained for 1 year. |\n| STORAGE_DAILY_HISTORY | Historical | 2 hours | Data retained for 1 year. |\nSection Title: Organization Usage \u00b6 > ORGANIZATION_USAGE views \u00b6\nContent:\n| View | Type | Latency [1] | Notes |\n| ACCESS_HISTORY | Historical | 24 hours | Premium view (only available in organization account). |\n| ACCOUNTS | Object | 24 hours |  |\n| ALERT_HISTORY | Historical | 24 hours | Premium view (only available in organization account). |\n| ANOMALIES_IN_CURRENCY_DAILY | Historical | 24 hours |  |\n| STORAGE_LIFECYCLE_POLICIES | Object | 24 hours | Premium view (only available in organization account). |\n| STORAGE_LIFECYCLE_POLICY_HISTORY | Historical | 24 hours | Premium view (only available in organization account). Data retained for 1 year. |\n| TABLE_CONSTRAINTS | Object | 24 hours | Premium view (only available in organization account). |\n| TABLE_STORAGE_METRICS | Object | 24 hours | Premium view (only available in organization account). |\n| TABLES | Object | 24 hours | Premium view (only available in organization account). |\n ... \nSection Title: Organization Usage \u00b6 > ORGANIZATION_USAGE views \u00b6\nContent:\n| View | Type | Latency [1] | Notes |\n| ACCESS_HISTORY | Historical | 24 hours | Premium view (only available in organization account). |\n| ACCOUNTS | Object | 24 hours |  |\n| ALERT_HISTORY | Historical | 24 hours | Premium view (only available in organization account). |\n| ANOMALIES_IN_CURRENCY_DAILY | Historical | 24 hours |  |\n| USERS | Object | 24 hours | Premium view (only available in organization account). |\n| VIEWS | Object | 24 hours | Premium view (only available in organization account). |\n| WAREHOUSE_EVENTS_HISTORY | Historical | 24 hours | Premium view (only available in organization account). |\n| WAREHOUSE_LOAD_HISTORY | Historical | 24 hours | Premium view (only available in organization account). |\n| WAREHOUSE_METERING_HISTORY | Historical | 24 hours | Data retained for 1 year. |\n ... \nSection Title: Organization Usage \u00b6 > Accessing the ORGANIZATION_ USAGE schema \u00b6\nContent:\nThe ORGANIZATION_USAGE schema is available in the organization account and a regular account that has the ORGADMIN role enabled. How you access the views in the schema differs depending on which type of account you are using. For details about accessing views, see the following:\nAccess schema in the organization account\nAccess schema in an ORGADMIN-enabled account\nNote\nThe views in the ORGANIZATION_USAGE schema are currently not available in US SnowGov Regions on AWS GovCloud and Microsoft Azure Government.\nSection Title: Organization Usage \u00b6 > ... > Access schema in the organization account \u00b6\nContent:\nBy default, only users granted the GLOBALORGADMIN role can access ORGANIZATION_USAGE views in the organization account .\nTo grant access to other users, the organization administrator can grant the appropriate *application role* to an account role or user.\nUsers who have been granted the SNOWFLAKE.ORG_USAGE_ADMIN application role can access all views in the ORGANIZATION_USAGE schema of the\norganization account. The following example lets user `joe` access all views in the schema:\n```\nUSE ROLE GLOBALORGADMIN ; \n\n GRANT APPLICATION ROLE SNOWFLAKE . ORG_USAGE_ADMIN TO ROLE custom_role ; \n\n GRANT ROLE custom_role TO USER joe ;\n```\nCopy\nThe organization administrator can also grant access on a more granular level. For example, the ORGANIZATION_OBJECT_VIEWER application role\ngrants access to the DATABASES view but does not grant access to the TASK_HISTORY view.\nSection Title: Organization Usage \u00b6 > ... > Access schema in the organization account \u00b6\nContent:\nUse the following list to determine which application role grants access to a specific view. These application roles are in the SNOWFLAKE\napplication. Use the fully qualified name of the application role when granting it to another role (for example,\nSNOWFLAKE.ORGANIZATION_USAGE_VIEWER).\nSection Title: Organization Usage \u00b6 > ... > Access schema in the organization account \u00b6\nContent:\n| View | Required application role |\n| ACCESS_HISTORY view | ORGANIZATION_GOVERNANCE_VIEWER |\n| ACCOUNTS view | ORGANIZATION_ACCOUNTS_VIEWER |\n| ALERT_HISTORY view | ORGANIZATION_USAGE_VIEWER |\n| AUTOMATIC_CLUSTERING_HISTORY view | ORGANIZATION_USAGE_VIEWER |\n| CLASSES view | ORGANIZATION_USAGE_VIEWER |\n| CLASS_INSTANCES view | ORGANIZATION_USAGE_VIEWER |\n| COLUMNS view | ORGANIZATION_OBJECT_VIEWER |\n| COMPLETE_TASK_GRAPHS view | ORGANIZATION_OBJECT_VIEWER |\n| CONTRACT_ITEMS view | ORGANIZATION_BILLING_VIEWER |\n| COPY_HISTORY view | ORGANIZATION_USAGE_VIEWER |\n| DATABASE_STORAGE_USAGE_HISTORY view | ORGANIZATION_USAGE_VIEWER |\n| DATABASES view | ORGANIZATION_OBJECT_VIEWER |\n| DATA_TRANSFER_DAILY_HISTORY view | ORGANIZATION_USAGE_VIEWER |\n| DATA_TRANSFER_HISTORY view | ORGANIZATION_USAGE_VIEWER |\n| FILE_FORMATS view | ORGANIZATION_OBJECT_VIEWER |\n| FUNCTIONS view | ORGANIZATION_OBJECT_VIEWER |\nSection Title: Organization Usage \u00b6 > ... > Access schema in the organization account \u00b6\nContent:\n| View | Required application role |\n| ACCESS_HISTORY view | ORGANIZATION_GOVERNANCE_VIEWER |\n| ACCOUNTS view | ORGANIZATION_ACCOUNTS_VIEWER |\n| ALERT_HISTORY view | ORGANIZATION_USAGE_VIEWER |\n| AUTOMATIC_CLUSTERING_HISTORY view | ORGANIZATION_USAGE_VIEWER |\n| GRANTS_TO_ROLES view | ORGANIZATION_SECURITY_VIEWER |\n| GRANTS_TO_USERS view | ORGANIZATION_SECURITY_VIEWER |\n| LISTING_AUTO_FULFILLMENT_USAGE_HISTORY view | ORGANIZATION_BILLING_VIEWER |\n| LOAD_HISTORY view | ORGANIZATION_USAGE_VIEWER |\n| LOCK_WAIT_HISTORY view | ORGANIZATION_USAGE_VIEWER |\n| LOGIN_HISTORY view | ORGANIZATION_SECURITY_VIEWER |\n| MARKETPLACE_DISBURSEMENT_REPORT View | ORGANIZATION_BILLING_VIEWER |\n| MARKETPLACE_PAID_USAGE_DAILY View | ORGANIZATION_USAGE_VIEWER |\n| MARKETPLACE_PURCHASE_EVENTS view | ORGANIZATION_BILLING_VIEWER |\n| MASKING_POLICIES view | ORGANIZATION_GOVERNANCE_VIEWER |\nSection Title: Organization Usage \u00b6 > ... > Access schema in the organization account \u00b6\nContent:\n| View | Required application role |\n| ACCESS_HISTORY view | ORGANIZATION_GOVERNANCE_VIEWER |\n| ACCOUNTS view | ORGANIZATION_ACCOUNTS_VIEWER |\n| ALERT_HISTORY view | ORGANIZATION_USAGE_VIEWER |\n| AUTOMATIC_CLUSTERING_HISTORY view | ORGANIZATION_USAGE_VIEWER |\n| MATERIALIZED_VIEW_REFRESH_HISTORY view | ORGANIZATION_USAGE_VIEWER |\n| METERING_DAILY_HISTORY view | ORGANIZATION_USAGE_VIEWER |\n| METERING_HISTORY view | ORGANIZATION_USAGE_VIEWER |\n| MONETIZED_USAGE_DAILY | ORGANIZATION_USAGE_VIEWER |\n| OBJECT_DEPENDENCIES view | ORGANIZATION_OBJECT_VIEWER |\n| PASSWORD_POLICIES view | ORGANIZATION_SECURITY_VIEWER |\n| PIPE_USAGE_HISTORY view | ORGANIZATION_USAGE_VIEWER |\n| PIPES view | ORGANIZATION_OBJECT_VIEWER |\n| POLICY_REFERENCES view | ORGANIZATION_GOVERNANCE_VIEWER |\n| PROCEDURES view | ORGANIZATION_OBJECT_VIEWER |\n| QUERY_ACCELERATION_ELIGIBLE view | ORGANIZATION_GOVERNANCE_VIEWER |\nSection Title: Organization Usage \u00b6 > ... > Access schema in the organization account \u00b6\nContent:\n| View | Required application role |\n| ACCESS_HISTORY view | ORGANIZATION_GOVERNANCE_VIEWER |\n| ACCOUNTS view | ORGANIZATION_ACCOUNTS_VIEWER |\n| ALERT_HISTORY view | ORGANIZATION_USAGE_VIEWER |\n| AUTOMATIC_CLUSTERING_HISTORY view | ORGANIZATION_USAGE_VIEWER |\n| QUERY_ACCELERATION_HISTORY view | * ORGANIZATION_GOVERNANCE_VIEWER |\nSection Title: Organization Usage \u00b6 > ... > Access schema in the organization account \u00b6\nContent:\nORGANIZATION_USAGE_VIEWER |\n|QUERY_ATTRIBUTION_HISTORY view |* ORGANIZATION_GOVERNANCE_VIEWER\nORGANIZATION_USAGE_VIEWER |\n|QUERY_HISTORY view |ORGANIZATION_GOVERNANCE_VIEWER |\n|RATE_SHEET_DAILY view |ORGANIZATION_BILLING_VIEWER |\n|REFERENTIAL_CONSTRAINTS view |ORGANIZATION_OBJECT_VIEWER |\n|REMAINING_BALANCE_DAILY view |ORGANIZATION_BILLING_VIEWER |\n|REPLICATION_GROUP_REFRESH_HISTORY view |ORGANIZATION_USAGE_VIEWER |\n|REPLICATION_GROUP_USAGE_HISTORY view |ORGANIZATION_USAGE_VIEWER |\n|REPLICATION_USAGE_HISTORY view |ORGANIZATION_USAGE_VIEWER |\n|RESOURCE_MONITORS view |ORGANIZATION_OBJECT_VIEWER |\n|ROLES view |ORGANIZATION_SECURITY_VIEWER |\n|ROW_ACCESS_POLICIES view |ORGANIZATION_GOVERNANCE_VIEWER |\n|SCHEMATA view |ORGANIZATION_OBJECT_VIEWER |\n|SEARCH_OPTIMIZATION_HISTORY view |ORGANIZATION_USAGE_VIEWER |\n|SEQUENCES view |ORGANIZATION_OBJECT_VIEWER |\n|SESSION_POLICIES view |ORGANIZATION_SECURITY_VIEWER |\n|SESSIONS\nSection Title: Organization Usage \u00b6 > ... > Access schema in the organization account \u00b6\nContent:\nview |ORGANIZATION_SECURITY_VIEWER |\n|STAGE_STORAGE_USAGE_HISTORY view |ORGANIZATION_USAGE_VIEWER |\n|STAGES view |ORGANIZATION_OBJECT_VIEWER |\n|STORAGE_LIFECYCLE_POLICIES view |ORGANIZATION_GOVERNANCE_VIEWER |\n|STORAGE_LIFECYCLE_POLICY_HISTORY view |ORGANIZATION_GOVERNANCE_VIEWER |\n|STORAGE_DAILY_HISTORY view |ORGANIZATION_USAGE_VIEWER |\n|TABLE_CONSTRAINTS view |ORGANIZATION_OBJECT_VIEWER |\n|TABLE_STORAGE_METRICS view |ORGANIZATION_USAGE_VIEWER |\n|TABLES view |ORGANIZATION_OBJECT_VIEWER |\n|TAG_REFERENCES view |ORGANIZATION_GOVERNANCE_VIEWER |\n|TAGS view |ORGANIZATION_OBJECT_VIEWER |\n|TASK_HISTORY view |ORGANIZATION_USAGE_VIEWER |\n|TASK_VERSIONS view |ORGANIZATION_OBJECT_VIEWER |\n|TRUST_CENTER_FINDINGS view |ORGANIZATION_SECURITY_VIEWER |\n|USAGE_IN_CURRENCY_DAILY view |ORGANIZATION_BILLING_VIEWER |\n|USERS view |ORGANIZATION_SECURITY_VIEWER |\n|VIEWS view |ORGANIZATION_OBJECT_VIEWER |\n|WAREHOUSE_EVENTS_HISTORY view"
      ]
    },
    {
      "url": "https://docs.snowflake.com/en/sql-reference/account-usage/query_attribution_history",
      "title": "QUERY_ATTRIBUTION_HISTORY view | Snowflake Documentation",
      "excerpts": [
        "[DOCUMENTATION](https://docs.snowflake.com)\n\n/\n\nGet started\n\nGuides\n\nDeveloper\n\nReference\n\nRelease notes\n\nTutorials\n\n[Status](https://status.snowflake.com)\n\nReference General reference SNOWFLAKE database Account Usage QUERY\\_ATTRIBUTION\\_HISTORY\n\nSchemas:\n    ACCOUNT\\_USAGE\n\n# QUERY\\_ ATTRIBUTION\\_ HISTORY view \u00b6\n\nThis Account Usage view can be used to determine the compute cost of a given query run on warehouses in your account\nin the last 365 days (1 year).\n\nFor more information, see Viewing cost by tag in SQL .\n\n## Columns \u00b6\n\n|Column name |Data type |Description |\n| --- | --- | --- |\n|QUERY\\_ID |VARCHAR |Internal/system-generated identifier for the SQL statement. |\n|PARENT\\_QUERY\\_ID |VARCHAR |Query ID of the parent query or NULL if the query does not have a parent. |\n|ROOT\\_QUERY\\_ID |VARCHAR |Query ID of the topmost query in the chain or NULL if the query does not have a parent. |\n|WAREHOUSE\\_ID |NUMBER |Internal/system-generated identifier for the warehouse that the query was executed on. |\n|WAREHOUSE\\_NAME |VARCHAR |Name of the warehouse that the query executed on. |\n|QUERY\\_HASH |VARCHAR |The hash value computed based on the canonicalized SQL text. |\n|QUERY\\_PARAMETERIZED\\_HASH |VARCHAR |The hash value computed based on the parameterized query. |\n|QUERY\\_TAG |VARCHAR |Query tag set for this statement through the QUERY\\_TAG session parameter. |\n|USER\\_NAME |VARCHAR |User who issued the query. |\n|START\\_TIME |TIMESTAMP\\_LTZ |Time when query execution started (in the local time zone). |\n|END\\_TIME |TIMESTAMP\\_LTZ |Time when query execution ended (in the local time zone). |\n|CREDITS\\_ATTRIBUTED\\_COMPUTE |NUMBER |Number of credits attributed to this query. Includes only the credit usage for the query execution and doesn\u2019t include any warehouse idle time. |\n|CREDITS\\_USED\\_QUERY\\_ACCELERATION |NUMBER |Number of credits consumed by the Query Acceleration Service to accelerate the query. NULL if the query is not accelerated. . . The total cost for an accelerated query is the sum of this column and the CREDITS\\_ATTRIBUTED\\_COMPUTE column. |\n\n## Usage notes \u00b6\n\n* Latency for this view can be up to eight hours.\n* This view displays results for any role granted the USAGE\\_VIEWER or GOVERNANCE\\_VIEWER database role .\n\n* The value in the `credits_attributed_compute` column contains the warehouse credit usage for executing the query,\n  inclusive of any resizing and/or autoscaling of multi-cluster warehouse(s). This cost is attributed based on\n  the weighted average of the resource consumption.\n  \n  The value doesn\u2019t include any credit usage for warehouse idle time. Idle time is a period\n  of time in which no queries are running in the warehouse and can be measured at the warehouse level.\n  \n  The value doesn\u2019t include any other credit usage that is incurred as a result of query execution.\n  For example, the following are not included in the query cost:\n  \n    + Data transfer costs\n    + Storage costs\n    + Cloud services costs\n    + Costs for serverless features\n    + Costs for tokens processed by AI services\n* For queries that are executed concurrently, the cost of the warehouse is attributed to individual queries based on the\n  weighted average of their resource consumption during a given time interval.\n* Short-running queries (<= ~100ms) are currently too short for per query cost attribution and are not included in the view.\n* Data for all columns is available starting from mid-August, 2024. Some data prior to this date might be available in the view, but\n  might be incomplete.\n\n## Examples \u00b6\n\n### Query costs for related queries \u00b6\n\nTo determine the costs of a specific query and similar queries using the query parameterized hash, replace `<query_id>` and execute the following statements:\n\n```\nSET query_id = '<query_id>' ; \n\n WITH query_hash_of_query AS ( \n  SELECT query_parameterized_hash \n  FROM SNOWFLAKE . ACCOUNT_USAGE . QUERY_ATTRIBUTION_HISTORY \n  WHERE query_id = $ query_id \n  LIMIT 1 \n ) \n SELECT \n  query_parameterized_hash , \n  COUNT (*) AS query_count , \n  SUM ( credits_attributed_compute ) AS recurrent_query_attributed_credits \n FROM SNOWFLAKE . ACCOUNT_USAGE . QUERY_ATTRIBUTION_HISTORY \n WHERE start_time >= DATE_TRUNC ( 'MONTH' , CURRENT_DATE ) \n  AND start_time < CURRENT_DATE \n  AND query_parameterized_hash = ( SELECT query_parameterized_hash FROM query_hash_of_query ) \n GROUP BY ALL ;\n```\n\nCopy\n\n### Query costs for the current user \u00b6\n\nTo determine the costs of queries executed by the current user for the current month, execute the following statement:\n\n```\nSELECT user_name , SUM ( credits_attributed_compute ) AS credits \n  FROM SNOWFLAKE . ACCOUNT_USAGE . QUERY_ATTRIBUTION_HISTORY \n  WHERE user_name = CURRENT_USER () \n    AND start_time >= DATE_TRUNC ( 'MONTH' , CURRENT_DATE ) \n    AND start_time < CURRENT_DATE \n  GROUP BY user_name ;\n```\n\nCopy\n\nFor an example of attributing warehouse costs to users, see Resources shared by users from different departments .\n\n### Query costs for stored procedures \u00b6\n\nFor stored procedures that issue multiple hierarchical queries, you can compute the attributed query costs for the\nprocedure by using the root query ID for the procedure.\n\n1. To find the root query ID for a stored procedure, use the ACCESS\\_HISTORY view . For example,\n   to find the root query ID for a stored procedure, set the `query_id` and execute the following statements:\n   \n   ```\n   SET query_id = '<query_id>' ; \n   \n    SELECT query_id , \n          parent_query_id , \n          root_query_id , \n          direct_objects_accessed \n     FROM SNOWFLAKE . ACCOUNT_USAGE . ACCESS_HISTORY \n     WHERE query_id = $ query_id ;\n   ```\n   \n   Copy\n   \n   For more information, see Ancestor queries with stored procedures .\n2. To sum the query cost for the entire procedure, replace `<root_query_id>` and execute the following statements:\n   \n   ```\n   SET query_id = '<root_query_id>' ; \n   \n    SELECT SUM ( credits_attributed_compute ) AS total_attributed_credits \n     FROM SNOWFLAKE . ACCOUNT_USAGE . QUERY_ATTRIBUTION_HISTORY \n     WHERE ( root_query_id = $ query_id OR query_id = $ query_id );\n   ```\n   \n   Copy\n\n### Additional examples \u00b6\n\nFor more examples, see Resources shared by users from different departments .\n\nWas this page helpful?\n\nYes No\n\n[Visit Snowflake](https://www.snowflake.com)\n\n[Join the conversation](https://community.snowflake.com/s/)\n\n[Develop with Snowflake](https://developers.snowflake.com)\n\nShare your feedback\n\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n\n[Get your own certification](https://learn.snowflake.com)\n\nOn this page\n\n1. Columns\n2. Usage notes\n3. Examples\n4. Query costs for related queries\n5. Query costs for the current user\n6. Query costs for stored procedures\n7. Additional examples\n\nRelated content\n\n1. Overview of warehouses\n\nLanguage: **English**\n\n* English\n* Fran\u00e7ais\n* Deutsch\n* \u65e5\u672c\u8a9e\n* \ud55c\uad6d\uc5b4\n* Portugu\u00eas\n\n## Snowflake's Use of Cookies\n\n## Privacy Preference Center\n\nYour Opt Out Preference Signal is Honored\n\n* ### Your Privacy\n* ### Strictly Necessary Cookies\n* ### Performance Cookies\n* ### Functional Cookies\n* ### Targeting Cookies\n\n#### Your Privacy\n\nWhen you visit any website, it may store or retrieve information on your browser, mostly in the form of cookies. This information might be about you, your preferences or your device and is mostly used to make the site work as you expect it to. The information does not usually directly identify you, but it can give you a more personalized web experience. Because we respect your right to privacy, you can choose not to allow some types of cookies. Click on the different category headings to find out more and change our default settings. However, blocking some types of cookies may impact your experience of the site and the services we are able to offer.  \n[More information](https://cookiepedia.co.uk/giving-consent-to-cookies)\n\n#### Strictly Necessary Cookies\n\nAlways Active\n\nThese cookies are necessary for the website to function and cannot be switched off. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.\n\nCookies Details\u200e\n\n#### Performance Cookies\n\nPerformance Cookies\n\nThese cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site.    All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance.\n\nCookies Details\u200e\n\n#### Functional Cookies\n\nFunctional Cookies\n\nThese cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages.    If you do not allow these cookies then some or all of these services may not function properly.\n\nCookies Details\u200e\n\n#### Targeting Cookies\n\nTargeting Cookies\n\nThese cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly identifiable personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising.\n\nCookies Details\u200e\n\n### Cookie List\n\nConsent Leg.Interest\n\ncheckbox label label\n\ncheckbox label label\n\ncheckbox label label\n\nClear\n\ncheckbox label label\n\nApply Cancel\n\nConfirm My Choices\n\nAllow All\n\n[](https://www.onetrust.com/products/cookie-consent/)"
      ]
    },
    {
      "url": "https://www.kipi.ai/insights/optimizing-cost-attribution-in-snowflake-a-chargeback-model-guide/",
      "title": "Optimizing Cost Attribution in Snowflake: A Chargeback Model Guide",
      "excerpts": [
        "Jun 20, 2025 \u2014 Cost attribution in Snowflake involves assigning usage costs to specific departments, projects, or teams. This process is vital for\u00a0... Jun 20, 2025 \u2014 Cost attribution in Snowflake involves assigning usage costs to specific departments, projects, or teams . This process is vital for\u00a0... Read more"
      ]
    },
    {
      "url": "https://medium.com/snowflake/granular-cost-attribution-and-chargeback-for-warehouse-costs-on-snowflake-cf96fb690967",
      "title": "Granular cost attribution and chargeback for warehouse costs on Snowflake | by Kaushal Jain | Snowflake Builders Blog: Data Engineers, App Developers, AI, & Data Science | Medium",
      "publish_date": "2024-09-03",
      "excerpts": [
        "Section Title: ... > Warehouse-Based Cost Allocation\nContent:\n**Scenario 2: Warehouse Naming Convention** Warehouses follow a naming convention such as *teamname_details* or *workload_details* . This allows for direct mapping of costs to the respective business units or workloads. Here is an example query that gives a split of the costs across teams assuming they follow a naming convention. The *others* bucket captures the ones not following the convention for reconciliation.\n ... \nSection Title: ... > Introducing Per Query Cost Attribution\nContent:\nThe per query cost attribution feature provides the portion of the warehouse cost that can be attributed to a given query. If there is only a single query running in a warehouse, the entire cost of the warehouse is attributed to that query. If multiple simultaneous queries are running, the cost of the warehouse during the overlapping periods is attributed to the queries based on their relative resource consumption. During the times when there is no query running and the warehouse is idle (not suspended), the costs are not attributed to any particular query but can be easily determined and spread across the queries as needed for reconciliation purposes.\n**Common Methods to Allocate Costs Using Per Query Cost Attribution**\nSection Title: ... > Get Kaushal Jain\u2019s stories in your inbox\nContent:\nJoin Medium for free to get updates from this writer.\nSubscribe\nSubscribe\n**1. User-Based Costs** Understanding costs associated with a given user can be useful for accountability, budgeting and more granular forecasting. It can also provide hints on which users are most effective in their use of Snowflake. Chargeback of Snowflake costs at a user level can be achieved using the USER_NAME column in the QUERY_ATTRIBUTION_HISTORY view. The following sample query provides a way to attribute monthly warehouse costs across users. The idle time costs are proportionately attributed based on the relative spend by users.\nSection Title: ... > Get Kaushal Jain\u2019s stories in your inbox\nContent:\n```\nWITH  wh_bill  AS  (  \nSELECT SUM (credits_used_compute)  AS  compute_credits  \nFROM  snowflake.account_usage.warehouse_metering_history  \nWHERE  start_time  >=  DATE_TRUNC( 'MONTH' , DATEADD( MONTH ,  -1 ,  CURRENT_DATE ))  \nAND  start_time  <  DATE_TRUNC( 'MONTH' ,  CURRENT_DATE )  \n),  \nuser_credits  AS  (  \nSELECT  user_name,  SUM (credits_attributed_compute)  AS  credits  \nFROM  snowflake.account_usage.query_attribution_history  \nWHERE  start_time  >=  DATE_TRUNC( 'MONTH' , DATEADD( MONTH ,  -1 ,  CURRENT_DATE ))  \nAND  start_time  <  DATE_TRUNC( 'MONTH' ,  CURRENT_DATE )  \nGROUP BY  user_name  \n),  \ntotal_credit  AS  (  \nSELECT SUM (credits)  AS  sum_all_credits  \nFROM  user_credits  \n)  \nSELECT  u.user_name, u.credits  /  t.sum_all_credits  *  w.compute_credits  AS  attributed_credits  \nFROM  user_credits u, total_credit t, wh_bill w;\n```\nPress enter or click to view image in full size\n ... \nSection Title: ... > Get Kaushal Jain\u2019s stories in your inbox\nContent:\n```\nSELECT  query_parameterized_hash,   \nCOUNT ( * )  AS  query_count,   \nSUM (credits_attributed_compute)  AS  total_credits  \nFROM  snowflake.account_usage.query_attribution_history  \nWHERE  start_time  >=  DATE_TRUNC( 'MONTH' , DATEADD( MONTH ,  -1 ,  CURRENT_DATE ))  \nAND  start_time  <  DATE_TRUNC( 'MONTH' ,  CURRENT_DATE )  \nGROUP BY  query_parameterized_hash  \nORDER BY  total_credits  DESC  \nLIMIT  20 ;\n```\nPress enter or click to view image in full size\nAdditionally, for stored procedures that often issue multiple hierarchical queries, you can compute the attributed costs for the entire procedure using the following example query, as the parent and the root query ids are available for such procedures in the view."
      ]
    },
    {
      "url": "https://diggrowth.com/blogs/marketing-attribution/snowflake-cost-attribution/",
      "title": "Snowflake Cost Attribution For B2B: Assign, Track, And Optimize Usage",
      "publish_date": "2025-06-30",
      "excerpts": [
        "Section Title: How B2B Companies Can Master Snowflake Cost Attribution > ... > Query Tags\nContent:\nQuery tags let you add metadata to SQL queries running in your Snowflake environment. You can define tags at the session level or within queries to reflect business-specific attributes.\nHow you can apply them:\nTag queries by team (for example, team=finance)\nIdentify activity by project (such as project=forecasting)\nSeparate environments using tags like env=prod or env=dev\nA consistent tagging approach across teams makes it easier to track query activity and link compute usage to specific business areas.\n ... \nSection Title: How B2B Companies Can Master Snowflake Cost Attribution > ... > Usage and Billing Views\nContent:\nSnowflake provides built-in system views through the ACCOUNT_USAGE and ORGANIZATION_USAGE schemas. These tables give you access to detailed billing and consumption data.\nKey views include:\nWAREHOUSE_METERING_HISTORY for tracking credit use by virtual warehouse\nQUERY_HISTORY for analyzing query behavior and execution context\nSTORAGE_USAGE for monitoring data volume over time\nLOGIN_HISTORY for auditing user access and activity\nWhen you combine these views with tags, user roles, and resource metadata, you gain the ability to access credit usage at a highly granular level. This enables precise cost attribution across departments, teams, and business functions.\nSection Title: How B2B Companies Can Master Snowflake Cost Attribution > ... > Usage and Billing Views\nContent:\nAbsolutely \u2014 here is a more **in-depth and comprehensive** version of the section \u201c **Building a Cost Attribution Strategy\u201d** that provides both strategic context and practical guidance. This version is designed to inform B2B readers who are serious about operationalizing Snowflake cost attribution at scale.\nSection Title: How B2B Companies Can Master Snowflake Cost Attribution > Building a Cost Attribution Strategy\nContent:\nA strong [cost attribution](https://diggrowth.com/blogs/marketing-attribution/cost-attribution-model/) strategy is not just about tracking spend \u2014 it is about making Snowflake usage measurable, accountable, and aligned with your business objectives. This requires more than setting up tags and queries. It calls for governance, automation, and buy-in from both technical and non-technical teams.\nBelow is a step-by-step guide to help you build a strategy that is accurate, scalable, and organization-wide.\nSection Title: ... > 1. Define Attribution Units That Reflect Business Ownership\nContent:\nThe first step is to identify which entities within your business should be accountable for Snowflake usage. These attribution units will form the basis of your cost model.\n ... \nSection Title: How B2B Companies Can Master Snowflake Cost Attribution > ... > Dashboard Concepts\nContent:\nOnce the data is available in an attribution-ready format, you can use BI tools (such as Tableau, Power BI, or Sigma) to build cost visibility for business leaders, engineers, and finance teams.\nHere are a few dashboard ideas that provide clarity and drive action:\nCost by Team:\nA bar or stacked chart showing total compute credits consumed by each tagged team over time. Helps in identifying high-usage departments.\nUsage Trends Over Time:\nA time-series visualization of total Snowflake usage segmented by team or environment. Helps in forecasting and understanding seasonal patterns.\nTag Coverage Report:\nA breakdown of tagged vs. untagged queries and objects to monitor tagging adoption and governance gaps.\nEnvironment Split (Dev vs Prod):\nVisualize spend across different environments to track whether development workloads are consuming production-level resources.\n ... \nSection Title: ... > Can Snowflake cost attribution be integrated with chargeback models?\nContent:\nYes, cost attribution data can feed into internal chargeback models, enabling finance teams to allocate Snowflake expenses directly to departments, improving budget accuracy and fostering usage accountability across the organization."
      ]
    },
    {
      "url": "https://docs.snowflake.com/en/user-guide/organization-accounts-premium-views",
      "title": "Premium views in the organization account | Snowflake Documentation",
      "excerpts": [
        "[DOCUMENTATION](https://docs.snowflake.com)\n\n/\n\nGet started\n\nGuides\n\nDeveloper\n\nReference\n\nRelease notes\n\nTutorials\n\n[Status](https://status.snowflake.com)\n\nGuides Organizations & Accounts Organization account Premium views\n\n# Premium views in the organization account \u00b6\n\nThe ORGANIZATION\\_USAGE schema contains views that provide organization-level data. The\nORGANIZATION\\_USAGE schema in the organization account contains views that are not available in the ORGANIZATION\\_USAGE schema of a regular account. These views are considered _premium views_ because they aggregate usage and object data from all accounts into a single view that is not otherwise available, and therefore incur\nadditional costs.\n\nPremium views correspond to views in the ACCOUNT\\_USAGE schema, but provide organization-level data rather than account-level data. For\nexample, someone could query the TAG\\_REFERENCES view in the ACCOUNT\\_USAGE schema to learn about how tags are used in a specific account, but\nsomeone could query the TAG\\_REFERENCES view in the ORGANIZATION\\_USAGE schema of the organization account to learn how tags are used\nthroughout the organization.\n\nFor a list of premium views, see Organization Usage .\n\nNote\n\nIt can take two weeks from the time the organization account is created until premium views are fully populated with 365 days of\nhistorical data from accounts.\n\n## Costs associated with premium views \u00b6\n\nPremium views incur additional costs based on how many records were processed to generate the views. For the current rate for premium views, find the Organization Usage table in the [Snowflake Service Consumption Table](https://www.snowflake.com/legal-files/CreditConsumptionTable.pdf) .\n\n## Grant access to the premium views \u00b6\n\nFor information about granting access to premium views, see Access schema in the organization account .\n\n## Organizations without a capacity contract \u00b6\n\nBy default, premium views are only available in organizations that have a capacity contract. If you have on demand accounts and want to\naccess premium views, contact [Snowflake Support](https://docs.snowflake.com/user-guide/contacting-support) .\n\n## Effect on views in the ACCOUNT\\_ USAGE schema \u00b6\n\nSnowflake uses the hidden schema `snowflake.organization_usage_local` to store internal objects used in conjunction with premium views.\nThese objects might be visible in the ACCOUNT\\_USAGE views in the organization account. Because these objects are internal, they might\nchange without notice in the future.\n\nWas this page helpful?\n\nYes No\n\n[Visit Snowflake](https://www.snowflake.com)\n\n[Join the conversation](https://community.snowflake.com/s/)\n\n[Develop with Snowflake](https://developers.snowflake.com)\n\nShare your feedback\n\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n\n[Get your own certification](https://learn.snowflake.com)\n\nOn this page\n\n1. Costs associated with premium views\n2. Grant access to the premium views\n3. Organizations without a capacity contract\n4. Effect on views in the ACCOUNT\\_USAGE schema\n\nRelated content\n\n1. Organization accounts\n2. Organization Usage\n\nLanguage: **English**\n\n* English\n* Fran\u00e7ais\n* Deutsch\n* \u65e5\u672c\u8a9e\n* \ud55c\uad6d\uc5b4\n* Portugu\u00eas"
      ]
    },
    {
      "url": "https://yukidata.com/snowflake-cost-per-query/",
      "title": "Snowflake Cost Per Query: Query-Level Cost Attribution Guide | Yuki",
      "publish_date": "2025-07-30",
      "excerpts": [
        "Section Title: Snowflake Cost Per Query: Complete Guide to Query-Level Cost Attribution\nContent:\nWhy query-level cost attribution is so important\nEasier, but less in-depth calculation strategy\nA more advanced calculation approach\nSnowflake\u2019s native query attribution\nHow to streamline costs with third-party tools\nSection Title: ... > Why Query-Level Cost Attribution Matters\nContent:\nRemember: Snowflake\u2019s billing model means you\u2019re paying for every second your virtual warehouses are running \u2013 and you have a minimum 60-second charge every time a warehouse resumes.\nSnowflake will give you a warehouse level cost breakdown, but what it doesn\u2019t show you are the queries behind your bill.\n*This* is why you need to understand the cost per query. Query-level cost attribution reveals situations like:\nThat single poorly optimized dashboard query costing you $2,000 every month\nRedundant data transformations running multiple times and churning out identical results\nThose developmental queries running on production-sized warehouses\n[Idle time queries](https://yukidata.com/blog/the-silent-credit-killer-snowflakes-idle-time-drain/) eating up 40% of your compute budget\nNow that you know why keeping an eye on Snowflake cost per query is so important, let\u2019s take a look at two approaches to calculate costs.\nSection Title: ... > The Easier Approach: Execution Time x Billing Rate\nContent:\nThere\u2019s an easy way and a harder way to calculate your Snowflake cost per query. The more straightforward path is easier to do, but comes with a few problems.\nAll you have to do is take your query\u2019s execution time and multiply it by your warehouse billing rate.\n**Example calculation:**\nSay you have a:\nQuery that runs for 10 minutes on a Medium warehouse\nThat medium warehouse costs you four credits per hour\nAt $3 per credit, you\u2019re looking at: 10/60 hours x 4 credits/hour x $3/credit = $2\n ... \nSection Title: ... > Snowflake\u2019s Native Query Attribution\nContent:\nSnowflake actually does have a query attribution history for you to look at native cost attribution. It was released in July 2024. But it has a few limitations:\nData only available from July 1, 2024 onwards\nShort queries (under 100ms) are excluded\nIdle time isn\u2019t included in attribution costs\nData appears with up to 6-hour delays\nSome users report inflated costs for short queries\nSnowflake\u2019s native query attribution is promising, but it\u2019s not there yet. Many organizations still turn to a custom logic for more accurate readings.\n ... \nSection Title: ... > Streamline Cost Optimization With Purpose-Built Tools\nContent:\nYou know how to build your DIY solution for figuring out costs per query, but this method \u2013 and other cost measurement solutions \u2013 are often unsustainable long-term. You\u2019re facing an uphill battle against:\nConstant updates for new Snowflake releases\nHandling the complexity of multi-cluster and auto-scaling warehouses\nLong-term cost analyses require robust data retention strategies\nTechnical solutions may not be best for business stakeholders\nYou don\u2019t have to spend entire engineering cycles building and maintaining cost attribution systems. Many organizations are turning to Snowflake cost optimization platforms like Yuki for help. These solutions provide:\nSection Title: ... > Streamline Cost Optimization With Purpose-Built Tools\nContent:\nAutomated cost attribution with real-time accuracy\nQuery optimization recommendations based on execution patterns\nWarehouse right-sizing and automated scaling\nBudget alerts and governance to prevent cost overruns\nEasy to use and understand executive dashboards perfect for stakeholders\nPlug-and-play tools like Yuki mean calculating \u2013 and optimizing \u2013 your queries with ease, no additional dev lift needed.\nReady to gain complete visibility into your Snowflake costs? Yuki\u2019s intelligent cost optimization platform provides automated query-level attribution, optimization recommendations, and governance controls \u2013 all without engineering overhead.\nContact us to get your [free demo today.](https://yukidata.com/request-demo/)\nBy Ido Arieli Noga"
      ]
    },
    {
      "url": "https://docs.snowflake.com/en/sql-reference/account-usage",
      "title": "Account Usage - Snowflake Documentation",
      "excerpts": [
        "[DOCUMENTATION](https://docs.snowflake.com)\n/\nGet started\nGuides\nDeveloper\nReference\nRelease notes\nTutorials\n[Status](https://status.snowflake.com)\nReference General reference SNOWFLAKE database Account Usage\nSection Title: Account Usage \u00b6\nContent:\nIn the SNOWFLAKE database, the ACCOUNT_USAGE and READER_ACCOUNT_USAGE schemas enable querying object metadata, as well as historical\nusage data, for your account and all reader accounts (if any) associated with the account.\nSection Title: Account Usage \u00b6 > Overview of Account Usage schemas \u00b6\nContent:\nACCOUNT_USAGE :\nViews that display object metadata and usage metrics for your account.\nIn general, these views mirror the corresponding views and table functions in the Snowflake Snowflake Information Schema , but\nwith the following differences:\nRecords for dropped objects included in each view.\nLonger retention time for historical usage data.\nData latency.\nFor more details, see Differences Between Account Usage and Information Schema (in this topic). For more details about each\nview, see ACCOUNT_USAGE Views (in this topic).\nREADER_ACCOUNT_USAGE :\nViews that display object metadata and usage metrics for all the reader accounts that have been created for\nyour account (as a Secure Data Sharing provider).\nThese views are a small subset of the ACCOUNT_USAGE views that apply to reader accounts. Also, each view in this schema contains an\nadditional `READER_ACCOUNT_NAME` column for filtering results by reader account.\n ... \nSection Title: Account Usage \u00b6 > Querying the Account Usage views \u00b6\nContent:\nThis section includes considerations when querying the Account Usage views along with query examples.\n ... \nSection Title: Account Usage \u00b6 > Querying the Account Usage views \u00b6 > Reconciling cost views \u00b6\nContent:\nThere are several Account Usage views that contain data related to the cost of compute resources, storage, and data transfers. If you are trying to reconcile these views against a corresponding view in the ORGANIZATION_USAGE schema , you must first set the timezone of the session to UTC.\nFor example, if you are trying to reconcile ACCOUNT_USAGE.WAREHOUSE_METERING_HISTORY to the account\u2019s data in ORGANIZATION_USAGE.WAREHOUSE_METERING_HISTORY, you must run the following command before querying the Account Usage view:\n```\nALTER SESSION SET TIMEZONE = UTC ;\n```\nCopy\nSection Title: Account Usage \u00b6 > Querying the Account Usage views \u00b6 > Examples \u00b6\nContent:\nThe following examples show some typical/useful queries using the views in the ACCOUNT_USAGE schema.\nNote\nThese examples assume the SNOWFLAKE database and the ACCOUNT_USAGE schema are in use for the current session. The examples also\nassume the ACCOUNTADMIN role (or a role granted IMPORTED PRIVILEGES on the database) is in use. If they are not in use, execute\nthe following commands before running the queries in the examples:Copy\n ... \nSection Title: Account Usage \u00b6 > ... > Examples \u00b6 > Examples: User query totals and execution times \u00b6\nContent:\nTotal jobs executed in your account (month-to-date):\nCopy\nTotal jobs executed by each warehouse in your account (month-to-date):\nCopy\nAverage query execution time by user (month-to-date):\nCopy\nAverage query execution time by query type and warehouse size (month-to-date):\nCopy\nSection Title: Account Usage \u00b6 > ... > Examples \u00b6 > Examples: Obtain a query count for every login event \u00b6\nContent:\nJoin columns from LOGIN_HISTORY, QUERY_HISTORY, and SESSIONS to obtain a query count for each user login event.\nNoteThe SESSIONS view records information starting on July 20-21, 2020, therefore the query result will only contain overlapping\ninformation for each of the three views starting from this date.Copy\nWas this page helpful?\nYes No\n[Visit Snowflake](https://www.snowflake.com)\n[Join the conversation](https://community.snowflake.com/s/)\n[Develop with Snowflake](https://developers.snowflake.com)\nShare your feedback\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n[Get your own certification](https://learn.snowflake.com)\nLanguage: **English**\nEnglish\nFran\u00e7ais\nDeutsch\n\u65e5\u672c\u8a9e\n\ud55c\uad6d\uc5b4\nPortugu\u00eas"
      ]
    }
  ],
  "usage": [
    {
      "name": "sku_search",
      "count": 1
    }
  ]
}
