{"extract_id":"extract_adf6b56c6a0445fdbcd6bd8775952dc3","results":[{"url":"https://docs.snowflake.com/en/user-guide/cost-controlling-controls","title":"Cost controls for warehouses | Snowflake Documentation","publish_date":null,"excerpts":["Guides Cost & Billing Control Cost controls for warehouses\nSection Title: Cost controls for warehouses ¶\nContent:\nThis topic discusses *controls* that you can use to limit how much is spent on virtual warehouse usage. These controls help ensure that the actual cost of using virtual warehouses does not exceed expected cost.\nThese controls do not apply to cloud services and serverless features .\nSection Title: Cost controls for warehouses ¶ > Control access to warehouses ¶\nContent:\nCarefully defining who can work with warehouses and what they can do with those warehouses helps control cost by limiting compute resource\nusage to known warehouses that have cost-effective configurations. Snowflake’s granular access control allows you to grant the following privileges for warehouses:\nSection Title: Cost controls for warehouses ¶ > Control access to warehouses ¶\nContent:\n**CREATE WAREHOUSE** — Global privilege (i.e. granted on the account) that restricts which roles can create a new warehouse, allowing\nyou to force individuals to use existing warehouses that have cost controls in place.\n**MODIFY** — Privilege on a specific warehouse that allows changing the settings that affect cost, including resizing a warehouse and\ndisabling the auto-suspend setting. Commonly, users increase the size of a warehouse for a\nparticular workload and then forget to change it back to its original size, which can have a significant effect on cost.\n**USAGE** — Privilege on a specific warehouse that allows activating the warehouse to provide compute resources for queries and other\nSQL actions. Carefully assigning this privilege ensures that users can only use warehouses with the appropriate size and configuration\nfor their workloads.\nSection Title: Cost controls for warehouses ¶ > Control access to warehouses ¶\nContent:\nCentralizing the responsibility of creating and scaling warehouses to just a few members of your team is considered a best practice. You can\ncreate a dedicated role with permissions to create and modify all warehouses, and then grant that role to a limited number of users. This\nallows you to control your warehouse policies and prevent accidental cost overruns resulting from warehouses being created or upsized\nunexpectedly.\nTip\nIf you want the ability to scale a warehouse to handle more demanding workloads, but do not want to give users the ability to increase\nthe size of a warehouse because they might forget to resize it later, consider using a multi-cluster warehouse . A multi-cluster warehouse scales automatically as workloads\nfluctuate.\nFor a list of all the privileges that can be set for a warehouse, see Virtual warehouse privileges .\n ... \nSection Title: Cost controls for warehouses ¶ > Limit query times ¶\nContent:\n```\nSHOW PARAMETERS LIKE 'STATEMENT_TIMEOUT_IN_SECONDS' IN ACCOUNT ; \n SHOW PARAMETERS LIKE 'STATEMENT_TIMEOUT_IN_SECONDS' IN USER < username >; \n SHOW PARAMETERS LIKE 'STATEMENT_TIMEOUT_IN_SECONDS' IN SESSION ; \n SHOW PARAMETERS LIKE 'STATEMENT_TIMEOUT_IN_SECONDS' IN WAREHOUSE < warehouse_name >;\n```\nCopy\nIf you need to adjust the time limits, use one of the following commands:\n```\nALTER ACCOUNT SET STATEMENT_TIMEOUT_IN_SECONDS = < number_of_seconds >; \n ALTER USER < username > SET STATEMENT_TIMEOUT_IN_SECONDS = < number_of_seconds >; \n ALTER SESSION SET STATEMENT_TIMEOUT_IN_SECONDS = < number_of_seconds >; \n ALTER WAREHOUSE < warehouse_name > SET STATEMENT_TIMEOUT_IN_SECONDS = < number_of_seconds >;\n```\nCopy\nSection Title: Cost controls for warehouses ¶ > Limit statement queue times ¶\nContent:\nSQL statements that are in a queue to use a warehouse do not consume credits. However, if a query stays in the queue too long, it might no\nlonger be relevant by the time it executes. Running a query that is no longer relevant wastes credits, so you can implement a\ncost control by setting a maximum amount of time that a SQL statement can be queued before it is cance led.\nThe parameter that controls the amount of time that a SQL statement stays in the queue is `STATEMENT_QUEUED_TIMEOUT_IN_SECONDS` . This\nparameter can be set for an entire account, a user, a session, or a specific warehouse. This parameter is set at the account level by\ndefault. When the parameter is set for a warehouse in addition to the session, the lowest non-zero value is enforced.\nUse the following commands to view the current queue time limits:\nSection Title: Cost controls for warehouses ¶ > Limit statement queue times ¶\nContent:\n```\nSHOW PARAMETERS LIKE 'STATEMENT_QUEUED_TIMEOUT_IN_SECONDS' IN ACCOUNT ; \n SHOW PARAMETERS LIKE 'STATEMENT_QUEUED_TIMEOUT_IN_SECONDS' IN USER < username >; \n SHOW PARAMETERS LIKE 'STATEMENT_QUEUED_TIMEOUT_IN_SECONDS' IN SESSION ; \n SHOW PARAMETERS LIKE 'STATEMENT_QUEUED_TIMEOUT_IN_SECONDS' IN WAREHOUSE < warehouse_name >;\n```\nCopy\nIf you need to adjust the time limits, use one of the following commands:\n```\nALTER ACCOUNT SET STATEMENT_QUEUED_TIMEOUT_IN_SECONDS = < number_of_seconds >; \n ALTER USER < username > SET STATEMENT_QUEUED_TIMEOUT_IN_SECONDS = < number_of_seconds >; \n ALTER SESSION SET STATEMENT_QUEUED_TIMEOUT_IN_SECONDS = < number_of_seconds >; \n ALTER WAREHOUSE < warehouse_name > SET STATEMENT_QUEUED_TIMEOUT_IN_SECONDS = < number_of_seconds >;\n```\nCopy\nSection Title: Cost controls for warehouses ¶ > Use auto-suspension ¶\nContent:\nBy default, all warehouses have the auto-suspend setting enabled, which means a warehouse automatically shuts down when it is inactive\nfor a defined period of time. A suspended warehouse does not consume credits, so the warehouse only incurs cost when it is processing a\nworkload.\nRestricting users from disabling the auto-suspend setting helps to prevent an unused warehouse from wasting credits. You can use access control to allow someone to use a warehouse but also prevent them from modifying its Auto\nSuspend setting.\n**Query: Find warehouses without auto-suspend**\nUse the following query to periodically check whether the auto-suspend setting was disabled for any warehouses.\n```\nSHOW WAREHOUSES \n  ->> SELECT \"name\" AS WAREHOUSE_NAME , \n             \"size\" AS WAREHOUSE_SIZE \n        FROM $ 1 \n        WHERE IFNULL ( \"auto_suspend\" , 0 ) = 0 ;\n```\nCopy\nSection Title: Cost controls for warehouses ¶ > Use auto-suspension ¶\nContent:\nTo enable auto-suspend for the warehouses that have it turned off, sign in to Snowsight . In the navigation menu, select Compute » Warehouses . You can also use the `AUTO_SUSPEND` parameter of the ALTER WAREHOUSE command.\nSection Title: Cost controls for warehouses ¶ > Use auto-suspension ¶ > Using auto-resume with auto-suspend ¶\nContent:\nIn general, every warehouse that has auto-suspend enabled should also have auto-resume enabled. The combination of these two settings\nstops and starts a warehouse automatically as the warehouse’s workload fluctuates.\n**Query: Find warehouses without Auto Resume**\nThe following query lists the warehouses that do not have auto-resume enabled, letting you know which ones need to be modified.\n```\nSHOW WAREHOUSES \n  ->> SELECT \"name\" AS WAREHOUSE_NAME , \n             \"size\" AS WAREHOUSE_SIZE \n        FROM $ 1 \n        WHERE \"auto_resume\" = 'false' ;\n```\nCopy\nTo enable auto-resume for the warehouses that have it turned off, sign in to Snowsight . In the navigation menu, select Compute » Warehouses . You can also use the `AUTO_RESUME` parameter of the ALTER WAREHOUSE command.\nSection Title: Cost controls for warehouses ¶ > Enforce spending limits ¶\nContent:\n*Resource monitors* provide the ability to set limits on credits consumed by a warehouse during a specific time interval or date range.\nThis can help prevent warehouses from unintentionally consuming more credits than typically expected.\nSometimes a resource monitor simply notifies an administrator when a credit limit is reached, but you can also *enforce* a limit by\nconfiguring a resource monitor to suspend a warehouse as soon as the limit is reached. There are two options when enforcing a limit: suspend\nthe warehouse after pending statements are executed or suspend immediately without waiting for statements to complete.\n ... \nSection Title: Cost controls for warehouses ¶ > Enforce spending limits ¶\nContent:\n```\nSHOW WAREHOUSES \n  ->> SELECT \"name\" AS WAREHOUSE_NAME , \n             \"size\" AS WAREHOUSE_SIZE \n        FROM $ 1 \n        WHERE \"resource_monitor\" = 'null' ;\n```\nCopy\nNote\nThe cloud services layer of the Snowflake architecture can still incur a small cost if queries are run against a warehouse that was\nsuspended by a resource monitor.\nWas this page helpful?\nYes No\n[Visit Snowflake](https://www.snowflake.com)\n[Join the conversation](https://community.snowflake.com/s/)\n[Develop with Snowflake](https://developers.snowflake.com)\nShare your feedback\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n[Get your own certification](https://learn.snowflake.com)\nOn this page\nControl access to warehouses\nLimit query times\nLimit statement queue times\nUse auto-suspension\nEnforce spending limits\nRelated content\nManaging cost in Snowflake"],"full_content":"Guides Cost & Billing Control Cost controls for warehouses\n\n# Cost controls for warehouses ¶\n\nThis topic discusses _controls_ that you can use to limit how much is spent on virtual warehouse usage. These controls help ensure that the actual cost of using virtual warehouses does not exceed expected cost.\n\nThese controls do not apply to cloud services and serverless features .\n\n## Control access to warehouses ¶\n\nCarefully defining who can work with warehouses and what they can do with those warehouses helps control cost by limiting compute resource\nusage to known warehouses that have cost-effective configurations. Snowflake’s granular access control allows you to grant the following privileges for warehouses:\n\n* **CREATE WAREHOUSE** — Global privilege (i.e. granted on the account) that restricts which roles can create a new warehouse, allowing\n  you to force individuals to use existing warehouses that have cost controls in place.\n* **MODIFY** — Privilege on a specific warehouse that allows changing the settings that affect cost, including resizing a warehouse and\n  disabling the auto-suspend setting. Commonly, users increase the size of a warehouse for a\n  particular workload and then forget to change it back to its original size, which can have a significant effect on cost.\n* **USAGE** — Privilege on a specific warehouse that allows activating the warehouse to provide compute resources for queries and other\n  SQL actions. Carefully assigning this privilege ensures that users can only use warehouses with the appropriate size and configuration\n  for their workloads.\n\nCentralizing the responsibility of creating and scaling warehouses to just a few members of your team is considered a best practice. You can\ncreate a dedicated role with permissions to create and modify all warehouses, and then grant that role to a limited number of users. This\nallows you to control your warehouse policies and prevent accidental cost overruns resulting from warehouses being created or upsized\nunexpectedly.\n\nTip\n\nIf you want the ability to scale a warehouse to handle more demanding workloads, but do not want to give users the ability to increase\nthe size of a warehouse because they might forget to resize it later, consider using a multi-cluster warehouse . A multi-cluster warehouse scales automatically as workloads\nfluctuate.\n\nFor a list of all the privileges that can be set for a warehouse, see Virtual warehouse privileges .\n\n## Limit query times ¶\n\nHung queries consume excessive credits because they run longer than expected. To avoid the excess cost associated with a\nrunaway query, you can set the `STATEMENT_TIMEOUT_IN_SECONDS` parameter to define the maximum amount of time a SQL statement can run\nbefore it is cancelled.\n\nThe `STATEMENT_TIMEOUT_IN_SECONDS` parameter can be set for an entire account, a user, a session, or a specific warehouse so that you can\ncarefully set time limits that match the expected run times for various workloads. This parameter is set at the account level by default.\nWhen the parameter is set for a warehouse in addition to the session, the lowest non-zero value is enforced.\n\nUse the following commands to view the current query time limits:\n\n```\nSHOW PARAMETERS LIKE 'STATEMENT_TIMEOUT_IN_SECONDS' IN ACCOUNT ; \n SHOW PARAMETERS LIKE 'STATEMENT_TIMEOUT_IN_SECONDS' IN USER < username >; \n SHOW PARAMETERS LIKE 'STATEMENT_TIMEOUT_IN_SECONDS' IN SESSION ; \n SHOW PARAMETERS LIKE 'STATEMENT_TIMEOUT_IN_SECONDS' IN WAREHOUSE < warehouse_name >;\n```\n\nCopy\n\nIf you need to adjust the time limits, use one of the following commands:\n\n```\nALTER ACCOUNT SET STATEMENT_TIMEOUT_IN_SECONDS = < number_of_seconds >; \n ALTER USER < username > SET STATEMENT_TIMEOUT_IN_SECONDS = < number_of_seconds >; \n ALTER SESSION SET STATEMENT_TIMEOUT_IN_SECONDS = < number_of_seconds >; \n ALTER WAREHOUSE < warehouse_name > SET STATEMENT_TIMEOUT_IN_SECONDS = < number_of_seconds >;\n```\n\nCopy\n\n## Limit statement queue times ¶\n\nSQL statements that are in a queue to use a warehouse do not consume credits. However, if a query stays in the queue too long, it might no\nlonger be relevant by the time it executes. Running a query that is no longer relevant wastes credits, so you can implement a\ncost control by setting a maximum amount of time that a SQL statement can be queued before it is cance led.\n\nThe parameter that controls the amount of time that a SQL statement stays in the queue is `STATEMENT_QUEUED_TIMEOUT_IN_SECONDS` . This\nparameter can be set for an entire account, a user, a session, or a specific warehouse. This parameter is set at the account level by\ndefault. When the parameter is set for a warehouse in addition to the session, the lowest non-zero value is enforced.\n\nUse the following commands to view the current queue time limits:\n\n```\nSHOW PARAMETERS LIKE 'STATEMENT_QUEUED_TIMEOUT_IN_SECONDS' IN ACCOUNT ; \n SHOW PARAMETERS LIKE 'STATEMENT_QUEUED_TIMEOUT_IN_SECONDS' IN USER < username >; \n SHOW PARAMETERS LIKE 'STATEMENT_QUEUED_TIMEOUT_IN_SECONDS' IN SESSION ; \n SHOW PARAMETERS LIKE 'STATEMENT_QUEUED_TIMEOUT_IN_SECONDS' IN WAREHOUSE < warehouse_name >;\n```\n\nCopy\n\nIf you need to adjust the time limits, use one of the following commands:\n\n```\nALTER ACCOUNT SET STATEMENT_QUEUED_TIMEOUT_IN_SECONDS = < number_of_seconds >; \n ALTER USER < username > SET STATEMENT_QUEUED_TIMEOUT_IN_SECONDS = < number_of_seconds >; \n ALTER SESSION SET STATEMENT_QUEUED_TIMEOUT_IN_SECONDS = < number_of_seconds >; \n ALTER WAREHOUSE < warehouse_name > SET STATEMENT_QUEUED_TIMEOUT_IN_SECONDS = < number_of_seconds >;\n```\n\nCopy\n\n## Use auto-suspension ¶\n\nBy default, all warehouses have the auto-suspend setting enabled, which means a warehouse automatically shuts down when it is inactive\nfor a defined period of time. A suspended warehouse does not consume credits, so the warehouse only incurs cost when it is processing a\nworkload.\n\nRestricting users from disabling the auto-suspend setting helps to prevent an unused warehouse from wasting credits. You can use access control to allow someone to use a warehouse but also prevent them from modifying its Auto\nSuspend setting.\n\n**Query: Find warehouses without auto-suspend**\n\nUse the following query to periodically check whether the auto-suspend setting was disabled for any warehouses.\n\n```\nSHOW WAREHOUSES \n  ->> SELECT \"name\" AS WAREHOUSE_NAME , \n             \"size\" AS WAREHOUSE_SIZE \n        FROM $ 1 \n        WHERE IFNULL ( \"auto_suspend\" , 0 ) = 0 ;\n```\n\nCopy\n\nTo enable auto-suspend for the warehouses that have it turned off, sign in to Snowsight . In the navigation menu, select Compute » Warehouses . You can also use the `AUTO_SUSPEND` parameter of the ALTER WAREHOUSE command.\n\n### Using auto-resume with auto-suspend ¶\n\nIn general, every warehouse that has auto-suspend enabled should also have auto-resume enabled. The combination of these two settings\nstops and starts a warehouse automatically as the warehouse’s workload fluctuates.\n\n**Query: Find warehouses without Auto Resume**\n\nThe following query lists the warehouses that do not have auto-resume enabled, letting you know which ones need to be modified.\n\n```\nSHOW WAREHOUSES \n  ->> SELECT \"name\" AS WAREHOUSE_NAME , \n             \"size\" AS WAREHOUSE_SIZE \n        FROM $ 1 \n        WHERE \"auto_resume\" = 'false' ;\n```\n\nCopy\n\nTo enable auto-resume for the warehouses that have it turned off, sign in to Snowsight . In the navigation menu, select Compute » Warehouses . You can also use the `AUTO_RESUME` parameter of the ALTER WAREHOUSE command.\n\n## Enforce spending limits ¶\n\n_Resource monitors_ provide the ability to set limits on credits consumed by a warehouse during a specific time interval or date range.\nThis can help prevent warehouses from unintentionally consuming more credits than typically expected.\n\nSometimes a resource monitor simply notifies an administrator when a credit limit is reached, but you can also _enforce_ a limit by\nconfiguring a resource monitor to suspend a warehouse as soon as the limit is reached. There are two options when enforcing a limit: suspend\nthe warehouse after pending statements are executed or suspend immediately without waiting for statements to complete.\n\nBecause a single resource monitor can be set for multiple warehouses or an entire account, you can effectively suspend multiple warehouses\nwhen an overall spending limit is reached. A warehouse can be assigned to its own resource monitor and an account-specific resource monitor\nat the same time; the warehouse is suspended when either of the credit limits is reached.\n\nFor more information about suspending warehouses when spending limits are reached, see Working with resource monitors .\n\n**Query: Find warehouses without resource monitors**\n\nThe following query lists the warehouses that aren’t assigned to a warehouse-specific resource monitor, which makes them vulnerable\nto runaway costs. The query doesn’t check for account-level resource monitors; warehouses in the list that belong to an account\nthat has an account-level resource monitor are still subject to credit limits.\n\n```\nSHOW WAREHOUSES \n  ->> SELECT \"name\" AS WAREHOUSE_NAME , \n             \"size\" AS WAREHOUSE_SIZE \n        FROM $ 1 \n        WHERE \"resource_monitor\" = 'null' ;\n```\n\nCopy\n\nNote\n\nThe cloud services layer of the Snowflake architecture can still incur a small cost if queries are run against a warehouse that was\nsuspended by a resource monitor.\n\nWas this page helpful?\n\nYes No\n\n[Visit Snowflake](https://www.snowflake.com)\n\n[Join the conversation](https://community.snowflake.com/s/)\n\n[Develop with Snowflake](https://developers.snowflake.com)\n\nShare your feedback\n\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n\n[Get your own certification](https://learn.snowflake.com)\n\nOn this page\n\n1. Control access to warehouses\n2. Limit query times\n3. Limit statement queue times\n4. Use auto-suspension\n5. Enforce spending limits\n\nRelated content\n\n1. Managing cost in Snowflake"},{"url":"https://docs.snowflake.com/en/user-guide/alerts","title":"Setting up alerts based on data in Snowflake | Snowflake Documentation","publish_date":null,"excerpts":["Guides Alerts & Notifications Snowflake Alerts\nSection Title: Setting up alerts based on data in Snowflake ¶\nContent:\nThis topic explains how to set up an alert that periodically performs an action under specific conditions, based on data within\nSnowflake.\nSection Title: Setting up alerts based on data in Snowflake ¶ > Introduction ¶\nContent:\nIn some cases, you might want to be notified or take action when data in Snowflake meets certain conditions. For example, you\nmight want to receive a notification when:\nThe warehouse credit usage increases by a specified percentage of your current quota.\nThe resource consumption for your pipelines, tasks, materialized views, etc. increases beyond a specified amount.\nYour data fails to comply with a particular business rule that you have set up.\nTo do this, you can set up a Snowflake alert. A Snowflake alert is a schema-level object that specifies:\nA condition that triggers the alert (e.g. the presence of queries that take longer than a second to complete).\nThe action to perform when the condition is met (e.g. send an email notification, capture some data in a table, etc.).\nWhen and how often the condition should be evaluated (e.g. every 24 hours, every Sunday at midnight, etc.).\nSection Title: Setting up alerts based on data in Snowflake ¶ > Introduction ¶\nContent:\nFor example, suppose that you want to send an email notification when the credit consumption exceeds a certain limit for a\nwarehouse. Suppose that you want to check for this every 30 minutes. You can create an alert with the following properties:\nCondition: The credit consumption for a warehouse (the sum of the `credits_used` column in the WAREHOUSE_METERING_HISTORY view in the ACCOUNT_USAGE ) schema exceeds a specified limit.\nAction: Email the administrator.\nFrequency / schedule: Check for this condition every 30 minutes.\nSection Title: Setting up alerts based on data in Snowflake ¶ > Choosing the type of alert ¶\nContent:\nYou can create the following types of alerts:\nAlert on a schedule : Snowflake evaluates the condition against the existing data on a\nscheduled basis.For example, you can set up a alert on a schedule to check if any of the existing rows in a table has a column value that\nexceeds a specified amount.\nAlert on new data : Snowflake evaluates the condition against any new rows in a specified\ntable or a view.For example, you can set up an alert on new data to notify you when new rows for error messages are inserted into the event table for your account. Because dynamic table refreshes\nand task executions log events to the event table, you can set up an alert on new data to:\nMonitor dynamic table refreshes .\nMonitor task executions .\nSection Title: Setting up alerts based on data in Snowflake ¶ > ... > Alerts on a schedule ¶\nContent:\nWith an alert on a schedule, you can set up an alert to execute every `_n_` minutes or on a schedule specified by a cron\nexpression.\nThe condition of the alert is evaluated on all of the data (as opposed to alerts on new data, where conditions are evaluated\nagainst only the new rows that have been inserted).\n ... \nSection Title: Setting up alerts based on data in Snowflake ¶ > Choosing the warehouse for the alerts ¶\nContent:\nAn alert requires a warehouse for execution. You can either use the serverless compute model or a virtual warehouse that you specify .\nSection Title: ... > Using the serverless compute model (serverless alerts) ¶\nContent:\nAlerts that use the serverless compute model called *serverless alerts* . If you use the serverless compute model, Snowflake\nautomatically resizes and scales the compute resources required for the alert. Snowflake determines the ideal size of the compute\nresources for a given run based on a dynamic analysis of statistics for the most recent previous runs of the same alert. The\nmaximum size for a serverless alert run is equivalent to an XXLARGE warehouse. Multiple workloads in your account share a common\nset of compute resources.\nBilling is similar to other serverless features (such as serverless tasks). See Understanding the costs of alerts .\nNote\nIf you are creating an alert on new data that is added infrequently, consider\nconfiguring this as a serverless alert. If you configure the alert to use a warehouse instead, even a simple action that sends\nan email notification incurs at least one minute of warehouse cost.\nSection Title: Setting up alerts based on data in Snowflake ¶ > ... > Using a virtual warehouse that you specify ¶\nContent:\nIf you want to specify a virtual warehouse, you must choose a warehouse that is sized appropriately for the SQL actions that\nare executed by the alert. For guidelines on choosing a warehouse, see Warehouse considerations .\nSection Title: Setting up alerts based on data in Snowflake ¶ > Understanding the costs of alerts ¶\nContent:\nThe costs associated with running an alert to execute SQL code differ depending on the compute resources used for the alert:\nSection Title: Setting up alerts based on data in Snowflake ¶ > Understanding the costs of alerts ¶\nContent:\nFor serverless alerts, Snowflake bills your account based on compute resource usage. Charges are calculated based on your\ntotal usage of the resources, including cloud service usage, measured in *compute-hours* credit usage. The compute-hours cost\nchanges based on warehouse size and query runtime. For more information, see Serverless credit usage .To learn how many credits are consumed by alerts, refer to the “Serverless Feature Credit Table” in\nthe [Snowflake Service Consumption Table](https://www.snowflake.com/legal-files/CreditConsumptionTable.pdf) .To view the usage history of serverless alerts, you can:\nCall the SERVERLESS_ALERT_HISTORY function. Query the SERVERLESS_ALERT_HISTORY view . For alerts that use a virtual warehouse that you specify, Snowflake bills your account for credit usage based on the warehouse usage when an alert is running.\nSection Title: Setting up alerts based on data in Snowflake ¶ > Understanding the costs of alerts ¶\nContent:\nThis is\nsimilar to the warehouse usage for executing the same SQL statements in a client or Snowsight. Per-second credit\nbilling and warehouse auto-suspend give you the flexibility to start with larger warehouse sizes and then adjust the size to\nmatch your alert workloads.\nSection Title: Setting up alerts based on data in Snowflake ¶ > Understanding the costs of alerts ¶\nContent:\nTip\nIf you want to set up an alert that evaluates new rows added to a table or view, use an alert on new data , rather than an alert on a schedule. An alert on a schedule will\nexecute at a scheduled time, regardless of whether or not new rows have been inserted.\nSection Title: Setting up alerts based on data in Snowflake ¶ > Granting the privileges to create alerts ¶\nContent:\nIn order to create an alert, you must use a role that has the following privileges:\nThe EXECUTE ALERT privilege on the account.NoteThis privilege can only be granted by a user with the ACCOUNTADMIN role.\nOne of the following privileges:\nThe EXECUTE MANAGED ALERT privilege on the account, if you are creating a serverless alert.\nThe USAGE privilege on the warehouse used to execute the alert, if you are specifying a virtual warehouse for the alert.\nThe USAGE and CREATE ALERT privileges on the schema in which you want to create the alert.\nThe USAGE privilege on the database containing the schema.\nThe SELECT privilege on the table or view that you want to query in the alert condition (if you are creating an alert on new data ).\nTo grant these privileges to a role, use the GRANT  … TO ROLE command.\nSection Title: Setting up alerts based on data in Snowflake ¶ > Granting the privileges to create alerts ¶\nContent:\nFor example, suppose that you want to create a custom role named `my_alert_role` that has the privileges to create an alert in\nthe schema named `my_schema` . You want the alert to use the warehouse `my_warehouse` .\nTo do this:\nSection Title: Setting up alerts based on data in Snowflake ¶ > Granting the privileges to create alerts ¶\nContent:\nHave a user with the ACCOUNTADMIN role do the following:\nCreate the custom role .For example:Copy\nGrant the EXECUTE ALERT global privilege to that custom role.For example:Copy\nIf you want to create a serverless alert, grant the EXECUTE MANAGED ALERT global privilege to that custom role.For example:Copy\nGrant the custom role to a user.For example:Copy\nHave the owners of the database, schema, and warehouse grant the privileges needed for creating the alert to the custom role:\nThe owner of the schema must grant the CREATE ALERT and USAGE privileges on the schema:Copy\nThe owner of the database must grant the USAGE privilege on the database:Copy\nIf you want to specify a warehouse for the alert, the owner of that warehouse must grant the USAGE privilege on the\nwarehouse:Copy\nSection Title: Setting up alerts based on data in Snowflake ¶ > Creating an alert ¶\nContent:\nThe following sections provide the basic steps and an example of creating different types of alerts:\nCreating an alert on a schedule\nCreating an alert on new data\n ... \nSection Title: Setting up alerts based on data in Snowflake ¶ > ... > Creating an alert on a schedule ¶\nContent:\nVerify that you are using a role that has the privileges to create an alert .If you are not using that role, execute the USE ROLE command to use that role.\nVerify that you are using the database and schema in which you plan to create the alert.If you are not using that database and schema, execute the USE DATABASE and USE SCHEMA commands to use that database and schema.\nExecute the CREATE ALERT command to create the alert:CopyIf you want to create a serverless alert, omit the WAREHOUSE parameter:CopyFor the full description of the CREATE ALERT command, refer to CREATE ALERT .NoteWhen you create an alert, the alert is suspended by default. You must resume the newly created alert in order for the alert\nto execute.\nResume the alert by executing the ALTER ALERT … RESUME command. For example:Copy\nSection Title: Setting up alerts based on data in Snowflake ¶ > ... > Creating an alert on new data ¶\nContent:\nSuppose that you want to receive an email notification when a stored procedure named `my_stored_proc` in the database and\nschema `my_db.my_schema` logs a FATAL message to the active event table for your account .\nTo create an alert named `my_alert` that does this:\n ... \nSection Title: Setting up alerts based on data in Snowflake ¶ > ... > Creating an alert on new data ¶\nContent:\nThe example assumes the following:CopyIf you want to create a serverless alert, omit the WAREHOUSE parameter:CopyFor the full description of the CREATE ALERT command, refer to CREATE ALERT .NoteWhen you create an alert, the alert is suspended by default. You must resume the newly created alert in order for the alert\nto execute. Your active event table is the default event table (SNOWFLAKE.TELEMETRY.EVENTS). You have set the severity level to capture events for your dynamic\ntable. You have set up a webhook notification integration for that Slack\nchannel. Resume the alert by executing the ALTER ALERT … RESUME command. For example:Copy\n ... \nSection Title: Setting up alerts based on data in Snowflake ¶ > Specifying timestamps based on alert schedules ¶\nContent:\nSCHEDULED_TIME returns the timestamp representing when the current alert was scheduled.\nLAST_SUCCESSFUL_SCHEDULED_TIME returns the timestamp representing when the last successfully\nevaluated alert was scheduled.\nThese functions are defined in the SNOWFLAKE.ALERT schema . To call these functions, you need\nto use a role that has been granted the SNOWFLAKE.ALERT_VIEWER database role . To\ngrant this role to another role, use the GRANT DATABASE ROLE command. For example, to grant this role\nto the custom role `alert_role` , execute:\n```\nGRANT DATABASE ROLE SNOWFLAKE . ALERT_VIEWER TO ROLE alert_role ;\n```\nCopy\nThe following example sends an email message if any new rows were added to `my_table` between the time that the last\nsuccessfully evaluated alert was scheduled and the time when the current alert has been scheduled:\nSection Title: Setting up alerts based on data in Snowflake ¶ > Specifying timestamps based on alert schedules ¶\nContent:\n```\nCREATE OR REPLACE ALERT alert_new_rows \n  WAREHOUSE = my_warehouse \n  SCHEDULE = '1 MINUTE' \n  IF ( EXISTS ( \n      SELECT * \n      FROM my_table \n      WHERE row_timestamp BETWEEN SNOWFLAKE.ALERT.LAST_SUCCESSFUL_SCHEDULED_TIME () \n       AND SNOWFLAKE.ALERT.SCHEDULED_TIME () \n  )) \n  THEN CALL SYSTEM$SEND_EMAIL (...);\n```\nCopy\nSection Title: ... > Checking the results of the SQL statement for the condition in the alert action ¶\nContent:\nWithin the action of an alert, if you need to check the results of the SQL statement for the condition:\nCall the GET_CONDITION_QUERY_UUID function to get the query ID for the SQL statement for the\ncondition.\nPass the query ID to the RESULT_SCAN function to get the results of the execution of that SQL\nstatement.\nFor example:\n```\nCREATE ALERT my_alert \n  WAREHOUSE = my_warehouse \n  SCHEDULE = '1 MINUTE' \n  IF ( EXISTS ( \n    SELECT * FROM my_source_table )) \n  THEN \n    BEGIN \n      LET condition_result_set RESULTSET := \n        ( SELECT * FROM TABLE ( RESULT_SCAN ( SNOWFLAKE.ALERT.GET_CONDITION_QUERY_UUID ()))); \n      ... \n    END ;\n```\nCopy\nSection Title: Setting up alerts based on data in Snowflake ¶ > Manually executing alerts ¶\nContent:\nIn some cases, you might need to execute an alert manually. For example:\nIf you are creating a new alert, you might want to verify that the alert works as you would expect.\nYou might want to execute the alert at a specific point in your data pipeline. For example, you might want to execute the\nalert at the end of a stored procedure call.\nTo execute an alert manually, run the EXECUTE ALERT command:\n```\nEXECUTE ALERT my_alert ;\n```\nCopy\nNote\nYou cannot use EXECUTE ALERT to execute an alert on new data .\nThe EXECUTE ALERT command manually triggers a single run of an alert, independent of the schedule defined for the alert.\nYou can execute this command interactively. You can also execute this command from within a stored procedure or a Snowflake\nScripting block.\nFor details on the privileges required to run this command and the effect of this command on suspended, running, and scheduled\nalerts, see EXECUTE ALERT .\nSection Title: Setting up alerts based on data in Snowflake ¶ > Suspending and resuming an alert ¶\nContent:\nIf you need to prevent an alert from executing temporarily, you can suspend the alert by executing the ALTER ALERT … SUSPEND command. For example:\n```\nALTER ALERT my_alert SUSPEND ;\n```\nCopy\nTo resume a suspended alert, execute the ALTER ALERT … RESUME command. For example:\n```\nALTER ALERT my_alert RESUME ;\n```\nCopy\nNote\nIf you are not the owner of the alert, you must have the OPERATE privilege on the alert to suspend or resume the alert.\nSection Title: Setting up alerts based on data in Snowflake ¶ > Modifying an alert ¶\nContent:\nTo modify the properties of an alert, execute the ALTER ALERT command.\nNote\nYou must be the owner of the alert to modify the properties of the alert.\nYou cannot change an alert on new data to an alert on a schedule . Similarly, you cannot change an alert on a schedule to an alert\non new data.\nFor example:\nTo change the warehouse for the alert named `my_alert` to `my_other_warehouse` , execute:Copy\nTo change the schedule for the alert named `my_alert` to be evaluated every 2 minutes, execute:Copy\nTo change the condition for the alert named `my_alert` so that you are alerted if any rows in the table named `gauge` have\nvalues greater than `300` in the `gauge_value` column, execute:Copy\nTo change the action for the alert named `my_alert` to `CALL my_procedure()` , execute:Copy\nSection Title: Setting up alerts based on data in Snowflake ¶ > Dropping an alert ¶\nContent:\nTo drop an alert, execute the DROP ALERT command. For example:\n```\nDROP ALERT my_alert ;\n```\nCopy\nTo drop an alert without raising an error if the alert does not exist, execute:\n```\nDROP ALERT IF EXISTS my_alert ;\n```\nCopy\nNote\nYou must be the owner of the alert to drop the alert.\nSection Title: Setting up alerts based on data in Snowflake ¶ > Viewing details about an alert ¶\nContent:\nTo list the alerts that have been created in an account, database, or schema, execute the SHOW ALERTS command. For example, to list the alerts that were created in the current schema, run the following command:\n```\nSHOW ALERTS ;\n```\nCopy\nThis command lists the alerts that you own and the alerts that you have the MONITOR or OPERATE privilege on.\nTo view the details about a specific alert, execute the DESCRIBE ALERT command. For example:\n```\nDESC ALERT my_alert ;\n```\nCopy\nNote\nIf you are not the owner of the alert, you must have the MONITOR or OPERATE privilege on the alert to view the details of the\nalert.\nSection Title: Setting up alerts based on data in Snowflake ¶ > Cloning an alert ¶\nContent:\nYou can clone an alert (either by using CREATE ALERT … CLONE or by cloning the\ndatabase or schema containing the alert).\nIf you are cloning a serverless alert, you don’t need to use a role that has the global EXECUTE MANAGED ALERT privilege. However,\nyou will not be able to resume that alert until the role that owns the alert has been granted the EXECUTE MANAGED ALERT privilege.\nSection Title: Setting up alerts based on data in Snowflake ¶ > Monitoring the execution of alerts ¶\nContent:\nTo monitor the execution of the alerts, you can:\nCheck the results of the action that was specified for the alert. For example, if the action inserted rows into a table, you can\ncheck the table for new rows.\nView the history of alert executions by using one of the following:\nThe ALERT_HISTORY table function in the INFORMATION_SCHEMA schema.For example, to view the executions of alerts over the past hour, execute the following statement:Copy\nThe ALERT_HISTORY view in the ACCOUNT_USAGE schema in the shared\nSNOWFLAKE database.\nIn the query history, the name of the user who executed the query will be SYSTEM. (The alerts are run by the system service .)\nSection Title: Setting up alerts based on data in Snowflake ¶ > Viewing the query history of a serverless alert ¶\nContent:\nTo view the query history of a serverless alert, you must be the owner of the alert, or you must use a role that has the\nMONITOR or OPERATE privilege on the alert itself. (This differs from alerts that use one your warehouses, which require the\nMONITOR or OPERATOR privilege on the warehouse.)\nFor example, suppose that you want to use the `my_alert_role` role when viewing the query history of the alert `my_alert` .\nIf `my_alert_role` is not the owner of `my_alert` , you must grant that role the\nMONITOR or OPERATE privilege on the alert:\n```\nGRANT MONITOR ON ALERT my_alert TO ROLE my_alert_role ;\n```\nCopy\nAfter the role is granted this privilege, you can use the role to view the query history of the alert:\n```\nUSE ROLE my_alert_role ;\n```\nCopy\nSection Title: Setting up alerts based on data in Snowflake ¶ > Viewing the query history of a serverless alert ¶\nContent:\n```\nSELECT query_text FROM TABLE ( INFORMATION_SCHEMA . QUERY_HISTORY ()) \n  WHERE query_text LIKE '%Some condition%' \n    OR query_text LIKE '%Some action%' \n  ORDER BY start_time DESC ;\n```\nCopy\nWas this page helpful?\nYes No\n[Visit Snowflake](https://www.snowflake.com)\n[Join the conversation](https://community.snowflake.com/s/)\n[Develop with Snowflake](https://developers.snowflake.com)\nShare your feedback\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n[Get your own certification](https://learn.snowflake.com)"],"full_content":"Guides Alerts & Notifications Snowflake Alerts\n\n# Setting up alerts based on data in Snowflake ¶\n\nThis topic explains how to set up an alert that periodically performs an action under specific conditions, based on data within\nSnowflake.\n\n## Introduction ¶\n\nIn some cases, you might want to be notified or take action when data in Snowflake meets certain conditions. For example, you\nmight want to receive a notification when:\n\n* The warehouse credit usage increases by a specified percentage of your current quota.\n* The resource consumption for your pipelines, tasks, materialized views, etc. increases beyond a specified amount.\n* Your data fails to comply with a particular business rule that you have set up.\n\nTo do this, you can set up a Snowflake alert. A Snowflake alert is a schema-level object that specifies:\n\n* A condition that triggers the alert (e.g. the presence of queries that take longer than a second to complete).\n* The action to perform when the condition is met (e.g. send an email notification, capture some data in a table, etc.).\n* When and how often the condition should be evaluated (e.g. every 24 hours, every Sunday at midnight, etc.).\n\nFor example, suppose that you want to send an email notification when the credit consumption exceeds a certain limit for a\nwarehouse. Suppose that you want to check for this every 30 minutes. You can create an alert with the following properties:\n\n* Condition: The credit consumption for a warehouse (the sum of the `credits_used` column in the WAREHOUSE\\_METERING\\_HISTORY view in the ACCOUNT\\_USAGE ) schema exceeds a specified limit.\n* Action: Email the administrator.\n* Frequency / schedule: Check for this condition every 30 minutes.\n\n## Choosing the type of alert ¶\n\nYou can create the following types of alerts:\n\n* Alert on a schedule : Snowflake evaluates the condition against the existing data on a\n  scheduled basis.\n  \n  For example, you can set up a alert on a schedule to check if any of the existing rows in a table has a column value that\n  exceeds a specified amount.\n* Alert on new data : Snowflake evaluates the condition against any new rows in a specified\n  table or a view.\n  \n  For example, you can set up an alert on new data to notify you when new rows for error messages are inserted into the event table for your account. Because dynamic table refreshes\n  and task executions log events to the event table, you can set up an alert on new data to:\n  \n    + Monitor dynamic table refreshes .\n    + Monitor task executions .\n\n### Alerts on a schedule ¶\n\nWith an alert on a schedule, you can set up an alert to execute every `_n_` minutes or on a schedule specified by a cron\nexpression.\n\nThe condition of the alert is evaluated on all of the data (as opposed to alerts on new data, where conditions are evaluated\nagainst only the new rows that have been inserted).\n\n### Alerts on new data ¶\n\nWith an alert on new data, you can set up an alert to execute only when new rows are inserted in a table or are made available\nin a view.\n\nWhenever new rows are inserted, the alert executes, evaluating the condition against just the new rows, and performing the action\nif the condition evaluates to TRUE.\n\nIf you want to evaluate a condition on newly inserted rows, use an alert on new data, rather than setting up an alert on a\nschedule (which executes on a fixed schedule, regardless of whether or not data has been added).\n\nBecause the alert operates only on newly inserted rows in a table or view, there are restrictions on the condition that you can\nspecify:\n\n* In the SELECT statement, the FROM clause can specify only one regular table, view, or event table.\n* You must enable change tracking on that table or view.\n* You cannot use:\n  \n    + Common table expressions (CTEs)\n    + Data Manipulation Language (DML) commands\n    + Calls to stored procedures\n    + Joins\n\nNote\n\nYou cannot use the EXECUTE ALERT command to execute an alert on new data.\n\n## Choosing the warehouse for the alerts ¶\n\nAn alert requires a warehouse for execution. You can either use the serverless compute model or a virtual warehouse that you specify .\n\n### Using the serverless compute model (serverless alerts) ¶\n\nAlerts that use the serverless compute model called _serverless alerts_ . If you use the serverless compute model, Snowflake\nautomatically resizes and scales the compute resources required for the alert. Snowflake determines the ideal size of the compute\nresources for a given run based on a dynamic analysis of statistics for the most recent previous runs of the same alert. The\nmaximum size for a serverless alert run is equivalent to an XXLARGE warehouse. Multiple workloads in your account share a common\nset of compute resources.\n\nBilling is similar to other serverless features (such as serverless tasks). See Understanding the costs of alerts .\n\nNote\n\nIf you are creating an alert on new data that is added infrequently, consider\nconfiguring this as a serverless alert. If you configure the alert to use a warehouse instead, even a simple action that sends\nan email notification incurs at least one minute of warehouse cost.\n\n### Using a virtual warehouse that you specify ¶\n\nIf you want to specify a virtual warehouse, you must choose a warehouse that is sized appropriately for the SQL actions that\nare executed by the alert. For guidelines on choosing a warehouse, see Warehouse considerations .\n\n## Understanding the costs of alerts ¶\n\nThe costs associated with running an alert to execute SQL code differ depending on the compute resources used for the alert:\n\n* For serverless alerts, Snowflake bills your account based on compute resource usage. Charges are calculated based on your\n  total usage of the resources, including cloud service usage, measured in _compute-hours_ credit usage. The compute-hours cost\n  changes based on warehouse size and query runtime. For more information, see Serverless credit usage .\n  \n  To learn how many credits are consumed by alerts, refer to the “Serverless Feature Credit Table” in\n  the [Snowflake Service Consumption Table](https://www.snowflake.com/legal-files/CreditConsumptionTable.pdf) .\n  \n  To view the usage history of serverless alerts, you can:\n  \n    + Call the SERVERLESS\\_ALERT\\_HISTORY function.\n    + Query the SERVERLESS\\_ALERT\\_HISTORY view .\n* For alerts that use a virtual warehouse that you specify, Snowflake bills your account for credit usage based on the warehouse usage when an alert is running. This is\n  similar to the warehouse usage for executing the same SQL statements in a client or Snowsight. Per-second credit\n  billing and warehouse auto-suspend give you the flexibility to start with larger warehouse sizes and then adjust the size to\n  match your alert workloads.\n\nTip\n\nIf you want to set up an alert that evaluates new rows added to a table or view, use an alert on new data , rather than an alert on a schedule. An alert on a schedule will\nexecute at a scheduled time, regardless of whether or not new rows have been inserted.\n\n## Granting the privileges to create alerts ¶\n\nIn order to create an alert, you must use a role that has the following privileges:\n\n* The EXECUTE ALERT privilege on the account.\n  \n  Note\n  \n  This privilege can only be granted by a user with the ACCOUNTADMIN role.\n* One of the following privileges:\n  \n    + The EXECUTE MANAGED ALERT privilege on the account, if you are creating a serverless alert.\n    + The USAGE privilege on the warehouse used to execute the alert, if you are specifying a virtual warehouse for the alert.\n* The USAGE and CREATE ALERT privileges on the schema in which you want to create the alert.\n* The USAGE privilege on the database containing the schema.\n* The SELECT privilege on the table or view that you want to query in the alert condition (if you are creating an alert on new data ).\n\nTo grant these privileges to a role, use the GRANT <privileges> … TO ROLE command.\n\nFor example, suppose that you want to create a custom role named `my_alert_role` that has the privileges to create an alert in\nthe schema named `my_schema` . You want the alert to use the warehouse `my_warehouse` .\n\nTo do this:\n\n1. Have a user with the ACCOUNTADMIN role do the following:\n   \n    1. Create the custom role .\n          \n          For example:\n          \n          ```\n          USE ROLE ACCOUNTADMIN ; \n          \n           CREATE ROLE my_alert_role ;\n          ```\n          \n          Copy\n    2. Grant the EXECUTE ALERT global privilege to that custom role.\n          \n          For example:\n          \n          ```\n          GRANT EXECUTE ALERT ON ACCOUNT TO ROLE my_alert_role ;\n          ```\n          \n          Copy\n    3. If you want to create a serverless alert, grant the EXECUTE MANAGED ALERT global privilege to that custom role.\n          \n          For example:\n          \n          ```\n          GRANT EXECUTE MANAGED ALERT ON ACCOUNT TO ROLE my_alert_role ;\n          ```\n          \n          Copy\n    4. Grant the custom role to a user.\n          \n          For example:\n          \n          ```\n          GRANT ROLE my_alert_role TO USER my_user ;\n          ```\n          \n          Copy\n2. Have the owners of the database, schema, and warehouse grant the privileges needed for creating the alert to the custom role:\n   \n    + The owner of the schema must grant the CREATE ALERT and USAGE privileges on the schema:\n         \n         ```\n         GRANT CREATE ALERT ON SCHEMA my_schema TO ROLE my_alert_role ; \n          GRANT USAGE ON SCHEMA my_schema TO ROLE my_alert_role ;\n         ```\n         \n         Copy\n    + The owner of the database must grant the USAGE privilege on the database:\n         \n         ```\n         GRANT USAGE ON DATABASE my_database TO ROLE my_alert_role ;\n         ```\n         \n         Copy\n    + If you want to specify a warehouse for the alert, the owner of that warehouse must grant the USAGE privilege on the\n         warehouse:\n         \n         ```\n         GRANT USAGE ON WAREHOUSE my_warehouse TO ROLE my_alert_role ;\n         ```\n         \n         Copy\n\n## Creating an alert ¶\n\nThe following sections provide the basic steps and an example of creating different types of alerts:\n\n* Creating an alert on a schedule\n* Creating an alert on new data\n\n### Creating an alert on a schedule ¶\n\nSuppose that whenever one or more rows in a table named `gauge` has a value in the `gauge_value` column that exceeds 200,\nyou want to insert the current timestamp into a table named `gauge_value_exceeded_history` .\n\nYou can create an alert that:\n\n* Evaluates the condition that `gauge_value` exceeds 200.\n* Inserts the timestamp into `gauge_value_exceeded_history` if this condition evaluates to true.\n\nTo create an alert named `my_alert` that does this:\n\n1. Verify that you are using a role that has the privileges to create an alert .\n   \n   If you are not using that role, execute the USE ROLE command to use that role.\n2. Verify that you are using the database and schema in which you plan to create the alert.\n   \n   If you are not using that database and schema, execute the USE DATABASE and USE SCHEMA commands to use that database and schema.\n3. Execute the CREATE ALERT command to create the alert:\n   \n   ```\n   CREATE OR REPLACE ALERT my_alert \n     WAREHOUSE = mywarehouse \n     SCHEDULE = '1 minute' \n     IF ( EXISTS ( \n       SELECT gauge_value FROM gauge WHERE gauge_value > 200 )) \n     THEN \n       INSERT INTO gauge_value_exceeded_history VALUES ( current_timestamp ());\n   ```\n   \n   Copy\n   \n   If you want to create a serverless alert, omit the WAREHOUSE parameter:\n   \n   ```\n   CREATE OR REPLACE ALERT my_alert \n     SCHEDULE = '1 minute' \n     IF ( EXISTS ( \n       SELECT gauge_value FROM gauge WHERE gauge_value > 200 )) \n     THEN \n       INSERT INTO gauge_value_exceeded_history VALUES ( current_timestamp ());\n   ```\n   \n   Copy\n   \n   For the full description of the CREATE ALERT command, refer to CREATE ALERT .\n   \n   Note\n   \n   When you create an alert, the alert is suspended by default. You must resume the newly created alert in order for the alert\n   to execute.\n4. Resume the alert by executing the ALTER ALERT … RESUME command. For example:\n   \n   ```\n   ALTER ALERT my_alert RESUME ;\n   ```\n   \n   Copy\n\n### Creating an alert on new data ¶\n\nSuppose that you want to receive an email notification when a stored procedure named `my_stored_proc` in the database and\nschema `my_db.my_schema` logs a FATAL message to the active event table for your account .\n\nTo create an alert named `my_alert` that does this:\n\n1. Find the name of the active event table for your account:\n   \n   ```\n   SHOW PARAMETERS LIKE 'EVENT_TABLE' IN ACCOUNT ;\n   ```\n   \n   Copy\n   \n   ```\n   +-------------+---------------------------+----------------------------+---------+-----------------------------------------+--------+ \n    | key         | value                     | default                    | level   | description                             | type   | \n    |-------------+---------------------------+----------------------------+---------+-----------------------------------------+--------| \n    | EVENT_TABLE | my_db.my_schema.my_events | snowflake.telemetry.events | ACCOUNT | Event destination for the given target. | STRING | \n    +-------------+---------------------------+----------------------------+---------+-----------------------------------------+--------+\n   ```\n2. Enable change tracking on the table or view that you plan to query in the alert\n   condition.\n   \n   ```\n   ALTER TABLE my_db . my_schema . my_events SET CHANGE_TRACKING = TRUE ;\n   ```\n   \n   Copy\n3. Set up a notification integration for sending email .\n4. Verify that you are using a role that has the privileges to create an alert .\n   \n   If you are not using that role, execute the USE ROLE command to use that role.\n5. Verify that you are using database and schema in which you plan to create the alert.\n   \n   If you are not using that database and schema, execute the USE DATABASE and USE SCHEMA commands to use that database and schema.\n6. Execute the CREATE ALERT command to create the alert, and omit the SCHEDULE parameter.\n   \n   For example, the following example creates an alert on new data that monitors the event table for errors in dynamic table\n   refreshes and sends a notification to a Slack channel. The example assumes the following:\n   \n    + Your active event table is the default event table (SNOWFLAKE.TELEMETRY.EVENTS).\n    + You have set the severity level to capture events for your dynamic\n         table.\n    + You have set up a webhook notification integration for that Slack\n         channel.\n   \n   ```\n   CREATE OR REPLACE ALERT my_alert \n     WAREHOUSE = mywarehouse \n     IF ( EXISTS ( \n       SELECT * FROM SNOWFLAKE . TELEMETRY . EVENTS \n         WHERE \n           resource_attributes : \"snow.executable.type\" = 'DYNAMIC_TABLE' AND \n           record_type = 'EVENT' AND \n           value : \"state\" = 'ERROR' \n     )) \n     THEN \n       BEGIN \n         LET result_str VARCHAR ; \n         ( SELECT ARRAY_TO_STRING ( ARRAY_AGG ( name ) ::ARRAY , ',' ) INTO :result_str \n           FROM ( \n             SELECT resource_attributes : \"snow.executable.name\" ::VARCHAR name \n               FROM TABLE ( RESULT_SCAN ( SNOWFLAKE.ALERT.GET_CONDITION_QUERY_UUID ())) \n               LIMIT 10 \n           ) \n         ); \n         CALL SYSTEM$SEND_SNOWFLAKE_NOTIFICATION ( \n           SNOWFLAKE.NOTIFICATION.TEXT_PLAIN ( :result_str ), \n           '{\"my_slack_integration\": {}}' \n         ); \n       END ;\n   ```\n   \n   Copy\n   \n   If you want to create a serverless alert, omit the WAREHOUSE parameter:\n   \n   ```\n   CREATE OR REPLACE ALERT my_alert \n     IF ( EXISTS ( \n       SELECT * FROM SNOWFLAKE . TELEMETRY . EVENTS \n         WHERE \n           resource_attributes : \"snow.executable.type\" = 'DYNAMIC_TABLE' AND \n           record_type = 'EVENT' AND \n           value : \"state\" = 'ERROR' \n     )) \n     THEN \n       BEGIN \n         LET result_str VARCHAR ; \n         ( SELECT ARRAY_TO_STRING ( ARRAY_AGG ( name ) ::ARRAY , ',' ) INTO :result_str \n           FROM ( \n             SELECT resource_attributes : \"snow.executable.name\" ::VARCHAR name \n               FROM TABLE ( RESULT_SCAN ( SNOWFLAKE.ALERT.GET_CONDITION_QUERY_UUID ())) \n               LIMIT 10 \n           ) \n         ); \n         CALL SYSTEM$SEND_SNOWFLAKE_NOTIFICATION ( \n           SNOWFLAKE.NOTIFICATION.TEXT_PLAIN ( :result_str ), \n           '{\"my_slack_integration\": {}}' \n         ); \n       END ;\n   ```\n   \n   Copy\n   \n   For the full description of the CREATE ALERT command, refer to CREATE ALERT .\n   \n   Note\n   \n   When you create an alert, the alert is suspended by default. You must resume the newly created alert in order for the alert\n   to execute.\n7. Resume the alert by executing the ALTER ALERT … RESUME command. For example:\n   \n   ```\n   ALTER ALERT my_alert RESUME ;\n   ```\n   \n   Copy\n\n## Specifying timestamps based on alert schedules ¶\n\nIn some cases, you might need to define a condition or action based on the alert schedule.\n\nFor example, suppose that a table has a timestamp column that represents when a row was added, and you want to send an alert\nif any new rows were added between the last alert that was successfully evaluated and the current scheduled alert. In other\nwords, you want to evaluate:\n\n```\n<now> - <last_execution_of_the_alert>\n```\n\nCopy\n\nIf you use CURRENT\\_TIMESTAMP and the scheduled time of the alert to calculate this range of\ntime, the calculated range does not account for latency between the time that the alert is scheduled and the time when the\nalert condition is actually evaluated.\n\nInstead, when you need the timestamps of the current schedule alert and the last alert that was successfully evaluated, use the\nfollowing functions:\n\n* SCHEDULED\\_TIME returns the timestamp representing when the current alert was scheduled.\n* LAST\\_SUCCESSFUL\\_SCHEDULED\\_TIME returns the timestamp representing when the last successfully\n  evaluated alert was scheduled.\n\nThese functions are defined in the SNOWFLAKE.ALERT schema . To call these functions, you need\nto use a role that has been granted the SNOWFLAKE.ALERT\\_VIEWER database role . To\ngrant this role to another role, use the GRANT DATABASE ROLE command. For example, to grant this role\nto the custom role `alert_role` , execute:\n\n```\nGRANT DATABASE ROLE SNOWFLAKE . ALERT_VIEWER TO ROLE alert_role ;\n```\n\nCopy\n\nThe following example sends an email message if any new rows were added to `my_table` between the time that the last\nsuccessfully evaluated alert was scheduled and the time when the current alert has been scheduled:\n\n```\nCREATE OR REPLACE ALERT alert_new_rows \n  WAREHOUSE = my_warehouse \n  SCHEDULE = '1 MINUTE' \n  IF ( EXISTS ( \n      SELECT * \n      FROM my_table \n      WHERE row_timestamp BETWEEN SNOWFLAKE.ALERT.LAST_SUCCESSFUL_SCHEDULED_TIME () \n       AND SNOWFLAKE.ALERT.SCHEDULED_TIME () \n  )) \n  THEN CALL SYSTEM$SEND_EMAIL (...);\n```\n\nCopy\n\n## Checking the results of the SQL statement for the condition in the alert action ¶\n\nWithin the action of an alert, if you need to check the results of the SQL statement for the condition:\n\n1. Call the GET\\_CONDITION\\_QUERY\\_UUID function to get the query ID for the SQL statement for the\n   condition.\n2. Pass the query ID to the RESULT\\_SCAN function to get the results of the execution of that SQL\n   statement.\n\nFor example:\n\n```\nCREATE ALERT my_alert \n  WAREHOUSE = my_warehouse \n  SCHEDULE = '1 MINUTE' \n  IF ( EXISTS ( \n    SELECT * FROM my_source_table )) \n  THEN \n    BEGIN \n      LET condition_result_set RESULTSET := \n        ( SELECT * FROM TABLE ( RESULT_SCAN ( SNOWFLAKE.ALERT.GET_CONDITION_QUERY_UUID ()))); \n      ... \n    END ;\n```\n\nCopy\n\n## Manually executing alerts ¶\n\nIn some cases, you might need to execute an alert manually. For example:\n\n* If you are creating a new alert, you might want to verify that the alert works as you would expect.\n* You might want to execute the alert at a specific point in your data pipeline. For example, you might want to execute the\n  alert at the end of a stored procedure call.\n\nTo execute an alert manually, run the EXECUTE ALERT command:\n\n```\nEXECUTE ALERT my_alert ;\n```\n\nCopy\n\nNote\n\nYou cannot use EXECUTE ALERT to execute an alert on new data .\n\nThe EXECUTE ALERT command manually triggers a single run of an alert, independent of the schedule defined for the alert.\n\nYou can execute this command interactively. You can also execute this command from within a stored procedure or a Snowflake\nScripting block.\n\nFor details on the privileges required to run this command and the effect of this command on suspended, running, and scheduled\nalerts, see EXECUTE ALERT .\n\n## Suspending and resuming an alert ¶\n\nIf you need to prevent an alert from executing temporarily, you can suspend the alert by executing the ALTER ALERT … SUSPEND command. For example:\n\n```\nALTER ALERT my_alert SUSPEND ;\n```\n\nCopy\n\nTo resume a suspended alert, execute the ALTER ALERT … RESUME command. For example:\n\n```\nALTER ALERT my_alert RESUME ;\n```\n\nCopy\n\nNote\n\nIf you are not the owner of the alert, you must have the OPERATE privilege on the alert to suspend or resume the alert.\n\n## Modifying an alert ¶\n\nTo modify the properties of an alert, execute the ALTER ALERT command.\n\nNote\n\n* You must be the owner of the alert to modify the properties of the alert.\n* You cannot change an alert on new data to an alert on a schedule . Similarly, you cannot change an alert on a schedule to an alert\n  on new data.\n\nFor example:\n\n* To change the warehouse for the alert named `my_alert` to `my_other_warehouse` , execute:\n  \n  ```\n  ALTER ALERT my_alert SET WAREHOUSE = my_other_warehouse ;\n  ```\n  \n  Copy\n* To change the schedule for the alert named `my_alert` to be evaluated every 2 minutes, execute:\n  \n  ```\n  ALTER ALERT my_alert SET SCHEDULE = '2 minutes' ;\n  ```\n  \n  Copy\n* To change the condition for the alert named `my_alert` so that you are alerted if any rows in the table named `gauge` have\n  values greater than `300` in the `gauge_value` column, execute:\n  \n  ```\n  ALTER ALERT my_alert MODIFY CONDITION EXISTS ( SELECT gauge_value FROM gauge WHERE gauge_value > 300 );\n  ```\n  \n  Copy\n* To change the action for the alert named `my_alert` to `CALL my_procedure()` , execute:\n  \n  ```\n  ALTER ALERT my_alert MODIFY ACTION CALL my_procedure ();\n  ```\n  \n  Copy\n\n## Dropping an alert ¶\n\nTo drop an alert, execute the DROP ALERT command. For example:\n\n```\nDROP ALERT my_alert ;\n```\n\nCopy\n\nTo drop an alert without raising an error if the alert does not exist, execute:\n\n```\nDROP ALERT IF EXISTS my_alert ;\n```\n\nCopy\n\nNote\n\nYou must be the owner of the alert to drop the alert.\n\n## Viewing details about an alert ¶\n\nTo list the alerts that have been created in an account, database, or schema, execute the SHOW ALERTS command. For example, to list the alerts that were created in the current schema, run the following command:\n\n```\nSHOW ALERTS ;\n```\n\nCopy\n\nThis command lists the alerts that you own and the alerts that you have the MONITOR or OPERATE privilege on.\n\nTo view the details about a specific alert, execute the DESCRIBE ALERT command. For example:\n\n```\nDESC ALERT my_alert ;\n```\n\nCopy\n\nNote\n\nIf you are not the owner of the alert, you must have the MONITOR or OPERATE privilege on the alert to view the details of the\nalert.\n\n## Cloning an alert ¶\n\nYou can clone an alert (either by using CREATE ALERT … CLONE or by cloning the\ndatabase or schema containing the alert).\n\nIf you are cloning a serverless alert, you don’t need to use a role that has the global EXECUTE MANAGED ALERT privilege. However,\nyou will not be able to resume that alert until the role that owns the alert has been granted the EXECUTE MANAGED ALERT privilege.\n\n## Monitoring the execution of alerts ¶\n\nTo monitor the execution of the alerts, you can:\n\n* Check the results of the action that was specified for the alert. For example, if the action inserted rows into a table, you can\n  check the table for new rows.\n* View the history of alert executions by using one of the following:\n  \n    + The ALERT\\_HISTORY table function in the INFORMATION\\_SCHEMA schema.\n        \n        For example, to view the executions of alerts over the past hour, execute the following statement:\n        \n        ```\n        SELECT * \n         FROM \n          TABLE ( INFORMATION_SCHEMA . ALERT_HISTORY ( \n            SCHEDULED_TIME_RANGE_START \n              => dateadd ( 'hour' ,- 1 , current_timestamp ()))) \n         ORDER BY SCHEDULED_TIME DESC ;\n        ```\n        \n        Copy\n    + The ALERT\\_HISTORY view in the ACCOUNT\\_USAGE schema in the shared\n        SNOWFLAKE database.\n\nIn the query history, the name of the user who executed the query will be SYSTEM. (The alerts are run by the system service .)\n\n## Viewing the query history of a serverless alert ¶\n\nTo view the query history of a serverless alert, you must be the owner of the alert, or you must use a role that has the\nMONITOR or OPERATE privilege on the alert itself. (This differs from alerts that use one your warehouses, which require the\nMONITOR or OPERATOR privilege on the warehouse.)\n\nFor example, suppose that you want to use the `my_alert_role` role when viewing the query history of the alert `my_alert` .\nIf `my_alert_role` is not the owner of `my_alert` , you must grant that role the\nMONITOR or OPERATE privilege on the alert:\n\n```\nGRANT MONITOR ON ALERT my_alert TO ROLE my_alert_role ;\n```\n\nCopy\n\nAfter the role is granted this privilege, you can use the role to view the query history of the alert:\n\n```\nUSE ROLE my_alert_role ;\n```\n\nCopy\n\n```\nSELECT query_text FROM TABLE ( INFORMATION_SCHEMA . QUERY_HISTORY ()) \n  WHERE query_text LIKE '%Some condition%' \n    OR query_text LIKE '%Some action%' \n  ORDER BY start_time DESC ;\n```\n\nCopy\n\nWas this page helpful?\n\nYes No\n\n[Visit Snowflake](https://www.snowflake.com)\n\n[Join the conversation](https://community.snowflake.com/s/)\n\n[Develop with Snowflake](https://developers.snowflake.com)\n\nShare your feedback\n\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n\n[Get your own certification](https://learn.snowflake.com)"},{"url":"https://keebo.ai/2025/02/01/proactive-suspension/","title":"See How Keebo’s Autonomous Warehouse Suspension Algorithm Maximizes Snowflake Savings - Keebo","publish_date":"2026-02-21","excerpts":["Section Title: See How Keebo’s Autonomous Warehouse Suspension Algorithm Maximizes Snowflake Savings\nContent:\n[](https://keebo.ai/2025/02/01/proactive-suspension/) [](https://keebo.ai/author/yongjoo/) [](https://keebo.ai/author/alex/) [Richard P. Spillane](https://keebo.ai/2025/02/01/proactive-suspension/ \"Posts by Richard P. Spillane\") , [Yongjoo Park](https://keebo.ai/author/yongjoo/ \"Posts by Yongjoo Park\") and [Alex Tokarev](https://keebo.ai/author/alex/ \"Posts by Alex Tokarev\")\nFebruary 1, 2025\n[AI](https://keebo.ai/category/ai/) , [Data Engineering](https://keebo.ai/category/data-engineering/) , [Reducing Snowflake Costs](https://keebo.ai/category/reducing-snowflake-costs/) , [Warehouse Optimization](https://keebo.ai/category/warehouse-optimization/)\nAmong Snowflake’s many built-in cost reduction measures is their auto-suspend system. In a nutshell, this capability suspends inactive warehouses, keeping you from spending compute resources when they’re not needed.\nSection Title: See How Keebo’s Autonomous Warehouse Suspension Algorithm Maximizes Snowflake Savings\nContent:\nConfiguring auto-suspend is straightforward: use Snowflake’s SQL command to implement your settings. For example, you might use an [ALTER WAREHOUSE command](https://docs.snowflake.com/en/sql-reference/sql/alter-warehouse) specify that a warehouse should suspend 45 seconds after the last query ends:\n```\nALTER WAREHOUSE <your_warehouse_name> \n```\n```\nSET AUTO_SUSPEND = 45;\n```\nHowever, the reality is more complicated. Although Snowflake will attempt to implement this policy, you’ll end up with the warehouse suspended after 60 seconds of inactivity, not 45. The reason, per Snowflake’s documentation is, “Setting a value less than 30, or a value that is not a multiple of 30, is allowed but might not result in the expected behavior due to the 30 second poll interval for warehouse suspension.”\nSection Title: See How Keebo’s Autonomous Warehouse Suspension Algorithm Maximizes Snowflake Savings\nContent:\nIn other words, Snowflake only checks to see if a warehouse is active every 30 seconds. If your auto-suspend is set to 45 seconds, the warehouse won’t be suspended until the next 30-second interval, which is 60 seconds. As a result, the warehouse runs 15 seconds longer than you intended.\nOf course, 15 seconds of activity here and there may not seem like a big deal. But if you compound that over a longer period of time and multiple warehouses of various sizes, it adds up. Consider the following examples:\n ... \nSection Title: See How Keebo’s Autonomous Warehouse Suspension Algorithm Maximizes Snowflake Savings\nContent:\nAlthough simplistic, these examples illustrate the problem: small periods of unneeded warehouse activity add up to significant overspending. And if you’re only relying on Snowflake’s default controller, there’s no way to address this issue.\nThat’s why Keebo has recently launched a real-time, automated proactive warehouse suspension algorithm. This new tool enables more fine-grained control over auto-suspend intervals. Depending on your current Snowflake configuration, this tool could help you save dollars you didn’t even realize you were wasting.\nSection Title: ... > How Keebo’s real-time, automated proactive warehouse suspension algorithm works\nContent:\nThe key difference between Keebo’s approach and Snowflake’s default behavior is that while Snowflake suspends warehouses in 30-second intervals, Keebo performs checks and implements suspensions within 2.5-5 seconds of your target deadline. This presents a 6-12X improvement in precision over Snowflake’s default controller.\nMost importantly, Keebo’s real-time, automated proactive warehouse suspension algorithm integrates natively with our other machine learning algorithms—warehouse optimization, performance guardrails, query routing, etc.—creating a workload-specific approach to reducing your Snowflake spend.\nHere’s an example to illustrate the benefits of real-time warehouse suspension control:\nLet’s break down the sequence of events in the example above:\nSection Title: ... > How Keebo’s real-time, automated proactive warehouse suspension algorithm works\nContent:\nThe user set Warehouse A’s auto-suspend to 45 seconds.\nWarehouse A asleep at 11:29:00 AM.\nTwo seconds later (11:29:02 AM), a query starts, resuming the warehouse. Snowflake starts billing the user for this warehouse’s operation.\nAt 12:01:32 PM, the query ends. From this point on, there are no new queries. According to the user’s settings, the warehouse should suspend at 12:02:17 PM.\nHowever, because Snowflake’s auto-suspend occurs in 30-second intervals, the actual suspension takes place at 12:02:33 PM (or 61 seconds after the query ended).\nAs a result, Snowflake bills the user for an additional 16 seconds of warehouse operation.\nHow would Keebo have handled that situation differently? Instead of operating in 30-second intervals, Keebo’s real-time controller polls the state of each warehouse to learn:\nSection Title: ... > How Keebo’s real-time, automated proactive warehouse suspension algorithm works\nContent:\nWhether the warehouse is running or idle\nHow many queries were last queued\nWhen the warehouse was last resumed, if running\nOnce the warehouse has been idle for the target auto-suspend time, the real-time controller puts the warehouse to sleep using the following SQL command:\n```\nALTER WAREHOUSE <warehouse_name> SUSPEND;\n```\n*Note: Snowflake promises not to suspend a warehouse while a query is actively running. In our testing we found this is usually the case, though there are rare circumstances where in-flight queries can still fail. Keebo counters this problem by enhancing the simple ALTER command with an additional server-side check that makes sure the warehouse is still idle before suspending. This eliminates the window in which queries can fail.*\nLet’s return to the example above:\nSection Title: ... > How Keebo’s real-time, automated proactive warehouse suspension algorithm works\nContent:\nThe user set Warehouse A’s auto-suspend to 45 seconds using Keebo’s real-time, automated proactive warehouse suspension algorithm. Warehouse A asleep at 11:29:00 AM. Two seconds later (11:29:02 AM), a query starts, resuming the warehouse. Snowflake starts billing the user for this warehouse’s operation. Throughout the duration of the query, Keebo polls the warehouse to determine whether the warehouse is running or idle. (This is indicated by the rays projecting upward toward the timeline.) Note that poll (0), the warehouse is determined to be active. At 12:01:32 PM, the query ends. From this point on, there are no new queries. According to the user’s settings, the warehouse should suspend at 12:02:17 PM. At poll (1) above, Keebo determines that the warehouse is idle and logs an *initial idle observation* .\nSection Title: ... > How Keebo’s real-time, automated proactive warehouse suspension algorithm works\nContent:\nAt poll (2) above, Keebo determines the warehouse has been idle for more than 45 seconds, then sends a suspend command (3). The warehouse is then suspended at 12:02:19, or 47 seconds after the query ends.\nSection Title: ... > How Keebo’s real-time, automated proactive warehouse suspension algorithm works\nContent:\nIn this example, the target suspend is delayed by only two seconds, compared to 16 seconds with Snowflake’s default controller. This has saved the customer 14 seconds of wasted billed uptime.\nSection Title: ... > Using real-time warehouse control & dynamic auto-suspend to maximize Snowflake savings\nContent:\nWe just demonstrated how Keebo gives you the fine-grained control over warehouse auto-suspend that Snowflake’s default auto-controller doesn’t. But those savings are dependent on how you define that auto-suspend time in the first place. The challenge is that the ideal auto-suspend time varies from organization to organization, warehouse to warehouse, and function of a variety of factors:\nThe warehouse’s currently executing workload\nHistorical performance\nWorkload characteristics across the overall business (inferred from analyzing other workloads in the same account)\nAs a result, the optimal auto-suspend value changes over time—there’s no ideal “set-it-and-forget-it” value. This means that to maximize the savings auto-suspend gives you, that value should be updated over time.\nSection Title: ... > Using real-time warehouse control & dynamic auto-suspend to maximize Snowflake savings\nContent:\nAnother common mistake Snowflake users often make is to set their auto-suspend as low as possible. There are risks associated with a warehouse that suspends too soon. Active warehouses maintain a cache of data accessed by recent queries, enabling subsequent queries to run faster. If your warehouse auto-suspends, then a new query begins two seconds later, the query execution time will increase due to an empty cache.\nKeebo addresses this problem with a dynamic, AI-driven approach to auto-suspend. First, users set a maximum upper limit (e.g. 45 seconds). Our algorithm dynamically determines the optimal auto-suspend value in real-time. This optimization aims to minimize the number of queries that encounter a cold cache, while maintaining query performance levels comparable to those achieved with the user-defined auto-suspend setting.\nSection Title: ... > What about credits consumed by the real-time controller? Won’t that offset any of our savings?\nContent:\nIf Keebo’s real-time controller is constantly polling your warehouses to see whether they’re active or idle, doesn’t that consume Snowflake resources? The answer is yes, but with a major caveat: polling the warehouse consumes **cloud credits** , not **warehouse credits.**\nThe difference: if your [cloud credits](https://docs.snowflake.com/en/user-guide/cost-understanding-overall) don’t exceed 10% of your daily warehouse usage, then Snowflake doesn’t bill you for them. So even though the real-time controller is increasing your cloud activity, as long as it falls within that 10% threshold, you won’t run into any issues.\nAs such, we’ve structured Keebo’s real-time controller and determined that five seconds in between polls was the optimal period for reducing daily credit consumption:\nSection Title: ... > What about credits consumed by the real-time controller? Won’t that offset any of our savings?\nContent:\nIt’s impossible to predict whether we’ll exceed that 10% threshold without knowing what a user’s cloud services usage is already. However, suffice it to say that we’re able to strike a balance between optimal savings while avoiding unnecessary cloud compute, thus achieving a cost-effective solution.\nAdditionally, Keebo’s polling mechanism covers all warehouses in the account. This means the cost of running the controller doesn’t increase linearly with the number of warehouses. In other words, the cost of running the controller is practically fixed. So the more warehouses you have, the more you can save without increasing your cost.\nSection Title: ... > Final thoughts on Keebo’s real-time controller\nContent:\nSnowflake’s flexible auto-suspend capability presents a major savings opportunity to its users—which is one of the advantages of using their data platform. But as with any tool, it’s important to understand exactly how it works and make sure you’re accurately accounting for your savings.\nBut here’s the best part. Let’s assume you’re running the smallest (and cheapest) Snowflake configuration: an X-Small warehouse on one cluster with a one-second auto-suspend. Even in that smallest configuration, the Keebo real-time controller still saves you money—because that “one second” is actually 30 seconds in reality.\nIn other words, even if you think you’re running Snowflake as inexpensively as possible, there’s still opportunity to save.\nSection Title: ... > Final thoughts on Keebo’s real-time controller\nContent:\nThe best way to learn more about our real-time controller—not to mention our comprehensive Snowflake cost optimization platform—is on a live demo. [Schedule some time with our team today](https://keebo.ai/contact/) .\n ... \nSection Title: ... > Richard P. Spillane\nContent:\n[Articles: 1](https://keebo.ai/2025/02/01/proactive-suspension/)\n[Previous Post Snowflake Pricing Explained: A Comprehensive 2025 Guide to Costs & Savings](https://keebo.ai/2025/01/28/snowflake-pricing/) [Next Post Designing a Reinforcement Learning Pipeline: Crafting the Reward Function and Simulator](https://keebo.ai/2025/03/04/reinforcement-learning-pipeline/)\nSection Title: ... > Related Posts\nContent:\n[](https://keebo.ai/2026/01/26/cut-snowflake-costs-with-smart-automation-tools/)\nSection Title: ... > [How Keebo Cuts Snowflake Costs with Smart Optimization Tools](https://keebo.ai/2026/01/26/...\nContent:\nFebruary 5, 2026\n[](https://keebo.ai/2026/01/26/databricks-cost-optmization-strategies/)\nSection Title: ... > [Databricks Cost Optimization: Proven Strategies to Reduce Cloud Spending](https://keebo.ai...\nContent:\nJanuary 26, 2026\n[](https://keebo.ai/2025/12/02/snowpark-optimized-warehouse-resource-constraints/)\nSection Title: ... > [Snowpark-Optimized Warehouses: How to Configure resource_constraints for Maximum Performan...\nContent:\nDecember 2, 2025"],"full_content":"# See How Keebo’s Autonomous Warehouse Suspension Algorithm Maximizes Snowflake Savings\n\n* [](https://keebo.ai/2025/02/01/proactive-suspension/) [](https://keebo.ai/author/yongjoo/) [](https://keebo.ai/author/alex/) [Richard P. Spillane](https://keebo.ai/2025/02/01/proactive-suspension/ \"Posts by Richard P. Spillane\") , [Yongjoo Park](https://keebo.ai/author/yongjoo/ \"Posts by Yongjoo Park\") and [Alex Tokarev](https://keebo.ai/author/alex/ \"Posts by Alex Tokarev\")\n* February 1, 2025\n* [AI](https://keebo.ai/category/ai/) , [Data Engineering](https://keebo.ai/category/data-engineering/) , [Reducing Snowflake Costs](https://keebo.ai/category/reducing-snowflake-costs/) , [Warehouse Optimization](https://keebo.ai/category/warehouse-optimization/)\n\nAmong Snowflake’s many built-in cost reduction measures is their auto-suspend system. In a nutshell, this capability suspends inactive warehouses, keeping you from spending compute resources when they’re not needed.\n\nConfiguring auto-suspend is straightforward: use Snowflake’s SQL command to implement your settings. For example, you might use an [ALTER WAREHOUSE command](https://docs.snowflake.com/en/sql-reference/sql/alter-warehouse) specify that a warehouse should suspend 45 seconds after the last query ends:\n\n```\nALTER WAREHOUSE <your_warehouse_name> \n```\n\n```\nSET AUTO_SUSPEND = 45;\n```\n\nHowever, the reality is more complicated. Although Snowflake will attempt to implement this policy, you’ll end up with the warehouse suspended after 60 seconds of inactivity, not 45. The reason, per Snowflake’s documentation is, “Setting a value less than 30, or a value that is not a multiple of 30, is allowed but might not result in the expected behavior due to the 30 second poll interval for warehouse suspension.”\n\nIn other words, Snowflake only checks to see if a warehouse is active every 30 seconds. If your auto-suspend is set to 45 seconds, the warehouse won’t be suspended until the next 30-second interval, which is 60 seconds. As a result, the warehouse runs 15 seconds longer than you intended.\n\nOf course, 15 seconds of activity here and there may not seem like a big deal. But if you compound that over a longer period of time and multiple warehouses of various sizes, it adds up. Consider the following examples:\n\n|**WH Size** |**\\# of WHs** |**Avg. extra activity for each auto-suspend (sec)** |**\\# of auto-suspends per month** |**Total credits wasted** |**Total spend wasted (Enterprise Edition, $3.00 per credit)** |\n| --- | --- | --- | --- | --- | --- |\n|XS |20 |15 |450 (15 per day) |37\\.5 |$112.50 |\n|M |15 |15 |450 (15 per day) |112\\.5 |$337.50 |\n|XL |5 |15 |450 (15 per day) |150 |$450.00 |\n\nAlthough simplistic, these examples illustrate the problem: small periods of unneeded warehouse activity add up to significant overspending. And if you’re only relying on Snowflake’s default controller, there’s no way to address this issue.\n\nThat’s why Keebo has recently launched a real-time, automated proactive warehouse suspension algorithm. This new tool enables more fine-grained control over auto-suspend intervals. Depending on your current Snowflake configuration, this tool could help you save dollars you didn’t even realize you were wasting.\n\n## How Keebo’s real-time, automated proactive warehouse suspension algorithm works\n\nThe key difference between Keebo’s approach and Snowflake’s default behavior is that while Snowflake suspends warehouses in 30-second intervals, Keebo performs checks and implements suspensions within 2.5-5 seconds of your target deadline. This presents a 6-12X improvement in precision over Snowflake’s default controller.\n\nMost importantly, Keebo’s real-time, automated proactive warehouse suspension algorithm integrates natively with our other machine learning algorithms—warehouse optimization, performance guardrails, query routing, etc.—creating a workload-specific approach to reducing your Snowflake spend.\n\nHere’s an example to illustrate the benefits of real-time warehouse suspension control:\n\nLet’s break down the sequence of events in the example above:\n\n1. The user set Warehouse A’s auto-suspend to 45 seconds.\n2. Warehouse A asleep at 11:29:00 AM.\n3. Two seconds later (11:29:02 AM), a query starts, resuming the warehouse. Snowflake starts billing the user for this warehouse’s operation.\n4. At 12:01:32 PM, the query ends. From this point on, there are no new queries. According to the user’s settings, the warehouse should suspend at 12:02:17 PM.\n5. However, because Snowflake’s auto-suspend occurs in 30-second intervals, the actual suspension takes place at 12:02:33 PM (or 61 seconds after the query ended).\n6. As a result, Snowflake bills the user for an additional 16 seconds of warehouse operation.\n\nHow would Keebo have handled that situation differently? Instead of operating in 30-second intervals, Keebo’s real-time controller polls the state of each warehouse to learn:\n\n* Whether the warehouse is running or idle\n* How many queries were last queued\n* When the warehouse was last resumed, if running\n\nOnce the warehouse has been idle for the target auto-suspend time, the real-time controller puts the warehouse to sleep using the following SQL command:\n\n```\nALTER WAREHOUSE <warehouse_name> SUSPEND;\n```\n\n_Note: Snowflake promises not to suspend a warehouse while a query is actively running. In our testing we found this is usually the case, though there are rare circumstances where in-flight queries can still fail. Keebo counters this problem by enhancing the simple ALTER command with an additional server-side check that makes sure the warehouse is still idle before suspending. This eliminates the window in which queries can fail._\n\nLet’s return to the example above:\n\n1. The user set Warehouse A’s auto-suspend to 45 seconds using Keebo’s real-time, automated proactive warehouse suspension algorithm.\n2. Warehouse A asleep at 11:29:00 AM.\n3. Two seconds later (11:29:02 AM), a query starts, resuming the warehouse. Snowflake starts billing the user for this warehouse’s operation.\n4. Throughout the duration of the query, Keebo polls the warehouse to determine whether the warehouse is running or idle. (This is indicated by the rays projecting upward toward the timeline.) Note that poll (0), the warehouse is determined to be active.\n5. At 12:01:32 PM, the query ends. From this point on, there are no new queries. According to the user’s settings, the warehouse should suspend at 12:02:17 PM.\n6. At poll (1) above, Keebo determines that the warehouse is idle and logs an _initial idle observation_ .\n7. At poll (2) above, Keebo determines the warehouse has been idle for more than 45 seconds, then sends a suspend command (3). The warehouse is then suspended at 12:02:19, or 47 seconds after the query ends.\n\nIn this example, the target suspend is delayed by only two seconds, compared to 16 seconds with Snowflake’s default controller. This has saved the customer 14 seconds of wasted billed uptime.\n\n## Using real-time warehouse control & dynamic auto-suspend to maximize Snowflake savings\n\nWe just demonstrated how Keebo gives you the fine-grained control over warehouse auto-suspend that Snowflake’s default auto-controller doesn’t. But those savings are dependent on how you define that auto-suspend time in the first place. The challenge is that the ideal auto-suspend time varies from organization to organization, warehouse to warehouse, and function of a variety of factors:\n\n* The warehouse’s currently executing workload\n* Historical performance\n* Workload characteristics across the overall business (inferred from analyzing other workloads in the same account)\n\nAs a result, the optimal auto-suspend value changes over time—there’s no ideal “set-it-and-forget-it” value. This means that to maximize the savings auto-suspend gives you, that value should be updated over time.\n\nAnother common mistake Snowflake users often make is to set their auto-suspend as low as possible. There are risks associated with a warehouse that suspends too soon. Active warehouses maintain a cache of data accessed by recent queries, enabling subsequent queries to run faster. If your warehouse auto-suspends, then a new query begins two seconds later, the query execution time will increase due to an empty cache.\n\nKeebo addresses this problem with a dynamic, AI-driven approach to auto-suspend. First, users set a maximum upper limit (e.g. 45 seconds). Our algorithm dynamically determines the optimal auto-suspend value in real-time. This optimization aims to minimize the number of queries that encounter a cold cache, while maintaining query performance levels comparable to those achieved with the user-defined auto-suspend setting.\n\n## What about credits consumed by the real-time controller? Won’t that offset any of our savings?\n\nIf Keebo’s real-time controller is constantly polling your warehouses to see whether they’re active or idle, doesn’t that consume Snowflake resources? The answer is yes, but with a major caveat: polling the warehouse consumes **cloud credits** , not **warehouse credits.**\n\nThe difference: if your [cloud credits](https://docs.snowflake.com/en/user-guide/cost-understanding-overall) don’t exceed 10% of your daily warehouse usage, then Snowflake doesn’t bill you for them. So even though the real-time controller is increasing your cloud activity, as long as it falls within that 10% threshold, you won’t run into any issues.\n\nAs such, we’ve structured Keebo’s real-time controller and determined that five seconds in between polls was the optimal period for reducing daily credit consumption:\n\nIt’s impossible to predict whether we’ll exceed that 10% threshold without knowing what a user’s cloud services usage is already. However, suffice it to say that we’re able to strike a balance between optimal savings while avoiding unnecessary cloud compute, thus achieving a cost-effective solution.\n\nAdditionally, Keebo’s polling mechanism covers all warehouses in the account. This means the cost of running the controller doesn’t increase linearly with the number of warehouses. In other words, the cost of running the controller is practically fixed. So the more warehouses you have, the more you can save without increasing your cost.\n\n## Final thoughts on Keebo’s real-time controller\n\nSnowflake’s flexible auto-suspend capability presents a major savings opportunity to its users—which is one of the advantages of using their data platform. But as with any tool, it’s important to understand exactly how it works and make sure you’re accurately accounting for your savings.\n\nBut here’s the best part. Let’s assume you’re running the smallest (and cheapest) Snowflake configuration: an X-Small warehouse on one cluster with a one-second auto-suspend. Even in that smallest configuration, the Keebo real-time controller still saves you money—because that “one second” is actually 30 seconds in reality.\n\nIn other words, even if you think you’re running Snowflake as inexpensively as possible, there’s still opportunity to save.  \n  \nThe best way to learn more about our real-time controller—not to mention our comprehensive Snowflake cost optimization platform—is on a live demo. [Schedule some time with our team today](https://keebo.ai/contact/) .\n\n## Authors\n\n* [Richard P. Spillane](https://keebo.ai/2025/02/01/proactive-suspension/ \"Richard P. Spillane\")\n  \n  [View all posts](https://keebo.ai/2025/02/01/proactive-suspension/ \"View all posts\") \n* [Yongjoo Park](https://keebo.ai/author/yongjoo/ \"Yongjoo Park\")\n  \n  [View all posts](https://keebo.ai/author/yongjoo/ \"View all posts\") \n* [Alex Tokarev](https://keebo.ai/author/alex/ \"Alex Tokarev\")\n  \n  [View all posts](https://keebo.ai/author/alex/ \"View all posts\") \n\n[](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fkeebo.ai%2F2025%2F02%2F01%2Fproactive-suspension%2F) [](https://twitter.com/intent/tweet?url=https%3A%2F%2Fkeebo.ai%2F2025%2F02%2F01%2Fproactive-suspension%2F&text=See%20How%20Keebo%E2%80%99s%20Autonomous%20Warehouse%20Suspension%20Algorithm%20Maximizes%20Snowflake%20Savings)  [](https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fkeebo.ai%2F2025%2F02%2F01%2Fproactive-suspension%2F&title=See%20How%20Keebo%E2%80%99s%20Autonomous%20Warehouse%20Suspension%20Algorithm%20Maximizes%20Snowflake%20Savings)\n\n[](https://keebo.ai/2025/02/01/proactive-suspension/)\n\n##### Richard P. Spillane\n\n[Articles: 1](https://keebo.ai/2025/02/01/proactive-suspension/)\n\n[Previous Post Snowflake Pricing Explained: A Comprehensive 2025 Guide to Costs & Savings](https://keebo.ai/2025/01/28/snowflake-pricing/) [Next Post Designing a Reinforcement Learning Pipeline: Crafting the Reward Function and Simulator](https://keebo.ai/2025/03/04/reinforcement-learning-pipeline/)\n\n### Related Posts\n\n[](https://keebo.ai/2026/01/26/cut-snowflake-costs-with-smart-automation-tools/)\n\n#### [How Keebo Cuts Snowflake Costs with Smart Optimization Tools](https://keebo.ai/2026/01/26/cut-snowflake-costs-with-smart-automation-tools/)\n\n* February 5, 2026\n\n[](https://keebo.ai/2026/01/26/databricks-cost-optmization-strategies/)\n\n#### [Databricks Cost Optimization: Proven Strategies to Reduce Cloud Spending](https://keebo.ai/2026/01/26/databricks-cost-optmization-strategies/)\n\n* January 26, 2026\n\n[](https://keebo.ai/2025/12/02/snowpark-optimized-warehouse-resource-constraints/)\n\n#### [Snowpark-Optimized Warehouses: How to Configure resource\\_constraints for Maximum Performance](https://keebo.ai/2025/12/02/snowpark-optimized-warehouse-resource-constraints/)\n\n* December 2, 2025"},{"url":"https://medium.com/snowflake/snowflake-native-alerts-24e3d8b3b31e","title":"Snowflake Native Alerts. Set alerts and get notified | by Prathamesh Nimkar | Snowflake Builders Blog: Data Engineers, App Developers, AI, & Data Science | Medium","publish_date":"2023-02-09","excerpts":["Sitemap\n[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F24e3d8b3b31e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&%7Estage=mobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)\nWrite\nSearch\n[## Snowflake Builders Blog: Data Engineers, App Developers, AI, & Data Science](https://medium.com/snowflake?source=post_page---publication_nav-34b6daafc07-24e3d8b3b31e---------------------------------------)\n·\n[](https://medium.com/snowflake?source=post_page---post_publication_sidebar-34b6daafc07-24e3d8b3b31e---------------------------------------)\nBest practices, tips & tricks from Snowflake experts and community\n ... \nSection Title: **Snowflake Native Alerts** > Introducing Snowflake Native Alerts\nContent:\nSnowflake users can now set up alerts and get notified when specific conditions are met. Please note this feature is currently in Private Preview. (Update: as of Feb 8, 2023 — it is **Public** Preview).\nLet’s take a quick look at the syntax:\n```\nCREATE [ OR REPLACE ] ALERT [ IF NOT EXISTS ] <alert name>  \n  WAREHOUSE = <warehouse name>  \n  SCHEDULE = '{ <num> MINUTE | USING CRON <expr> <time zone> }'  \n-- Condition    \nIF( EXISTS(  \n    <condition statement>  \n))  \n-- Action  \n  THEN  \n    <action statement>  \n;\n```\nAn alert is a schema-level object that specifies:\n ... \nSection Title: **Snowflake Native Alerts** > Introducing Snowflake Native Alerts > The Action\nContent:\nSince we plan to send out an email notification, we need to create a [Notification Integration](https://docs.snowflake.com/en/sql-reference/email-stored-procedures.html) . Here’s a quick look at the syntax:\n```\nCREATE [ OR REPLACE ] NOTIFICATION INTEGRATION [ IF NOT EXISTS ] <name>  \n  TYPE = EMAIL  \n  ENABLED = { TRUE | FALSE }  \n  ALLOWED_RECIPIENTS = ( '<email_address_1>' [ , ... '<email_address_N>' ] )  \n  [ COMMENT = '<string_literal>' ]  \n  ;\n```\nAnd the following would be for our specific requirement:\n```\n-- You will need AccountAdmin role to create a Notification Integration  \nCREATE NOTIFICATION INTEGRATION my_email_int  \n    TYPE=email  \n    ENABLED=true  \n    ALLOWED_RECIPIENTS=('my_id@domain.com')  \n    COMMENT='Created via Native Alerts App'  \n;  \n  \n  \n-- Required Grants  \nGRANT usage ON integration my_email_int to role <role_name>;\n```\nSection Title: **Snowflake Native Alerts** > Introducing Snowflake Native Alerts > The Alert\nContent:\nPutting the pieces together within the alert syntax as we learnt above:\nSection Title: **Snowflake Native Alerts** > Introducing Snowflake Native Alerts > The Alert\nContent:\n```\n-- If you wish to grant the privileges to another role  \n-- Perform the following steps using AccountAdmin role  \nCREATE ROLE <alert_role>;  \nGRANT ROLE <alert_role> TO USER <alert_user>;  \nGRANT EXECUTE ALERT ON ACCOUNT TO ROLE <alert_role>;  \n  \n-- You may also require USAGE privileges on the database and warehouse  \n-- Using schema owner role, grant the following permissions to alert_role  \nGRANT CREATE ALERT ON SCHEMA <schema_name> TO ROLE <alert_role>;  \n-- or  \nGRANT OWNERSHIP ON SCHEMA <schema_name> TO ROLE <alert_role>;  \n  \n-- if you have performed the above steps in this snippet  \nUSE ROLE <alert_role>;  \n-- I am using AccountAdmin role, hence I will be ignoring the above steps  \n  \n-- Let's create the alert now  \nCREATE OR REPLACE ALERT myalert  \n    WAREHOUSE = compute_wh  \n    SCHEDULE = '1 minute'  \n    IF  \n        (EXISTS(  \n                  SELECT  \n                      event_timestamp,\nSection Title: **Snowflake Native Alerts** > Introducing Snowflake Native Alerts > The Alert\nContent:\nuser_name, client_IP, reported_client_type,  \n                      first_authentication_factor, second_authentication_factor  \n                  FROM snowflake.account_usage.login_history  \n                  WHERE second_authentication_factor IS NULL  \n                  AND (  \n                     reported_client_type = 'SNOWFLAKE_UI'  \n                  OR reported_client_type = 'OTHER'  \n                  )  \n                  AND user_name IN (  \n                    SELECT grantee_name  \n                    FROM SNOWFLAKE.ACCOUNT_USAGE.grants_to_users  \n                    WHERE role = 'ACCOUNTADMIN'  \n                      AND deleted_on IS NULL  \n                                  )  \n          ))  \n    THEN  \n        CALL system$send_email(  \n        'my_email_int',  \n        'my_id@domain.com',  \n        'Email Alert: MFA not used',  \n        'Hi, Please note MFA is not being used in Snowflake account\nSection Title: **Snowflake Native Alerts** > Introducing Snowflake Native Alerts > The Alert\nContent:\n- abc12345.' );\n```\nSection Title: **Snowflake Native Alerts** > Introducing Snowflake Native Alerts > The Alert\nContent:\nFor more details on `CALL system$send_email()` stored proc, please visit the documentation [here](https://docs.snowflake.com/en/sql-reference/email-stored-procedures.html) .\nAdditionally, we need to resume this alert:\n```\nALTER ALERT myalert RESUME;\n```\nSection Title: **Snowflake Native Alerts** > Introducing Snowflake Native Alerts > The Output\nContent:\nThis is the output email that I received:\nPress enter or click to view image in full size\nImage by Author\nTo prevent alerts from unnecessarily executing and incurring cost, please be a good samaritan and disable/drop your alerts:\n```\n-- Disable alerts  \nALTER ALERT myalert SUSPEND;  \n  \n-- Drop alerts  \nDROP ALERT myalert;\n```\nAdditionally:\nYou can edit the action script to send emails directly to the end users instead of an admin. But their email addresses need to be verified in their Snowflake profile and added to the notification integration.\nSending tabular data can be tricky, but you should consider using [python tabulate](https://pypi.org/project/tabulate/) .\nSection Title: **Snowflake Native Alerts** > Monitoring & Managing your alerts\nContent:\nLet’s see the show and describe commands syntax:\n```\n-- Show Alerts  \nSHOW [ TERSE ] ALERTS [ LIKE '<pattern>' ]  \n  [ IN { ACCOUNT |   \n         DATABASE [ <db_name> ] |   \n         [ SCHEMA ] [ <schema_name> ]   \n       }   \n  ]  \n  [ STARTS WITH '<name_string>' ]  \n  [ LIMIT <rows> [ FROM '<name_string>' ] ]  \n;  \n  \n-- Describe Alerts  \nDESC[RIBE] ALERT <name>;\n```\nThese will help us understand the state and execution status of our alerts:\n```\nSHOW ALERTS LIKE 'myalert';  \nDESC ALERT myalert;\n```\nSection Title: **Snowflake Native Alerts** > Monitoring & Managing your alerts\nContent:\n```\n+-------------------------------+---------+-------------------+-------------+--------------+---------+------------+----------+-----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+  \n|          created_on           |  name   |   database_name   | schema_name |    owner     | comment | warehouse  | schedule |   state   |\nSection Title: **Snowflake Native Alerts** > Monitoring & Managing your alerts\nContent:\ncondition                                                                                                                                                                      |                                                                                      action                                                                                      |\nSection Title: **Snowflake Native Alerts** > Monitoring & Managing your alerts\nContent:\n+-------------------------------+---------+-------------------+-------------+--------------+---------+------------+----------+-----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+  \n| 2023-01-25 20:24:03.143 -0800 | MYALERT | NATIVE_ALERTS_RND | PUBLIC      | ACCOUNTADMIN |         | COMPUTE_WH | 1 minute | suspended | SELECT event_timestamp AS event_time, user_name, client_IP, reported_client_type, first_authentication_factor,\nSection Title: **Snowflake Native Alerts** > Monitoring & Managing your alerts\nContent:\nsecond_authentication_factor FROM snowflake.account_usage.login_history WHERE second_authentication_factor IS NULL  AND (reported_client_type = 'SNOWFLAKE_UI' OR reported_client_type = 'OTHER') ORDER BY event_time DESC LIMIT 10 | CALL system$send_email('my_email_int', 'my_id@domain.com', 'Email Alert: MFA not used', 'Hi, Please note MFA is not being used in Snowflake account - abc12345.')\nSection Title: **Snowflake Native Alerts** > Monitoring & Managing your alerts\nContent:\n|  \n+-------------------------------+---------+-------------------+-------------+--------------+---------+------------+----------+-----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n```\nSection Title: **Snowflake Native Alerts** > Monitoring & Managing your alerts\nContent:\nI like how the alert parameters we defined earlier are neatly segregated into columns here, i.e., name, warehouse, and schedule. It is intelligent enough to also segregate the condition and the action.\nNow, let’s check out the syntax for alert executions:\n```\nALERT_HISTORY(  \n      [ SCHEDULED_TIME_RANGE_START => <constant_expr> ]  \n      [, SCHEDULED_TIME_RANGE_END => <constant_expr> ]  \n      [, RESULT_LIMIT => <integer> ]  \n      [, ALERT_NAME => '<string>' ] )\n```\n```\nSELECT *  \nFROM TABLE(INFORMATION_SCHEMA.alert_history(  \n    scheduled_time_range_start=>DATEADD('day', -1, CURRENT_TIMESTAMP())))  \nORDER BY scheduled_time DESC  \n;\n```\nI don’t have too many alerts so I’ve skipped some of the parameter inputs to Alert History.\nSection Title: **Snowflake Native Alerts** > Monitoring & Managing your alerts\nContent:\n```\n+---------+-------------------+-------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+-----------+----------------+-------------------+-------------------------------+-------------------------------+  \n|  NAME   |   DATABASE_NAME   | SCHEMA_NAME |\nSection Title: **Snowflake Native Alerts** > Monitoring & Managing your alerts\nContent:\nCONDITION                                                                                                                                                                      |          CONDITION_QUERY_ID          |                                                                              ACTION                                                                               |           ACTION_QUERY_ID            |   STATE   | SQL_ERROR_CODE | SQL_ERROR_MESSAGE |        SCHEDULED_TIME         |        COMPLETED_TIME         |\nSection Title: **Snowflake Native Alerts** > Monitoring & Managing your alerts\nContent:\n+---------+-------------------+-------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+-----------+----------------+-------------------+-------------------------------+-------------------------------+  \n| MYALERT | NATIVE_ALERTS_RND | PUBLIC      | SELECT event_timestamp AS event_time, user_name, client_IP, reported_client_type, first_authentication_factor, second_authentication_factor FROM\nSection Title: **Snowflake Native Alerts** > Monitoring & Managing your alerts\nContent:\nsnowflake.account_usage.login_history WHERE second_authentication_factor IS NULL  AND (reported_client_type = 'SNOWFLAKE_UI' OR reported_client_type = 'OTHER') ORDER BY event_time DESC LIMIT 10 | 01a9e66a-0402-7758-0059-bd030026751e | CALL system$send_email('my_email_int', 'my_id@domain.com', 'Email Alert: MFA not used', 'Hi, Please note MFA is not being used in Snowflake account - abc12345.')\nSection Title: **Snowflake Native Alerts** > Monitoring & Managing your alerts\nContent:\n| 01a9e66a-0402-7758-0059-bd0300267526 | TRIGGERED |              0 |                   | 2023-01-25 20:26:06.014 -0800 | 2023-01-25 20:26:14.874 -0800 |  \n+---------+-------------------+-------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+-----------+----------------+-------------------+-------------------------------+-------------------------------+\n```\nSection Title: **Snowflake Native Alerts** > Monitoring & Managing your alerts\nContent:\nThis gives you information on the query ids for the condition and the action, execution state, errors, and timings.\nSection Title: **Snowflake Native Alerts** > Cost\nContent:\nTaking you back to the initial syntax we had:\n```\nCREATE [ OR REPLACE ] ALERT [ IF NOT EXISTS ] <alert name>  \n  WAREHOUSE = <warehouse name>  \n  SCHEDULE = '{ <num> MINUTE | USING CRON <expr> <time zone> }'  \n-- Condition    \nIF( EXISTS(  \n    <condition statement>  \n))  \n-- Action  \n  THEN  \n    <action statement>  \n;\n```\nYou are only charged based on the compute used through the virtual warehouse for the execution of your condition and action queries.\nYou are **not** charged for sending the email.\nSection Title: ... > [Snowflake Native Alerts Streamlit App](https://github.com/prathamesh-nimkar/native_alerts)\nContent:\nSo far we have seen a simple example to set up alerts for Admins to monitor users with AccountAdmin role who are not using MFA to access Snowflake.\nNow let’s go ahead and extend that example with a Snowflake Alerting app on [Streamlit](https://streamlit.io/) . Here is what the basic workflow looks like:\nPress enter or click to view image in full size\nImage by Author\nWe are going to use a couple of more queries from the same [Github repo — SnowAlert](https://github.com/snowflakedb/SnowAlert/tree/master/packs) .\nThe Home Page 🏠 will have two forms:\n- Create a Snowflake connection 🔌\n- Create a Notification Integration 🤝\nThen we will add two pages to our app:\n- Security Alerts 🔑\n- Auth Alerts ⚠️\nFinally, we will create a Monitoring Dashboard 🖥️ that includes:\n- Show Alert Description 🛎️\n- Show Alert History 📜\nHere’s a nifty video of the app in action:\nSection Title: ... > [Snowflake Native Alerts Streamlit App](https://github.com/prathamesh-nimkar/native_alerts)\nContent:\nStreamlit Monitoring App usingNative Alerts, Video by Author\nThis brings me to the end of my post, I do hope you find this useful. Feel free to experiment with or extend this use-case. Or perhaps you have another use-case in mind, do keep us posted on what you come up with.\nSince this feature is in Private Preview, there are on-going developments to be expected and so I would advise not to use in Production. (Update: as of Feb 8, 2023 — it is **Public** Preview, however, please don’t do Production deployments).\nSection Title: ... > [Snowflake Native Alerts Streamlit App](https://github.com/prathamesh-nimkar/native_alerts)\nContent:\nLast but not least, please do check out our careers page [here](https://careers.snowflake.com/) . We’re hiring across the board in multiple geographies. Also, don’t hesitate to reach out to me on Medium here or LinkedIn [here](https://www.linkedin.com/in/prathameshnimkar/) — my name is Prathamesh, and I’m a Data Cloud Architect at [Snowflake](https://snowflake.com/) , however, my opinions are personal and do not reflect those of Snowflake.\nReferences:\nSection Title: ... > [Snowflake Native Alerts Streamlit App](https://github.com/prathamesh-nimkar/native_alerts)\nContent:\n[Multi-factor Authentication or MFA](https://docs.snowflake.com/en/user-guide/security-mfa.html) & [Enrolling a Snowflake user in MFA](https://docs.snowflake.com/en/user-guide/security-mfa.html:~:text=MFA%20is%20enabled%20on%20a%20per-user%20basis;%20however,%20at%20this%20time,%20users%20are%20not%20automatically%20enrolled%20in%20MFA.%20To%20use%20MFA,%20users%20must%20enroll%20themselves.)\n[Notification Integration](https://docs.snowflake.com/en/sql-reference/email-stored-procedures.html) & [Sending an email](https://docs.snowflake.com/en/sql-reference/email-stored-procedures.html)\n[SnowAlert Github Repo](https://github.com/snowflakedb/SnowAlert) & [SnowAlert Security Monitoring SQL](https://github.com/snowflakedb/SnowAlert/blob/master/packs/snowflake_security_monitoring.sql)\n[Python tabulate](https://pypi.org/project/tabulate/)\n[Streamlit](https://streamlit.io/)\nSnowflake\nAlerts\nSection Title: ... > [Snowflake Native Alerts Streamlit App](https://github.com/prathamesh-nimkar/native_alerts)\nContent:\nStreamlit\nNotifications\nSnowflake Data Cloud\n--\n--\n2\n[](https://medium.com/snowflake?source=post_page---post_publication_info--24e3d8b3b31e---------------------------------------)\n[](https://medium.com/snowflake?source=post_page---post_publication_info--24e3d8b3b31e---------------------------------------)\n[## Published in Snowflake Builders Blog: Data Engineers, App Developers, AI, & Data Science](https://medium.com/snowflake?source=post_page---post_publication_info--24e3d8b3b31e---------------------------------------)\n10.3K followers\n· Last published 8 hours ago\nBest practices, tips & tricks from Snowflake experts and community\nSection Title: **Snowflake Native Alerts** > Written by Prathamesh Nimkar\nContent:\n257 followers\n· 72 following\nTech Enthusiast — Data | LinkedIN: https://www.linkedin.com/in/prathameshnimkar/\n ... \nSection Title: **Snowflake Native Alerts** > Responses (2)\nContent:\n[Text to speech](https://speechify.com/medium?source=post_page-----24e3d8b3b31e---------------------------------------)"],"full_content":"Sitemap\n\n[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F24e3d8b3b31e&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderCollection&%7Estage=mobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)\n\nWrite\n\nSearch\n\n[## Snowflake Builders Blog: Data Engineers, App Developers, AI, & Data Science](https://medium.com/snowflake?source=post_page---publication_nav-34b6daafc07-24e3d8b3b31e---------------------------------------)\n\n·\n\n[](https://medium.com/snowflake?source=post_page---post_publication_sidebar-34b6daafc07-24e3d8b3b31e---------------------------------------)\n\nBest practices, tips & tricks from Snowflake experts and community\n\n# **Snowflake Native Alerts**\n\n## Set alerts and get notified\n\nPrathamesh Nimkar\n\n8 min read\n\n·\n\nJan 30, 2023\n\n\\--\n\n2\n\nListen\n\nShare\n\nPress enter or click to view image in full size\n\nPhoto by [Hugo Jehanne](https://unsplash.com/@hugojehanne?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)\n\nW hen architecting complex solutions and performing POCs with our awesome clients, we sometimes have to use ‘AccountAdmin’ role on our demo accounts. Due to the temporary nature of POCs and sometimes urgent deadlines, I have, and I hate to admit it, missed out on implementing [Multi-Factor Authentication or MFA](https://docs.snowflake.com/en/user-guide/security-mfa.html) as a best practice for enhanced security.\n\nOur team at Snowflake has decided that we need to enable MFA on all users with AccountAdmin role on all our demo accounts. It is important to note that [users cannot currently be automatically enrolled into MFA](https://docs.snowflake.com/en/user-guide/security-mfa.html:~:text=MFA%20is%20enabled%20on%20a%20per%2Duser%20basis%3B%20however%2C%20at%20this%20time%2C%20users%20are%20not%20automatically%20enrolled%20in%20MFA.%20To%20use%20MFA%2C%20users%20must%20enroll%20themselves.) , but need to enable it via a self-service process. Across hundreds of users within a demo account, this can be a very tedious thing to track. So, how do we track this enrolment?\n\n## Introducing Snowflake Native Alerts\n\nSnowflake users can now set up alerts and get notified when specific conditions are met. Please note this feature is currently in Private Preview. (Update: as of Feb 8, 2023 — it is **Public** Preview).\n\nLet’s take a quick look at the syntax:\n\n```\nCREATE [ OR REPLACE ] ALERT [ IF NOT EXISTS ] <alert name>  \n  WAREHOUSE = <warehouse name>  \n  SCHEDULE = '{ <num> MINUTE | USING CRON <expr> <time zone> }'  \n-- Condition    \nIF( EXISTS(  \n    <condition statement>  \n))  \n-- Action  \n  THEN  \n    <action statement>  \n;\n```\n\nAn alert is a schema-level object that specifies:\n\n* A **condition** that triggers an alert, for instance, a query running over two hours or in this case, users that are not using MFA when signing into Snowflake.\n* A **schedule** for how often a condition must be evaluated, for instance, every 24 hours or every minute, every Sunday at midnight, etc.\n* An **action** for what to do when the condition is satisfied, for instance, capture data in a table or send an email notification.\n\nComing back to our use-case — we want to create an alert for users with AccountAdmin role who are not using MFA when logging into Snowflake. This condition needs to be run every day (however, for the purposes of this exercise, I will choose the schedule to be every minute). And basis the results, we need to take some action, which will be to send an email to the admin — me.\n\n### The Condition\n\nFirst things first, let’s identify the condition required to be fulfilled.\n\n```\nSELECT  \n    event_timestamp, user_name, client_IP, reported_client_type,  \n    first_authentication_factor, second_authentication_factor  \nFROM snowflake.account_usage.login_history  \nWHERE second_authentication_factor IS NULL  \n    AND (  \n       reported_client_type = 'SNOWFLAKE_UI'  \n    OR reported_client_type = 'OTHER'  \n    )  \n;\n```\n\nThe above query has been sourced from:  \n[SnowAlert/blob/master/packs/snowflake\\_security\\_monitoring.sql](https://github.com/snowflakedb/SnowAlert/blob/master/packs/snowflake_security_monitoring.sql#:~:text=%2D%2D%20User%20not%20using%20Multi%20Factor%20Authentication)\n\nThis gives us **all users** who logged in without MFA. We need to make small changes to reflect users who have AccountAdmin privileges:\n\n```\n-- Sample script above, but updated for AccountAdmin roles only  \nSELECT  \n    event_timestamp, user_name, client_IP, reported_client_type,  \n    first_authentication_factor, second_authentication_factor  \nFROM snowflake.account_usage.login_history  \nWHERE second_authentication_factor IS NULL  \n    AND (  \n       reported_client_type = 'SNOWFLAKE_UI'  \n    OR reported_client_type = 'OTHER'  \n    )  \n    -- Searching for AccountAdmin users  \n    AND user_name IN (  \n      SELECT grantee_name  \n      FROM SNOWFLAKE.ACCOUNT_USAGE.grants_to_users  \n      WHERE role = 'ACCOUNTADMIN'  \n        AND deleted_on IS NULL)  \n;\n```\n\nPress enter or click to view image in full size\n\nUsers with AccountAdmin role logging into Snowflake without MFA, Image by Author\n\nAs can be seen from the image output above, _second\\_authentication\\_factor_ is empty, indicating that MFA was not used.\n\nOn the flip side, if we want to see users who are using MFA, we can simply change the _WHERE_ condition to reflect `second_authentication_factor IS **NOT** NULL` .\n\nPress enter or click to view image in full size\n\nUsers with AccountAdmin role logging into Snowflake with MFA, Image by Author\n\nSince we configured the Duo Mobile MFA, we can see it the _second\\_authentication\\_factor_ column in the image above.\n\n### The Action\n\nSince we plan to send out an email notification, we need to create a [Notification Integration](https://docs.snowflake.com/en/sql-reference/email-stored-procedures.html) . Here’s a quick look at the syntax:\n\n```\nCREATE [ OR REPLACE ] NOTIFICATION INTEGRATION [ IF NOT EXISTS ] <name>  \n  TYPE = EMAIL  \n  ENABLED = { TRUE | FALSE }  \n  ALLOWED_RECIPIENTS = ( '<email_address_1>' [ , ... '<email_address_N>' ] )  \n  [ COMMENT = '<string_literal>' ]  \n  ;\n```\n\nAnd the following would be for our specific requirement:\n\n```\n-- You will need AccountAdmin role to create a Notification Integration  \nCREATE NOTIFICATION INTEGRATION my_email_int  \n    TYPE=email  \n    ENABLED=true  \n    ALLOWED_RECIPIENTS=('my_id@domain.com')  \n    COMMENT='Created via Native Alerts App'  \n;  \n  \n  \n-- Required Grants  \nGRANT usage ON integration my_email_int to role <role_name>;\n```\n\n### The Alert\n\nPutting the pieces together within the alert syntax as we learnt above:\n\n```\n-- If you wish to grant the privileges to another role  \n-- Perform the following steps using AccountAdmin role  \nCREATE ROLE <alert_role>;  \nGRANT ROLE <alert_role> TO USER <alert_user>;  \nGRANT EXECUTE ALERT ON ACCOUNT TO ROLE <alert_role>;  \n  \n-- You may also require USAGE privileges on the database and warehouse  \n-- Using schema owner role, grant the following permissions to alert_role  \nGRANT CREATE ALERT ON SCHEMA <schema_name> TO ROLE <alert_role>;  \n-- or  \nGRANT OWNERSHIP ON SCHEMA <schema_name> TO ROLE <alert_role>;  \n  \n-- if you have performed the above steps in this snippet  \nUSE ROLE <alert_role>;  \n-- I am using AccountAdmin role, hence I will be ignoring the above steps  \n  \n-- Let's create the alert now  \nCREATE OR REPLACE ALERT myalert  \n    WAREHOUSE = compute_wh  \n    SCHEDULE = '1 minute'  \n    IF  \n        (EXISTS(  \n                  SELECT  \n                      event_timestamp, user_name, client_IP, reported_client_type,  \n                      first_authentication_factor, second_authentication_factor  \n                  FROM snowflake.account_usage.login_history  \n                  WHERE second_authentication_factor IS NULL  \n                  AND (  \n                     reported_client_type = 'SNOWFLAKE_UI'  \n                  OR reported_client_type = 'OTHER'  \n                  )  \n                  AND user_name IN (  \n                    SELECT grantee_name  \n                    FROM SNOWFLAKE.ACCOUNT_USAGE.grants_to_users  \n                    WHERE role = 'ACCOUNTADMIN'  \n                      AND deleted_on IS NULL  \n                                  )  \n          ))  \n    THEN  \n        CALL system$send_email(  \n        'my_email_int',  \n        'my_id@domain.com',  \n        'Email Alert: MFA not used',  \n        'Hi, Please note MFA is not being used in Snowflake account - abc12345.'  \n    );\n```\n\nFor more details on `CALL system$send_email()` stored proc, please visit the documentation [here](https://docs.snowflake.com/en/sql-reference/email-stored-procedures.html) .\n\nAdditionally, we need to resume this alert:\n\n```\nALTER ALERT myalert RESUME;\n```\n\n### The Output\n\nThis is the output email that I received:\n\nPress enter or click to view image in full size\n\nImage by Author\n\nTo prevent alerts from unnecessarily executing and incurring cost, please be a good samaritan and disable/drop your alerts:\n\n```\n-- Disable alerts  \nALTER ALERT myalert SUSPEND;  \n  \n-- Drop alerts  \nDROP ALERT myalert;\n```\n\nAdditionally:\n\n* You can edit the action script to send emails directly to the end users instead of an admin. But their email addresses need to be verified in their Snowflake profile and added to the notification integration.\n* Sending tabular data can be tricky, but you should consider using [python tabulate](https://pypi.org/project/tabulate/) .\n\n## Monitoring & Managing your alerts\n\nLet’s see the show and describe commands syntax:\n\n```\n-- Show Alerts  \nSHOW [ TERSE ] ALERTS [ LIKE '<pattern>' ]  \n  [ IN { ACCOUNT |   \n         DATABASE [ <db_name> ] |   \n         [ SCHEMA ] [ <schema_name> ]   \n       }   \n  ]  \n  [ STARTS WITH '<name_string>' ]  \n  [ LIMIT <rows> [ FROM '<name_string>' ] ]  \n;  \n  \n-- Describe Alerts  \nDESC[RIBE] ALERT <name>;\n```\n\nThese will help us understand the state and execution status of our alerts:\n\n```\nSHOW ALERTS LIKE 'myalert';  \nDESC ALERT myalert;\n```\n\n```\n+-------------------------------+---------+-------------------+-------------+--------------+---------+------------+----------+-----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+  \n|          created_on           |  name   |   database_name   | schema_name |    owner     | comment | warehouse  | schedule |   state   |                                                                                                                                                                     condition                                                                                                                                                                      |                                                                                      action                                                                                      |  \n+-------------------------------+---------+-------------------+-------------+--------------+---------+------------+----------+-----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+  \n| 2023-01-25 20:24:03.143 -0800 | MYALERT | NATIVE_ALERTS_RND | PUBLIC      | ACCOUNTADMIN |         | COMPUTE_WH | 1 minute | suspended | SELECT event_timestamp AS event_time, user_name, client_IP, reported_client_type, first_authentication_factor, second_authentication_factor FROM snowflake.account_usage.login_history WHERE second_authentication_factor IS NULL  AND (reported_client_type = 'SNOWFLAKE_UI' OR reported_client_type = 'OTHER') ORDER BY event_time DESC LIMIT 10 | CALL system$send_email('my_email_int', 'my_id@domain.com', 'Email Alert: MFA not used', 'Hi, Please note MFA is not being used in Snowflake account - abc12345.')                |  \n+-------------------------------+---------+-------------------+-------------+--------------+---------+------------+----------+-----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n```\n\nI like how the alert parameters we defined earlier are neatly segregated into columns here, i.e., name, warehouse, and schedule. It is intelligent enough to also segregate the condition and the action.\n\nNow, let’s check out the syntax for alert executions:\n\n```\nALERT_HISTORY(  \n      [ SCHEDULED_TIME_RANGE_START => <constant_expr> ]  \n      [, SCHEDULED_TIME_RANGE_END => <constant_expr> ]  \n      [, RESULT_LIMIT => <integer> ]  \n      [, ALERT_NAME => '<string>' ] )\n```\n\n```\nSELECT *  \nFROM TABLE(INFORMATION_SCHEMA.alert_history(  \n    scheduled_time_range_start=>DATEADD('day', -1, CURRENT_TIMESTAMP())))  \nORDER BY scheduled_time DESC  \n;\n```\n\nI don’t have too many alerts so I’ve skipped some of the parameter inputs to Alert History.\n\n```\n+---------+-------------------+-------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+-----------+----------------+-------------------+-------------------------------+-------------------------------+  \n|  NAME   |   DATABASE_NAME   | SCHEMA_NAME |                                                                                                                                                                     CONDITION                                                                                                                                                                      |          CONDITION_QUERY_ID          |                                                                              ACTION                                                                               |           ACTION_QUERY_ID            |   STATE   | SQL_ERROR_CODE | SQL_ERROR_MESSAGE |        SCHEDULED_TIME         |        COMPLETED_TIME         |  \n+---------+-------------------+-------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+-----------+----------------+-------------------+-------------------------------+-------------------------------+  \n| MYALERT | NATIVE_ALERTS_RND | PUBLIC      | SELECT event_timestamp AS event_time, user_name, client_IP, reported_client_type, first_authentication_factor, second_authentication_factor FROM snowflake.account_usage.login_history WHERE second_authentication_factor IS NULL  AND (reported_client_type = 'SNOWFLAKE_UI' OR reported_client_type = 'OTHER') ORDER BY event_time DESC LIMIT 10 | 01a9e66a-0402-7758-0059-bd030026751e | CALL system$send_email('my_email_int', 'my_id@domain.com', 'Email Alert: MFA not used', 'Hi, Please note MFA is not being used in Snowflake account - abc12345.') | 01a9e66a-0402-7758-0059-bd0300267526 | TRIGGERED |              0 |                   | 2023-01-25 20:26:06.014 -0800 | 2023-01-25 20:26:14.874 -0800 |  \n+---------+-------------------+-------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+-----------+----------------+-------------------+-------------------------------+-------------------------------+\n```\n\nThis gives you information on the query ids for the condition and the action, execution state, errors, and timings.\n\n## Cost\n\nTaking you back to the initial syntax we had:\n\n```\nCREATE [ OR REPLACE ] ALERT [ IF NOT EXISTS ] <alert name>  \n  WAREHOUSE = <warehouse name>  \n  SCHEDULE = '{ <num> MINUTE | USING CRON <expr> <time zone> }'  \n-- Condition    \nIF( EXISTS(  \n    <condition statement>  \n))  \n-- Action  \n  THEN  \n    <action statement>  \n;\n```\n\n* You are only charged based on the compute used through the virtual warehouse for the execution of your condition and action queries.\n* You are **not** charged for sending the email.\n\n## [Snowflake Native Alerts Streamlit App](https://github.com/prathamesh-nimkar/native_alerts)\n\nSo far we have seen a simple example to set up alerts for Admins to monitor users with AccountAdmin role who are not using MFA to access Snowflake.\n\nNow let’s go ahead and extend that example with a Snowflake Alerting app on [Streamlit](https://streamlit.io/) . Here is what the basic workflow looks like:\n\nPress enter or click to view image in full size\n\nImage by Author\n\n* We are going to use a couple of more queries from the same [Github repo — SnowAlert](https://github.com/snowflakedb/SnowAlert/tree/master/packs) .\n* The Home Page 🏠 will have two forms:  \n  \\- Create a Snowflake connection 🔌  \n  \\- Create a Notification Integration 🤝\n* Then we will add two pages to our app:  \n  \\- Security Alerts 🔑  \n  \\- Auth Alerts ⚠️\n* Finally, we will create a Monitoring Dashboard 🖥️ that includes:  \n  \\- Show Alert Description 🛎️  \n  \\- Show Alert History 📜\n\nHere’s a nifty video of the app in action:\n\nStreamlit Monitoring App usingNative Alerts, Video by Author\n\nThis brings me to the end of my post, I do hope you find this useful. Feel free to experiment with or extend this use-case. Or perhaps you have another use-case in mind, do keep us posted on what you come up with.\n\nSince this feature is in Private Preview, there are on-going developments to be expected and so I would advise not to use in Production. (Update: as of Feb 8, 2023 — it is **Public** Preview, however, please don’t do Production deployments).\n\nLast but not least, please do check out our careers page [here](https://careers.snowflake.com/) . We’re hiring across the board in multiple geographies. Also, don’t hesitate to reach out to me on Medium here or LinkedIn [here](https://www.linkedin.com/in/prathameshnimkar/) — my name is Prathamesh, and I’m a Data Cloud Architect at [Snowflake](https://snowflake.com/) , however, my opinions are personal and do not reflect those of Snowflake.\n\nReferences:\n\n* [Multi-factor Authentication or MFA](https://docs.snowflake.com/en/user-guide/security-mfa.html) & [Enrolling a Snowflake user in MFA](https://docs.snowflake.com/en/user-guide/security-mfa.html:~:text=MFA%20is%20enabled%20on%20a%20per-user%20basis;%20however,%20at%20this%20time,%20users%20are%20not%20automatically%20enrolled%20in%20MFA.%20To%20use%20MFA,%20users%20must%20enroll%20themselves.)\n* [Notification Integration](https://docs.snowflake.com/en/sql-reference/email-stored-procedures.html) & [Sending an email](https://docs.snowflake.com/en/sql-reference/email-stored-procedures.html)\n* [SnowAlert Github Repo](https://github.com/snowflakedb/SnowAlert) & [SnowAlert Security Monitoring SQL](https://github.com/snowflakedb/SnowAlert/blob/master/packs/snowflake_security_monitoring.sql)\n* [Python tabulate](https://pypi.org/project/tabulate/)\n* [Streamlit](https://streamlit.io/)\n\nSnowflake\n\nAlerts\n\nStreamlit\n\nNotifications\n\nSnowflake Data Cloud\n\n\\-- \n\n\\--\n\n2\n\n[](https://medium.com/snowflake?source=post_page---post_publication_info--24e3d8b3b31e---------------------------------------)\n\n[](https://medium.com/snowflake?source=post_page---post_publication_info--24e3d8b3b31e---------------------------------------)\n\n[## Published in Snowflake Builders Blog: Data Engineers, App Developers, AI, & Data Science](https://medium.com/snowflake?source=post_page---post_publication_info--24e3d8b3b31e---------------------------------------)\n\n10\\.3K followers\n\n· Last published 8 hours ago\n\nBest practices, tips & tricks from Snowflake experts and community\n\n## Written by Prathamesh Nimkar\n\n257 followers\n\n· 72 following\n\nTech Enthusiast — Data | LinkedIN: <https://www.linkedin.com/in/prathameshnimkar/>\n\n## Responses (2)\n\n[](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--24e3d8b3b31e---------------------------------------)\n\nSee all responses\n\n[Help](https://help.medium.com/hc/en-us?source=post_page-----24e3d8b3b31e---------------------------------------)\n\n[Status](https://status.medium.com/?source=post_page-----24e3d8b3b31e---------------------------------------)\n\nAbout\n\nCareers\n\nPress\n\n[Blog](https://blog.medium.com/?source=post_page-----24e3d8b3b31e---------------------------------------)\n\n[Privacy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----24e3d8b3b31e---------------------------------------)\n\n[Rules](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----24e3d8b3b31e---------------------------------------)\n\n[Terms](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----24e3d8b3b31e---------------------------------------)\n\n[Text to speech](https://speechify.com/medium?source=post_page-----24e3d8b3b31e---------------------------------------)"}],"errors":[],"warnings":null,"usage":[{"name":"sku_extract_excerpts","count":4},{"name":"sku_extract_full","count":4}]}
