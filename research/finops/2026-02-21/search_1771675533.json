{"search_id":"search_8a411723085e4359a0030e884883a3e2","results":[{"url":"https://www.snowflake.com/en/blog/10-best-practices-every-snowflake-admin-can-do-to-optimize-resources/","title":"10 Best Practices for Optimizing Resources %%sep%% %%sitename%% Blog","publish_date":"2024-08-12","excerpts":["Section Title: ... > Best Practice #6: Monitor Warehouses That Are Approaching the Cloud Service Billing Threshold\nContent:\nThe following query looks at warehouses where cloud services costs comprise a high percentage of the workload. Overall for an account (and outside of serverless features), Snowflake will charge for cloud services only if they exceed 10% of the daily virtual warehouse credit consumption. Cloud services tasks are useful for meta-data operations such as BI tool discovery queries, heartbeat queries, SHOW commands, cache usage, and several other service optimizing features. So if you use 100 compute credits in a day, but you use 15 additional credits for cloud services (unlikely), you will be charged an additional 5 credits for that day for the 5 cloud service credits that were over the 10% allowance. This means 105 credits total would be billed for the day with Snowflake providing 10 free credits of cloud services usage.\n ... \nSection Title: ... > Guardrails for Automatic Scaling\nContent:\nOn a reactive basis, admins can monitor users, databases, tables, queries, and workloads through the ACCOUNT_USAGE schema shared with all Snowflake accounts. This data is commonly used to forecast usage trends and provide showback and chargeback billing for departments, teams, and workloads. Daily usage metrics are built into the platform for both individual users, account administrators, and organization administrators. This figure shows the built-in dashboard providing an hourly breakdown of credits for both compute and cloud services:\nSection Title: ... > Best Practice #9: Find Warehouses That Don’t Have Resource Monitors\nContent:\nResource monitors are a great way to proactively control workload budgets and prevent unexpected resource spikes. Resource monitors can help monitor both user usage and service account usage in Snowflake. First, you should have dedicated virtual warehouses for each of your loading, ELT, BI, reporting, and data science workloads as well as for other workloads. Accounts and warehouses can have total, yearly, monthly, weekly, and daily credit quotas. The following query will identify all warehouses that do not have a resource monitor:\n ... \nSection Title: ... > Bonus Best Practice: Use BI Partner Dashboards\nContent:\nTableau’s Enterprise Analytics team uses these dashboards to uncover emerging usage patterns and optimize warehouse cost efficiency.\n ... \nSection Title: ... > Bonus Best Practice: Use BI Partner Dashboards\nContent:\n[Qlik/Attunity](https://community.qlik.com/t5/Technology-Partners-Ecosystem-Documents/Qlik-amp-Snowflake-Usage-Dashboard/ta-p/1646629)\n[Sigma](https://www.sigmacomputing.com/blog/set-up-snowflake-monitoring-quickly-with-sigma-templates/)\n[Looker](https://looker.com/platform/blocks/source/cost-and-usage-analysis-by-snowflake)\n[Microsoft Power BI](https://medium.com/analytics-vidhya/snowflake-power-bi-snowflake-usage-report-f628dadbdc85)\n[ThoughtSpot](https://docs.thoughtspot.com/cloud/latest/spotapps-snowflake)\nSection Title: 10 Best Practices Every Snowflake Admin Can Do to Optimize Resources > ... > Conclusion\nContent:\nWith Snowflake’s highly elastic compute and per-second billing model, account administrators should monitor usage, growth, and resource efficiency on an ongoing basis to make sure they match performance requirements and budgets. Even though Snowflake can help to optimize resources automatically, there are opportunities for account administrators to further tune their deployment, especially as their compute footprint grows. We recommend these basic best practices for monitoring and optimizing resources to avoid common pitfalls that are easy to overlook.\nSection Title: 10 Best Practices Every Snowflake Admin Can Do to Optimize Resources > ... > Conclusion > Authors\nContent:\nDavid A. Spezia\nMike Klaczynski"]},{"url":"https://www.flexera.com/blog/finops/snowflake-native-apps/","title":"Snowflake Native Apps 101: Build and monetize data apps (2026)","publish_date":"2026-01-27","excerpts":["[Book your personalized demo](https://www.flexera.com/products/flexera-one/saas-management)\nIT Visibility\nITAM\nSnow Atlas\nCloud License Management\nSaaS Management\nFinOps\nCloud Cost Optimization\nCloud Commitment Management\nContainer Optimization\nVirtual Machine Optimization\nData Cloud Optimization\nApplication Readiness\nSecurity\nIntegrations\nTechnology Intelligence Platform\nAll Products\nSuccessCustomer SuccessServices & TrainingSupport[2025 Technology Intelligence Awards](https://info.flexera.com/ITAM-REPORT-State-of-IT-Asset-Management)The results are in—see how our 2025 winners and honorable mentions are shaping the future of Technology Intelligence.\n ... \nSection Title: ... > What Are Snowflake Native Applications?\nContent:\n**Snowflake Native Apps** are applications built using the Snowflake Native App Framework, which allows developers to create, test and deploy applications directly within Snowflake’s Data Cloud. These Native Apps leverage Snowflake’s core features like stored procedures , user-defined functions (Snowflake UDFs) and the [Snowpark API](https://docs.snowflake.com/en/developer-guide/snowpark/index) , all while keeping the data secure by running the code on your data stored in Snowflake. Native apps are available on the Snowflake Marketplace . You can discover and install them quickly, just like downloading an app on your smartphone.\nSection Title: ... > What Are Snowflake Native Applications?\nContent:\n**TL;DR:\n** **What They Are** — Snowflake Native Apps run entirely within Snowflake, eliminating the need to move data out for processing.\n**How They Work** — Snowflake Native Apps operate in your Snowflake account, using your existing data without external connections. Developers create and distribute them via the Snowflake Marketplace.\n**Why Use Them** :\n**Fast** — Snowflake Native Apps process data directly in Snowflake, reducing latency.\n**Secure** — Snowflake Native Apps don’t access or store data outside your account, relying on Snowflake’s encryption and access controls.\n**Scalable** — Snowflake Native Apps can grow alongside your Snowflake resources, handling larger datasets or more users.\nSnowflake Native Apps (Source: [Snowflake](https://www.snowflake.com/en/data-cloud/workloads/applications/native-apps/) )\nSection Title: ... > 1) **Native Integration with Snowflake Services**\nContent:\nSnowflake Native Apps work directly with Snowflake’s core services. They use stored procedures , user-defined functions (Snowflake UDFs UDFs) and the Snowpark API, making them efficient and seamless.\n ... \nSection Title: Snowflake Native Apps 101: Build and monetize data apps (2026) > ... > ➥ **Enhanced Performance**\nContent:\nSnowflake Native apps utilize the consumer’s Snowflake compute resources, which ensures optimal performance tailored to the existing workload. Consumers benefit from Snowflake’s underlying scalability and processing power, resulting in faster query execution and application responsiveness​.\n ... \nSection Title: Snowflake Native Apps 101: Build and monetize data apps (2026) > FAQs\nContent:\n[Empowering users with intuitive, actionable data: introducing Data Explorer](https://www.flexera.com/blog/it-visibility/empowering-users-with-intuitive-actionable-data-introducing-data-explorer/ \"Empowering users with intuitive, actionable data: introducing Data Explorer\")\n[From Spot Eco to Flexera One Cloud Commitment Management: A new era of automated cloud cost optimization](https://www.flexera.com/blog/finops/from-spot-eco-to-flexera-one-cloud-commitment-management-a-new-era-of-automated-cloud-cost-optimization/ \"From Spot Eco to Flexera One Cloud Commitment Management: A new era of automated cloud cost optimization\")\n[The practical FinOps roadmap series: What to do before you start practicing FinOps (1/4)](https://www.flexera.com/blog/finops/the-practical-finops-roadmap-series-what-to-do-before-you-start-practicing-finops-1-4/ \"The practical FinOps roadmap series: What to do before you start practicing FinOps"]},{"url":"https://www.snowflake.com/en/blog/managing-snowflakes-compute-resources/","title":"Managing Snowflake's Compute Resources","publish_date":"2024-08-12","excerpts":["Section Title: Category\nContent:\nAI/ML At Snowflake Partner & Customer Value Industry Solutions Product & Technology Strategy & Insights\nData Engineering\nDec 16, 2020 | 10 min read\nSection Title: Managing Snowflake’s Compute Resources\nContent:\n*This is the 3rd blog in our series on Snowflake Resource Optimization. * In parts 1 and 2 of this blog series, we showed you how Snowflake’s unique architecture allows for a virtually unlimited number of compute resources to be accessed near-instantaneously. We also provided best practices for administering these compute resources to optimize performance and reduce credit consumption. In this blog post, I’ll show you the best practices our internal Snowflake team uses to manage our own usage of Snowflake. My name is Tamir Rozenberg and I support one of the world's largest Snowflake deployments - it just so happens to be the one we have here internally at Snowflake. Prior to Snowflake, I managed Instacart's Snowflake platform. In the 4 years I’ve been overseeing Snowflake resources, I’ve developed several strategies that have helped me implement highly efficient and performant deployments. I'll share those strategies with you in this post.\nSection Title: Managing Snowflake’s Compute Resources\nContent:\nWhen we talk about the multi-cluster compute layer of Snowflake, we’re referring to the virtual warehouses that execute queries on the centralized storage layer. Below is the architectural diagram that shows the 3 components of the Snowflake platform.\n ... \nSection Title: Managing Snowflake’s Compute Resources > Monitoring Best Practices\nContent:\nNow that you have virtual warehouse resources running on Snowflake, let’s explore the various ways to monitor and manage them.\nWe provided 11 tips for optimizing your resources in our 2nd blog post .\nLet me show you three more ways to manage your resource consumption.\n ... \nSection Title: Managing Snowflake’s Compute Resources > Monitoring Best Practices > Identifying Costly Queries\nContent:\nIf you followed the best practices above and you still want to find the query on a single warehouse that consumes most of your credits, you can query account_usage to get more insight about costly queries or queries that require tuning. Below you can find a few examples for queries you can use: **Here’s an example that breaks down by day and username of long-running queries that run frequently:**\n ... \nSection Title: Managing Snowflake’s Compute Resources > Monitoring Best Practices > Identifying Costly Queries\nContent:\nACCOUNT_USAGE . QUERY_HISTORYrn   where (  error_message  IS  NULLrn         or  error_code  = 604 ) rn         and  warehouse_size  IS NOT NULL  rn         and  START_TIME  >=  DATEADD ( DAY , - 30 , CURRENT_TIMESTAMP ( ) rn         )  rn                                 )  rnORDER  BY  total_credit  desc\n```\nSection Title: Managing Snowflake’s Compute Resources > Monitoring Best Practices > Identifying Costly Queries\nContent:\nCopy\nSection Title: Managing Snowflake’s Compute Resources > ... > Using the QUERY_TAG Session Parameter\nContent:\n[QUERY_TAG](https://docs.snowflake.com/en/sql-reference/parameters.html) is an optional string that can be used to tag queries and other SQL statements executed within a session. Using it is helpful when multiple applications are sharing the same user ID and warehouse. If you use it wisely and consistently, you can identify workload trends such as performance issues and cost issues. As a best practice, tag your session with a unique identifier for your workload. Then, all the workload activities will be recorded with the tag you specified. This can help you identify issues with certain elements of the data pipeline. **Here’s an example of using this parameter:**\n```\nALTER SESSION SET  QUERY_TAG = 'My workload tag'\n```\nCopy\nAs shown in the following figure, you can search for specific tags using the Snowflake History tab. This can help you identify the slowest part of your pipeline."]},{"url":"https://www.snowflake.com/en/developers/guides/resource-optimization-usage-monitoring/","title":"Resource Optimization: Usage Monitoring - Snowflake","excerpts":["Section Title: Resource Optimization: Usage Monitoring\nContent:\nMatt Meredith\n[fork repo](https://github.com/Snowflake-Labs/sfquickstarts/tree/master/site/sfguides/src/resource-optimization-usage-monitoring)\nSection Title: Resource Optimization: Usage Monitoring > Overview\nContent:\nThis resource optimization guide represents one module of the four contained in the series. These guides are meant to help customers better monitor and manage their credit consumption. Helping our customers build confidence that their credits are being used efficiently is key to an ongoing successful partnership. In addition to this set of Snowflake Quickstarts for Resource Optimization, Snowflake also offers community support as well as Training and Professional Services offerings. To learn more about the paid offerings, take a look at upcoming education and training .\nThis blog post can provide you with a better understanding of Snowflake's Resource Optimization capabilities.\nContact our team at marketing@snowflake.com , we appreciate your feedback.\nSection Title: Resource Optimization: Usage Monitoring > Overview > Usage Monitoring\nContent:\nUsage Monitoring queries are designed to identify the warehouses, queries, tools, and users that are responsible for consuming the most credits over a specified period of time. These queries can be used to determine which of those resources are consuming more credits than anticipated and take the necessary steps to reduce their consumption.\nSection Title: Resource Optimization: Usage Monitoring > Overview > What You’ll Learn\nContent:\nhow to analyze consumption trends and patterns\nhow to identify consumption anomolies\nhow to analyze partner tool consumption metrics\nSection Title: Resource Optimization: Usage Monitoring > Overview > What You’ll Need\nContent:\nA Snowflake Account\nAccess to view [Account Usage Data Share](https://docs.snowflake.com/en/sql-reference/account-usage.html)\n ... \nSection Title: Resource Optimization: Usage Monitoring > Query Tiers > Tier 2 Queries\nContent:\nTier 2 queries, while still playing a vital role in the process, offer an extra level of depth around Resource Optimization and while they may not be essential to all customers and their workloads, it can offer further explanation as to any additional areas in which over-consumption may be identified.\n ... \nSection Title: Resource Optimization: Usage Monitoring > Forecasting Usage/Billing (T1) > Tier 1 > SQL\nContent:\n--STORAGE COSTS\nSELECT\n'Storage' AS WAREHOUSE_GROUP_NAME\n,'Storage' AS WAREHOUSE_NAME\n,NULL AS GROUP_CONTACT\n,NULL AS GROUP_COST_CENTER\n,NULL AS GROUP_COMMENT\n,SU.USAGE_DATE\n,SU.USAGE_DATE\n,NULL AS CREDITS_USED\n,$CREDIT_PRICE\n,((STORAGE_BYTES + STAGE_BYTES + FAILSAFE_BYTES)/(1024*1024*1024*1024)*23)/DA.DAYS_IN_MONTH AS DOLLARS_USED\n,'ACTUAL COMPUTE' AS MEASURE_TYPE\nfrom    SNOWFLAKE.ACCOUNT_USAGE.STORAGE_USAGE SU\nJOIN    (SELECT COUNT(*) AS DAYS_IN_MONTH,TO_DATE(DATE_PART('year',D_DATE)||'-'||DATE_PART('month',D_DATE)||'-01') as DATE_MONTH FROM SNOWFLAKE_SAMPLE_DATA.TPCDS_SF10TCL.DATE_DIM GROUP BY TO_DATE(DATE_PART('year',D_DATE)||'-'||DATE_PART('month',D_DATE)||'-01')) DA ON DA.DATE_MONTH = TO_DATE(DATE_PART('year',USAGE_DATE)||'-'||DATE_PART('month',USAGE_DATE)||'-01')\n) A\ngroup by 1\n),\nFORECASTED_USAGE_SLOPE_INTERCEPT as\n ... \nSection Title: Resource Optimization: Usage Monitoring > ... > Tier 2 > Description:\nContent:\nLooks at the top 50 longest running queries to see if there are patterns\n ... \nSection Title: Resource Optimization: Usage Monitoring > ... > Tier 2 > How to Interpret Results:\nContent:\nFocus on Warehouses that are using a high volume and ratio of cloud services compute. Investigate why this is the case to reduce overall cost (might be cloning, listing files in S3, partner tools setting session parameters, etc.). The goal to reduce cloud services credit consumption is to aim for cloud services credit to be less than 10% of overall credits."]},{"url":"https://www.snowflake.com/en/pricing-options/cost-and-performance-optimization/","title":"FinOps on Snowflake: Built-In Cost and Performance Control","excerpts":["Section Title: Resources\nContent:\nPricing calculator overview Pricing calculator FAQs Snowflake Performance Index\n[*Image Source*](https://squadrondata.com/org-impact-comparison-spark-based-saas-vs-snowflake/)\n ... \nSection Title: FinOps on Snowflake > Go from painstaking configurations to a proven, fully-managed service\nContent:\nSince its founding in 2012, Snowflake has provided automated cluster management, maintenance and upgrades — all without downtime — so you can spend time on valuable data projects\nGet **out-of-the-box governance and security through Snowflake Horizon Catalog** without extra configurations or protocols\nSection Title: FinOps on Snowflake > Go from piecemeal dashboards to built-in cost & performance management\nContent:\nGet granular visibility, control and optimization of Snowflake spend through a unified Cost Management Interface .\nCheck query performance easily to proactively save on costs.\nAutomatically benefit from regular rollouts of performance improvements across all workloads.\n ... \nSection Title: FinOps on Snowflake > Saving time on platform admin. Getting to market faster.\nContent:\nTravelpass CTC Natwest\nTravel and Hospitality “Now, we aren’t so focused on how to build things. We are focused more on what to build.” Dan Shah\nManager of Data Science Read the story * **1 week** for 130 Dynamic Tables to be in production after migration\n**65%** cost savings switching from Databricks to Snowflake\nRead the case study Financial Services “Now with fewer ephemeral failures and higher visibility in Snowflake, we have a platform that’s much easier and cost-effective to operate than managed Spark.” David Trumbell\nHead of Data Engineering, CTC Read the story * **1st** data availability deadline was hit everyday for the 1st time\n**54%** cost savings switching from managed Spark to Snowflake\nSection Title: FinOps on Snowflake > Saving time on platform admin. Getting to market faster.\nContent:\nRead the case study Financial Services “The speed at which we’ve delivered wouldn’t have been possible with other providers.” Kaushik Ghosh Dastidar\nHead of ESG Cloud Solutions, NatWest Read the story * **6x** reduction in onboarding time from 3 months to 2 weeks\n**$750K** saved in salaries & staff training costs\nRead the case study\n[Resource #### Snowflake Joins the FinOps Foundation Snowflake joins The FinOps Foundation as a Premier Enterprise Member to provide thought leadership and set industry financial best practices. Read more](https://www.finops.org/members/snowflake/)\nResource #### Snowflake Pricing Calculator Curious about Snowflake pricing? Our Snowflake pricing calculator shows credit usage, warehouse costs, and total expenses. Access calculator\nSection Title: FinOps on Snowflake > Saving time on platform admin. Getting to market faster.\nContent:\nGuide #### Definitive Guide to Managing Spend in Snowflake Learn about considerations for consumption models such as Snowflake's, frameworks for better managing spend, and more. Get the guide\nSection Title: FinOps on Snowflake > Even More To Explore > Snowflake Documentation\nContent:\nAccess documentation on Managing Costs and Optimizing Performance in Snowflake.\nRead about Managing Costs\nRead about Optimizing Performance\n ... \nSection Title: FinOps on Snowflake > Even More To Explore > Snowflake Documentation > Priority Support\nContent:\nLearn more about how our Priority Support team can help you reduce consumption spend through performance monitoring, observability, and management.\nLearn about Priority Support\nSection Title: FinOps on Snowflake > Where Data Does More\nContent:\n30-day free trial\nNo credit card required\nCancel anytime\nstart for free\nwatch a demo\n**Subscribe to our monthly newsletter** Stay up to date on Snowflake’s latest products, expert insights and resources—right in your inbox!\n*\n*"]},{"url":"https://medium.com/snowflake/best-practices-to-optimize-resource-optimization-in-snowflake-837218c6db59","title":"Best Practices to optimize Resource Optimization in Snowflake | by Isabella Renzetti | Snowflake Builders Blog: Data Engineers, App Developers, AI, & Data Science | Medium","publish_date":"2023-04-07","excerpts":["Section Title: Best Practices to optimize Resource Optimization in Snowflake > ... > **Conclusion**\nContent:\nDue to Snowflake’s high elasticity of calculation and per-second billing model, account administrators should constantly monitor resource utilization, growth and efficiency to ensure they match performance requirements and budget.\nFor companies seeking to enhance their cost governance, it is advisable to analyze their usage patterns and detect any inadequacies or inefficiencies. Snowflake’s products can offer significant benefits in this regard, such as automating usage monitoring and setting up triggers to maintain manageable costs as usage increases.\nTo begin examining your own company’s usage patterns, it is recommended to explore the Resource Optimization Quick Start Guide:"]},{"url":"https://medium.com/snowflake/finops-cost-management-in-snowflake-insights-from-a-streamlit-app-92d74477c137","title":"FinOps Cost Management in Snowflake — Insights from a Streamlit App | by Eladio Rincón Herrera | Snowflake Builders Blog: Data Engineers, App Developers, AI, & Data Science | Medium","publish_date":"2025-10-17","excerpts":["Section Title: ... > How Snowflake Maps Its Cost Data Model to FOCUS v1.2\nContent:\nPress enter or click to view image in full size\nFOCUS in Snowflake\nSection Title: ... > What is Possible in the Snowflake Portal\nContent:\nThe Snowflake web portal provides native visibility into cost and usage, enabling FinOps practices directly within the platform. From the Billing & Usage section, customers can download detailed usage statements that include credits consumed, billing currency, and invoiced amounts. These statements serve as the source of truth for financial reconciliation and can be mapped into the FOCUS specification for standardized reporting.\nIn addition, the portal exposes Snowsight dashboards for monitoring warehouse utilization, query activity, and service-level costs. Finance and engineering teams can leverage these dashboards to track trends, attribute spend, and spot anomalies without external tools. While deeper FinOps workflows may require exporting data to FOCUS-compliant pipelines, the portal ensures that organizations always have a clear, auditable view of Snowflake consumption and spend."]},{"url":"https://www.snowflake.com/en/developers/guides/well-architected-framework-performance/","title":"Performance","excerpts":["Section Title: Performance\nContent:\nWell Architected Framework Team\n[fork repo](https://github.com/Snowflake-Labs/sfquickstarts/tree/master/site/sfguides/src/well-architected-framework-performance)\nSection Title: Performance > Overview\nContent:\nOptimizing performance on Snowflake is crucial for efficient data\nanalysis. This guidance, for data architects, developers, and\nadministrators, outlines best practices for designing, implementing, and\nmaintaining data workloads.\nApplying these recommendations streamlines operations, enhances user\nexperience, and improves business value through increased revenue and\nreduced costs. For instance, faster query execution translates to\nquicker insights and greater adoption.\nPerformance tuning often balances performance and cost, with\nimprovements frequently benefiting both. Snowflake's autoscaling\ncapabilities, for example, ensure consistent performance by dynamically\nallocating resources as concurrency increases, while also providing cost\nefficiency by scaling down during lower demand.\nSection Title: Performance > ... > Principles > Establish and validate performance objectives\nContent:\nDefine clear, measurable, and achievable performance targets within\ntechnical and budgetary limits before application design. Consider key\nworkload characteristics."]}],"usage":[{"name":"sku_search","count":1}]}
