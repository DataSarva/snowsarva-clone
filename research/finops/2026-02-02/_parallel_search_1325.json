{"search_id":"search_defcbd8bf4e54e059282d0413bb377f0","results":[{"url":"https://docs.snowflake.com/en/sql-reference/account-usage/query_attribution_history","title":"QUERY_ATTRIBUTION_HISTORY view - Snowflake Documentation","excerpts":["[DOCUMENTATION](https://docs.snowflake.com)\n\n/\n\n[Get started](/en/user-guide-getting-started)\n\n[Guides](/en/guides)\n\n[Developer](/en/developer)\n\n[Reference](/en/reference)\n\n[Release notes](/en/release-notes/overview)\n\n[Tutorials](/en/tutorials)\n\n[Status](https://status.snowflake.com)\n\n[Reference](/en/reference) [General reference](/en/sql-reference) [SNOWFLAKE database](/en/sql-reference/snowflake-db) [Account Usage](/en/sql-reference/account-usage) QUERY\\_ATTRIBUTION\\_HISTORY\n\nSchemas:\n    [ACCOUNT\\_USAGE](../account-usage.html)\n\n# QUERY\\_ ATTRIBUTION\\_ HISTORY view [¶]( \"Link to this heading\")\n\nThis Account Usage view can be used to determine the compute cost of a given query run on warehouses in your account\nin the last 365 days (1 year).\n\nFor more information, see [Viewing cost by tag in SQL](../../user-guide/cost-attributing.html) .\n\n## Columns [¶]( \"Link to this heading\")\n\n|Column name |Data type |Description |\n| --- | --- | --- |\n|`query_id` |VARCHAR |Internal/system-generated identifier for the SQL statement. |\n|`parent_query_id` |VARCHAR |Query ID of the parent query or NULL if the query does not have a parent. |\n|`root_query_id` |VARCHAR |Query ID of the topmost query in the chain or NULL if the query does not have a parent. |\n|`warehouse_id` |NUMBER |Internal/system-generated identifier for the warehouse that the query was executed on. |\n|`warehouse_name` |VARCHAR |Name of the warehouse that the query executed on. |\n|`query_hash` |VARCHAR |The [hash value](../../user-guide/query-hash.html) computed based on the canonicalized SQL text. |\n|`query_parameterized_hash` |VARCHAR |The [hash value](../../user-guide/query-hash.html) computed based on the parameterized query. |\n|`query_tag` |VARCHAR |Query tag set for this statement through the [QUERY\\_TAG](../parameters.html) session parameter. |\n|`user_name` |VARCHAR |User who issued the query. |\n|`start_time` |TIMESTAMP\\_LTZ |Time when query execution started (in the local time zone). |\n|`end_time` |TIMESTAMP\\_LTZ |Time when query execution ended (in the local time zone). |\n|`credits_attributed_compute` |NUMBER |Number of credits attributed to this query. Includes only the credit usage for the query execution and doesn’t include any warehouse idle time. |\n|`credits_used_query_acceleration` |NUMBER |Number of credits consumed by the [Query Acceleration Service](../../user-guide/query-acceleration-service) to accelerate the query. NULL if the query is not accelerated. . . The total cost for an accelerated query is the sum of this column and the `credits_attributed_compute` column. |\n\n## Usage notes [¶]( \"Link to this heading\")\n\n* Latency for this view can be up to eight hours.\n* This view displays results for any role granted the USAGE\\_VIEWER or GOVERNANCE\\_VIEWER [database role](../snowflake-db-roles) .\n\n\n* The value in the `credits_attributed_compute` column contains the warehouse credit usage for executing the query,\n  inclusive of any resizing and/or autoscaling of multi-cluster warehouse(s). This cost is attributed based on\n  the weighted average of the resource consumption.\n  \n  The value doesn’t include any credit usage for warehouse idle time. Idle time is a period\n  of time in which no queries are running in the warehouse and can be measured at the warehouse level.\n  \n  The value doesn’t include any other credit usage that is incurred as a result of query execution.\n  For example, the following are not included in the query cost:\n  \n    + Data transfer costs\n    + Storage costs\n    + Cloud services costs\n    + Costs for serverless features\n    + Costs for tokens processed by AI services\n* For queries that are executed concurrently, the cost of the warehouse is attributed to individual queries based on the\n  weighted average of their resource consumption during a given time interval.\n* Short-running queries (<= ~100ms) are currently too short for per query cost attribution and are not included in the view.\n* Data for all columns is available starting from mid-August, 2024. Some data prior to this date might be available in the view, but\n  might be incomplete.\n\n## Examples [¶]( \"Link to this heading\")\n\n### Query costs for related queries [¶]( \"Link to this heading\")\n\nTo determine the costs of a specific query and similar queries using the query parameterized hash, replace `<query_id>` and execute the following statements:\n\n```\nSET query_id = '<query_id>' ; \n\n WITH query_hash_of_query AS ( \n  SELECT query_parameterized_hash \n  FROM SNOWFLAKE . ACCOUNT_USAGE . QUERY_ATTRIBUTION_HISTORY \n  WHERE query_id = $ query_id \n  LIMIT 1 \n ) \n SELECT \n  query_parameterized_hash , \n  COUNT (*) AS query_count , \n  SUM ( credits_attributed_compute ) AS recurrent_query_attributed_credits \n FROM SNOWFLAKE . ACCOUNT_USAGE . QUERY_ATTRIBUTION_HISTORY \n WHERE start_time >= DATE_TRUNC ( 'MONTH' , CURRENT_DATE ) \n  AND start_time < CURRENT_DATE \n  AND query_parameterized_hash = ( SELECT query_parameterized_hash FROM query_hash_of_query ) \n GROUP BY ALL ;\n```\n\nCopy\n\n### Query costs for the current user [¶]( \"Link to this heading\")\n\nTo determine the costs of queries executed by the current user for the current month, execute the following statement:\n\n```\nSELECT user_name , SUM ( credits_attributed_compute ) AS credits \n  FROM SNOWFLAKE . ACCOUNT_USAGE . QUERY_ATTRIBUTION_HISTORY \n  WHERE user_name = CURRENT_USER () \n    AND start_time >= DATE_TRUNC ( 'MONTH' , CURRENT_DATE ) \n    AND start_time < CURRENT_DATE \n  GROUP BY user_name ;\n```\n\nCopy\n\nFor an example of attributing warehouse costs to users, see [Resources shared by users from different departments](../../user-guide/cost-attributing.html) .\n\n### Query costs for stored procedures [¶]( \"Link to this heading\")\n\nFor stored procedures that issue multiple hierarchical queries, you can compute the attributed query costs for the\nprocedure by using the root query ID for the procedure.\n\n1. To find the root query ID for a stored procedure, use the [ACCESS\\_HISTORY view](access_history) . For example,\n   to find the root query ID for a stored procedure, set the `query_id` and execute the following statements:\n   \n   ```\n   SET query_id = '<query_id>' ; \n   \n    SELECT query_id , \n          parent_query_id , \n          root_query_id , \n          direct_objects_accessed \n     FROM SNOWFLAKE . ACCOUNT_USAGE . ACCESS_HISTORY \n     WHERE query_id = $ query_id ;\n   ```\n   \n   Copy\n   \n   For more information, see [Example: Ancestor queries with stored procedures](../../user-guide/access-history.html) .\n2. To sum the query cost for the entire procedure, replace `<root_query_id>` and execute the following statements:\n   \n   ```\n   SET query_id = '<root_query_id>' ; \n   \n    SELECT SUM ( credits_attributed_compute ) AS total_attributed_credits \n     FROM SNOWFLAKE . ACCOUNT_USAGE . QUERY_ATTRIBUTION_HISTORY \n     WHERE ( root_query_id = $ query_id OR query_id = $ query_id );\n   ```\n   \n   Copy\n\n### Additional examples [¶]( \"Link to this heading\")\n\nFor more examples, see [Resources shared by users from different departments](../../user-guide/cost-attributing.html) .\n\nWas this page helpful?\n\nYes No\n\n[Visit Snowflake](https://www.snowflake.com)\n\n[Join the conversation](https://community.snowflake.com/s/)\n\n[Develop with Snowflake](https://developers.snowflake.com)\n\n[Share your feedback](/feedback)\n\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n\n[Get your own certification](https://learn.snowflake.com)\n\n[Privacy Notice](https://www.snowflake.com/privacy-policy/) [Site Terms](https://www.snowflake.com/legal/snowflake-site-terms/) Cookies Settings © 2026 Snowflake, Inc. All Rights Reserved.\n\nOn this page\n\n1. [Columns]()\n2. [Usage notes]()\n3. [Examples]()\n4. [Query costs for related queries]()\n5. [Query costs for the current user]()\n6. [Query costs for stored procedures]()\n7. [Additional examples]()\n\nRelated content\n\n1. [Overview of warehouses](/sql-reference/account-usage/../../user-guide/warehouses-overview)\n\nLanguage: **English**\n\n* [English](/en/sql-reference/account-usage/query_attribution_history)\n* [Français](/fr/sql-reference/account-usage/query_attribution_history)\n* [Deutsch](/de/sql-reference/account-usage/query_attribution_history)\n* [日本語](/ja/sql-reference/account-usage/query_attribution_history)\n* [한국어](/ko/sql-reference/account-usage/query_attribution_history)\n* [Português](/pt/sql-reference/account-usage/query_attribution_history)\n\n## Snowflake's Use of Cookies\n\nWe use cookies to enhance your experience and to analyze site traffic as described in our Cookie Statement. By accepting, you consent to our use of cookies. [Cookie Statement.](https://www.snowflake.com/privacy-policy/cookie-statement/)\n\nCookies Settings Reject All Accept All Cookies\n\n## Privacy Preference Center\n\nYour Opt Out Preference Signal is Honored\n\n* ### Your Privacy\n* ### Strictly Necessary Cookies\n* ### Performance Cookies\n* ### Functional Cookies\n* ### Targeting Cookies\n\n#### Your Privacy\n\nWhen you visit any website, it may store or retrieve information on your browser, mostly in the form of cookies. This information might be about you, your preferences or your device and is mostly used to make the site work as you expect it to. The information does not usually directly identify you, but it can give you a more personalized web experience. Because we respect your right to privacy, you can choose not to allow some types of cookies. Click on the different category headings to find out more and change our default settings. However, blocking some types of cookies may impact your experience of the site and the services we are able to offer.  \n[More information](https://cookiepedia.co.uk/giving-consent-to-cookies)\n\n#### Strictly Necessary Cookies\n\nAlways Active\n\nThese cookies are necessary for the website to function and cannot be switched off. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.\n\nCookies Details‎\n\n#### Performance Cookies\n\nPerformance Cookies\n\nThese cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site.    All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance.\n\nCookies Details‎\n\n#### Functional Cookies\n\nFunctional Cookies\n\nThese cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages.    If you do not allow these cookies then some or all of these services may not function properly.\n\nCookies Details‎\n\n#### Targeting Cookies\n\nTargeting Cookies\n\nThese cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly identifiable personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising.\n\nCookies Details‎\n\n### Cookie List\n\nConsent Leg.Interest\n\ncheckbox label label\n\ncheckbox label label\n\ncheckbox label label\n\nClear\n\ncheckbox label label\n\nApply Cancel\n\nConfirm My Choices\n\nAllow All\n\n[](https://www.onetrust.com/products/cookie-consent/)\n"]},{"url":"https://docs.snowflake.com/en/user-guide/cost-attributing","title":"Attributing cost | Snowflake Documentation","excerpts":["[Overview](/en/guides \"Overview\")\n[Snowflake Horizon Catalog](/en/user-guide/snowflake-horizon \"Snowflake Horizon Catalog\")\n[Applications and tools for connecting to Snowflake](/en/guides-overview-connecting \"Applications and tools for connecting to Snowflake\")\n[Virtual warehouses](/en/user-guide/warehouses \"Virtual warehouses\")\n[Databases, Tables, & Views](/en/guides-overview-db \"Databases, Tables, & Views\")\n[Data types](/en/data-types \"Data types\")\nData Integration\n[Snowflake Openflow](/en/user-guide/data-integration/openflow/about \"Snowflake Openflow\")\nApache Iceberg™\n[Apache Iceberg™ Tables](/en/user-guide/tables-iceberg \"Apache Iceberg™ Tables\")\n[Snowflake Open Catalog](/en/user-guide/opencatalog/overview \"Snowflake Open Catalog\")\nData engineering\n[Data loading](/en/guides-overview-loading-data \"Data loading\")\n[Dynamic Tables](/en/user-guide/dynamic-tables-about \"Dynamic Tables\")\n[Streams and Tasks](/en/user-guide/data-pipelines-intro \"Streams and Tasks\")\n[dbt Projects on\n ... \nSection Title: Attributing cost [¶]( \"Link to this heading\")\nContent:\nAn organization can apportion the cost of using Snowflake to logical units within the organization (for example, to different\ndepartments, environments, or projects). This chargeback or showback model is useful for accounting purposes and pinpoints\nareas of the organization that could benefit from controls and optimizations that can reduce costs.\nTo attribute costs to different groups like departments or projects, use the following recommended approach:\nUse [object tags](object-tagging/introduction) to associate resources and users with departments or projects.\nUse [query tags](../sql-reference/parameters.html) to associate individual queries with departments or projects when the queries are\nmade by the same application on behalf of users belonging to multiple departments.\nSection Title: ... > Types of cost attribution scenarios [¶]( \"Link to this heading\")\nContent:\nThe following cost attribution scenarios are the most commonly encountered. In these scenarios, warehouses are used as an\nexample of a resource that incurs costs.\nSection Title: ... > Types of cost attribution scenarios [¶]( \"Link to this heading\")\nContent:\n**Resources used exclusively by a single cost center or department:** An example of this is using object tags to associate\nwarehouses with a department. You can use these object tags to attribute the costs incurred by those warehouses to that\ndepartment entirely. [](../_images/cost-attribute-non-shared.png)\n**Resources that are shared by users from multiple departments:** An example of this is a warehouse shared by users from\ndifferent departments. In this case, you use object tags to associate each user with a department. The costs of queries are\nattributed to the users. Using the object tags assigned to users, you can break down the costs by department. [](../_images/cost-attribute-user-level-share.png)\n**Applications or workflows shared by users from different departments:** An example of this is an application that issues\nqueries on behalf of its users.\n ... \nSection Title: ... > Setting up object tags for cost attribution [¶]( \"Link to this heading\")\nContent:\nWhen you set up tags to represent the groupings that you want to use for cost attribution, you should determine if the\ngroupings apply to a single account or multiple accounts. This determines how you set up your tags.\nFor example, suppose that you want to attribute costs based on department.\nIf the resources used by the department are located in a single account, you create the tags in a database in that account.\nIf the resources used by the department span multiple accounts, you [create the tags]() in a key account in your organization (for example, in your [organization account](organization-accounts) ),\nand you make those tags available in other accounts through [replication]() .\nThe next sections explain how to create the tags, replicate the tags, and apply the tags to resources.\n[Creating the tags]()\n[Replicating the tag database]()\n[Tagging the resources and users]()\nNote\n ... \nSection Title: Attributing cost [¶]( \"Link to this heading\") > ... > Creating the tags [¶]( \"Link to this heading\")\nContent:\nAs part of designing the strategy, decide on the database and schema where you plan to create the tags.\nYou can create a dedicated database and schema for the tags.\nIf you want to tag resources in different accounts across your organization, you can create the tags in a key account in your\norganization (for example, in your [organization account](organization-accounts) ).\nThe following example creates a database named `cost_management` and a schema named `tags` for the tags that you plan to use:\nCopy\nWith `cost_management` and `tags` selected as the current database and schema, create a tag named `cost_center` and set\nthe values allowed for the tag to the names of cost centers:\nCopy\n ... \nSection Title: ... > Tagging the resources and users [¶]( \"Link to this heading\")\nContent:\nAfter creating and replicating the tags, you can use these tags to identify the warehouses and users belonging to each\ndepartment. For example, because the sales department uses both `warehouse1` and `warehouse2` , you can set the `cost_center` tag to `'SALES'` for both warehouses.\nTip\nIdeally, you should have workflows that automate the process of applying these tags when you create resources and users.\nCopy\nSection Title: ... > Viewing cost by tag in SQL [¶]( \"Link to this heading\")\nContent:\nYou can attribute costs within an account or across accounts in an organization:\nSection Title: ... > Viewing cost by tag in SQL [¶]( \"Link to this heading\")\nContent:\n**Attributing costs within an account**You can attribute costs within an account by querying the following views in the [ACCOUNT_USAGE](../sql-reference/account-usage) schema:\n[TAG_REFERENCES view](../sql-reference/account-usage/tag_references) : Identifies objects (for example, warehouses and users) that have tags. [WAREHOUSE_METERING_HISTORY view](../sql-reference/account-usage/warehouse_metering_history) : Provides credit usage for warehouses. [QUERY_ATTRIBUTION_HISTORY view](../sql-reference/account-usage/query_attribution_history) : Provides the compute costs for queries. The cost per query is\nthe warehouse credit usage for executing the query.For more information on using this view, see [About the QUERY_ATTRIBUTION_HISTORY view]() .\nSection Title: ... > Viewing cost by tag in SQL [¶]( \"Link to this heading\")\nContent:\n**Attributing costs across accounts in an organization**Within an organization, you can also attribute costs for resources that are used **exclusively by a single department** by\nquerying views in the [ORGANIZATION_USAGE](../sql-reference/organization-usage) schema from the [organization account](organization-accounts) .Note\nIn the ORGANIZATION_USAGE schema, the TAG_REFERENCES view is only available in the organization account. The QUERY_ATTRIBUTION_HISTORY view is only available in the ACCOUNT_USAGE schema for an account. There is no\norganization-wide equivalent of the view.\nSection Title: ... > Viewing cost by tag in SQL [¶]( \"Link to this heading\")\nContent:\nThe next sections explain how to attribute costs for some of the [common cost-attribution scenarios]() :\n[Resources not shared by departments]()\n[Resources shared by users from different departments]()\n[Resources used by applications that need to attribute costs to different departments]()\nSection Title: ... > Resources not shared by departments [¶]( \"Link to this heading\")\nContent:\nSuppose that you want to attribute costs by department and that each department uses a set of dedicated warehouses.\nIf you tag warehouses with a `cost_center` tag to identify the department that owns the warehouse, you can join the\nACCOUNT_USAGE [TAG_REFERENCES view](../sql-reference/account-usage/tag_references) with the [WAREHOUSE_METERING_HISTORY view](../sql-reference/account-usage/warehouse_metering_history) on the `object_id` and `warehouse_id` columns to get usage\ninformation by warehouse, and you can use the `tag_value` column to identify the departments that own those warehouses.\nThe following SQL statement performs this join:\nCopy\nYou can run a similar query to perform the same attribution for all the accounts in your organization using views in the\nORGANIZATION_USAGE schema from the [organization account](organization-accounts) . The rest of the query\ndoes not change.\nCopy\nSection Title: ... > Resources shared by users from different departments [¶]( \"Link to this heading\")\nContent:\nSuppose that users in different departments share the same warehouses and you want to break down the credits used by each\ndepartment. You can tag the users with a `cost_center` tag to identify the department that they belong to, and you can join\nthe [TAG_REFERENCES view](../sql-reference/account-usage/tag_references) with the [QUERY_ATTRIBUTION_HISTORY view](../sql-reference/account-usage/query_attribution_history) .\nNote\nYou can only get this data for a single account at a time. You cannot execute a query that retrieves this data across\naccounts in an organization.\nThe next sections provide examples of SQL statements for attributing costs for shared resources.\n ... \nSection Title: ... > Viewing cost by tag in Snowsight [¶]( \"Link to this heading\")\nContent:\nYou can attribute costs by reporting on the use of resources that have the `cost_center` tag. You can access this data in [Snowsight](ui-snowsight-gs.html) .\nSwitch to a role that has [access to the ACCOUNT_USAGE schema](../sql-reference/account-usage.html) .\nIn the navigation menu, select Admin » Cost management .\nSelect Consumption .\nFrom the Tags drop-down, select the `cost_center` tag.\nTo focus on a specific cost center, select a value from the list of the tag’s values.\nSelect Apply .\nFor more details about filtering in Snowsight, see [Filter by tag](cost-exploring-compute.html) .\nSection Title: ... > About the QUERY_ATTRIBUTION_HISTORY view [¶]( \"Link to this heading\")\nContent:\nYou can use the [QUERY_ATTRIBUTION_HISTORY view](../sql-reference/account-usage/query_attribution_history) to attribute cost based on queries. The cost per\nquery is the warehouse credit usage for executing the query. This cost does not include any other credit usage that is incurred\nas a result of query execution. For example, the following are not included in the query cost:\nData transfer costs\nStorage costs\nCloud services costs\nCosts for serverless features\nCosts for tokens processed by AI services\nFor queries that are executed concurrently, the cost of the warehouse is attributed to individual queries based on the weighted\naverage of their resource consumption during a given time interval.\nThe cost per query does not include warehouse *idle time* . Idle time is a period of time in which no queries are running in the\nwarehouse and can be measured at the warehouse level.\n ... \nSection Title: ... > Attributing costs of hierarchical queries [¶]( \"Link to this heading\")\nContent:\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n[Get your own certification](https://learn.snowflake.com)\n[Privacy Notice](https://www.snowflake.com/privacy-policy/) [Site Terms](https://www.snowflake.com/legal/snowflake-site-terms/) Cookies Settings © 2025 Snowflake, Inc. All Rights Reserved.\nOn this page\n[Types of cost attribution scenarios]()\n[Setting up object tags for cost attribution]()\n[Creating the tags]()\n[Replicating the tag database]()\n[Tagging the resources and users]()\n[Viewing cost by tag in SQL]()\n[Resources not shared by departments]()\n[Resources shared by users from different departments]()\n[Resources used by applications that need to attribute costs to different departments]()\n[Viewing cost by tag in Snowsight]()\n[About the QUERY_ATTRIBUTION_HISTORY view]()\n[Additional examples of queries]()\n[Grouping similar queries]()\n[Attributing costs of hierarchical queries]()"]},{"url":"https://yukidata.com/blog/snowflake-finops-guide/","title":"Snowflake FinOps: Complete Guide to Automated Cost Optimization | Yuki","publish_date":"2025-09-19","excerpts":["SolutionsClose Solutions Open Solutions\nResourcesClose Resources Open Resources[Blog](https://yukidata.com/blog/) [Customers](https://yukidata.com/customers/) [News](https://yukidata.com/news/) [Documentation](https://yukidata.com/customers/)\n[About Us](https://yukidata.com/about/)\n[Contact Us](https://yukidata.com/contact/)\nSection Title: Snowflake FinOps: Complete Guide to Automated Cost Optimization\nContent:\nBy Perry Tapiero\nSeptember 19, 2025 | 5 min read\nYour Snowflake bill increased 40% last quarter, but query performance actually got worse.\nSound familiar?\nAll FinOps organizations eventually run into this wall when they outgrow Snowflake’s basic auto-suspend and resource monitors. While Snowflake’s per-second billing offers flexibility, it also means a single efficient query can eat through hundreds of dollars – which is why manual warehouse management can’t keep pace with enterprise-sized workloads.\nThe bright side: modern Snowflake FinOps fixes this with automated systems that allow you to optimize spend and performance in real time.\nHow do you get to that point? Read on. We’ll share all of our FinOps best practices,e automation strategies, and real-world tactics that have helped enterprises cut monthly Snowflake costs by 30% or more.\n ... \nSection Title: Snowflake FinOps: Complete Guide to Automated Cost Optimization > What is FinOps for Snowflake?\nContent:\n**Credit-based consumption:** At $2-4 per credit (depending on your region and edition) with cost scaling linearly from X-Small (1 credit/hour) to 6X-Large (512 credits/hour).\n**Query-level optimization:** Using QUERY_HISTORY and WAREHOUSE_METERING_HISTORY views to identify expensive queries before they ruin your budget.\n**Dynamic warehouse scaling:** Beyond basic auto-suspend, implementing intelligent scaling based on queue depth and query complexity\n**Storage and** [**data transfer**](https://yukidata.com/blog/snowflake-data-transfer-costs-complete-guide/) **:** Long-term storage and cross-regional replication can add significant costs if not managed with lifestyle policies and governance.\nSection Title: Snowflake FinOps: Complete Guide to Automated Cost Optimization > What is FinOps for Snowflake?\nContent:\nThe big challenge here? Manual management. That same hands-on approach that worked so well for traditional infrastructure of the past breaks down when you apply the same method to millions of queries and dozens of ever-changing warehouses.\n*With Yuki, warehouse optimization is automated with a single toggle – no more manual resizing or monitoring.*\n ... \nSection Title: Snowflake FinOps: Complete Guide to Automated Cost Optimization > ... > The Engineering Time Tax\nContent:\nYour data engineers aren’t working for you to babysit warehouses. Yet many teams still find themselves spending hours each week manually resizing, suspending, and monitoring clusters. Even if that’s just 5-10 hours per engineer, that’s *thousands* of dollars lost in productivity per month – before you even add in wasted compute.\nManual management also results in issues like:\n**Overprovisioned warehouses** kept large *just in case*\n**Idle compute** burning credits overnight\n**Compliance gaps** from inconsistent chargeback and lack of audit trails\nSection Title: Snowflake FinOps: Complete Guide to Automated Cost Optimization > ... > The Speed vs. Cost Dilemma\nContent:\nFast-growing companies always run into this growing pain: should they optimize for speed or for cost? Most choose speed, leaving them with:\n**Overprovisioned warehouses** to avoid performance bottlenecks\n**Warehouse sprawl** as teams created dedicated resources for SLAs\n**Idle compute** running 24/7 “just in case”\nThe result? Snowflake costs outgrowing revenue and eating into margin and ROI.\nSection Title: Snowflake FinOps: Complete Guide to Automated Cost Optimization > ... > The Compliance Complexity\nContent:\nEnterprise FinOps needs control, not just cost reduction. You’ll find manual approaches falling short of this:\n**Granular spend attribution** across cost centers and teams\n**Real-time budget enforcement** to prevent runaway costs\n**Audit trails** for compliance and chargeback scenarios\n**Role-based access** maintaining security while enabling autonomy\nThese challenges only continue to compound as you scale, making manual management not just expensive, but impossible to maintain.\n ... \nSection Title: ... > : Implement Granular Cost Attribution\nContent:\n**The problem:** Snowflake’s native cost reporting only shows warehouse-level spending. You need query- and team-level attribution for effective chargeback.\n**The solution:** Build automated tagging and attribution using Snowflake’s metadata like this:\nYou can use this to pull key metrics like:\nCost per team per month: SUM(credits_used * $3) GROUP BY team_attribution\nMost expensive users: SUM(credits_used) GROUP BY user_name\nWarehouse efficiency: credits_used / execution_time ratio\nSection Title: ... > : Automated Chargeback and Showback Models\nContent:\n**The problem:** No clear cost attribution means that teams often treat Snowflake as if it were “free,” leading to wasteful usage and budget overruns.\n**The solution:** Automated cost attribution that gets you accountability without expensive administration overhead:\n**Tag-based attribution** that automatically assigns costs to projects and business units\n**Usage-based chargeback** for shared warehouses using per-query\n**Predictive showback** forecasting team spend based on current trends\n**ROI tracking** connecting data platform costs to business outcomes\nManual tagging doesn’t scale. You need systems that automatically attribute costs based on your usage patterns, user roles, and business context.\nSection Title: ... > : Proactive Budget Management and Alerts\nContent:\n**The problem:** Reactive alerts document overspend after it happens. They don’t prevent it.\n**The solution:** Intelligent budget management that actually prevents overruns before they occur:\n**Predictive alerting** based on usage trends and historical patterns\n**Automated spend controls** scaling resources down when budgets risk\n**Multi-tiered notifications** that escalates teams to finance as spending approaches limits\n**Business-context budgeting** adjusting limits based on revenue cycles\nEffective budget management isn’t about saying “no”. It’s saying “yes” to the right workloads while automating the rest.\nSection Title: ... > : Automated Warehouse Scaling\nContent:\n**The problem:** Snowflake’s auto-suspend helps with idle time, but it doesn’t actually optimize warehouse size when it comes to workload complexity.\n**The solution:** Implement workload-aware scaling. For example, use Snowflake’s WAREHOUSE_LOAD_HISTORY to track query depth and concurrency, then programmatically adjust sizes via Snowflake Python Connector or Snowpark API:\nThis approach can help you [reduce warehouse costs](https://yukidata.com/blog/snowflake-warehouse-optimization-guide/) by 20-40% because it lets you match your compute size to actual workload requirements.\nSection Title: ... > : Strategic Workload Investment\nContent:\n**The problem:** All workloads aren’t equal. Fraud detection needs different allocation outside of monthly reports.\n**The solution:** ROI-device resource allocation aligning your spending with real business values:\n**Workload classification** that automatically identifies business-critical vs development queries\n**Priority-based allocation** so you can be certain critical workloads always get resources first\n**Cost-per-insight analysis** which lets you measure business value per dollar spent\n**Automated lifecycle management** that lets you retire low-value processes while scaling high-impact ones\nThis step lets you move past generic optimization into business-aware optimizations you can create the perfect system for varying workloads.\nSection Title: ... > : Automated Governance and Compliance\nContent:\n**The problem:** Manual governance doesn’t scale. Maintaining control without slowing growth becomes more and more impossible as teams grow.\n**The solution:** Intelligent guardrails that maintain control *and* enable autonomy:\n**Role-based resource limits** that prevent unauthorized warehouse creation or sizing\n**Automated compliance monitoring** to keep data governance policies in place\n**Policy-driven scaling** that allows you to apply optimization rules based on workload classification\n**Audit-ready reporting** so you can get complete visibility for compliance and chargeback\nThese six approaches build out a foundation for your FinOps platform to operate automatically, letting your teams focus on innovation while maintaining growth.\n*Yuki lets you organize Snowflake costs into business domains, apply budgets, and monitor daily usage trends – making FinOps governance actionable.*\nSection Title: ... > Snowflake FinOps Quick Wins: How to Get Started\nContent:\nIf you’re scratching your head wondering how you’re going to implement any one of those six steps above, don’t be discouraged. Automation can seem overwhelming. Before you dive in, make sure you’ve already implemented these three easy quick fixes:\nSection Title: ... > Fix #1: Enabling Basic Controls\nContent:\nBefore you get into automation, this puts guardrails in place. Resource monitors mean you can cap resources before budgets spiral.\nHere’s an example of what this could look like to prevent runaway spending by suspending warehouses when you reach a certain quota:\n ... \nSection Title: ... > Multi-Region Compliance & Data Residency\nContent:\nGlobal enterprises have to maintain data residency requirements while continuing to optimize costs across different regions. Doing this manually means having to carefully balance regulatory compliance and [cost optimization](https://yukidata.com/blog/snowflake-optimization-guide/) across multiple geographic regions and regulatory frameworks.\n**The solution:** Use automated, region-aware optimization. This lets you maintain compliance while minimizing cross-region data movement costs. Think intelligent query routing that processes all you need within boundaries, optimizing for cost and performance and getting you the best of both worlds.\n ... \nSection Title: Snowflake FinOps: Complete Guide to Automated Cost Optimization > ... > AI-Native Cost Optimization\nContent:\nIt shouldn’t surprise you to see AI on this list. Next-generation systems will be using machine learning for everything. Not just analysis, but optimization, too:\n**Predictive configurations** for new workloads based on historical patterns\n[**Automated query tuning**](https://yukidata.com/blog/snowflake-query-optimization/) using reinforcement learning\n**Intelligent data placement** that minimizes storage and compute costs at the same time\nAI-native approaches take you another step further from reactive optimization to [predictive cost management](https://yukidata.com/blog/snowflake-cost-optimization-guide/) . It means you can prevent inefficiencies before they even occur.\n ... \nSection Title: ... > [Introducing Yuki Insights: Root Cause for Snowflake Cost and Performance](https://yukidata...\nContent:\n[Learn More >](https://yukidata.com/introducing-yuki-insights-root-cause-snowflake-cost-performance/)\nJanuary 3, 2026\n ... \nSection Title: ... > [Introducing Yuki Insights: Root Cause for Snowflake Cost and Performance](https://yukidata...\nContent:\n[Learn More >](https://yukidata.com/introducing-yuki-insights-root-cause-snowflake-cost-performance/)\nJanuary 3, 2026\n[Back to Blog](https://yukidata.com/blog/)\nSection Title: Snowflake FinOps: Complete Guide to Automated Cost Optimization > Related posts > Free cost analysis\nContent:\nTake 5 minutes to learn how much money you can save on your Snowflake account.\nBy clicking Submit you’re confirming that you agree with our Terms and Conditions.\n[Skip to content]()"]},{"url":"https://www.snowflake.com/en/developers/guides/well-architected-framework-cost-optimization-and-finops/","title":"Cost Optimization","excerpts":["Section Title: Cost Optimization > ... > Overview > Establish a consistent and granular cost attribution strategy\nContent:\nImplementing robust and organizationally consistent tagging and labeling\nstrategies across all resources (e.g. storage objects, warehouses,\naccounts, queries) is crucial to accurately allocate costs to specific\nteams, products, or initiatives and linking actions to outcomes.\n**Tagging in Snowflake**\nTagging can be done at several levels:\nSection Title: Cost Optimization > ... > Overview > Establish a consistent and granular cost attribution strategy\nContent:\n**Snowflake object tagging:** Snowflake allows you to apply [object-level tags](https://docs.snowflake.com/en/user-guide/object-tagging/introduction) (key-value pairs) to accounts, warehouses, databases, schemas, users,\ntables, and more. These tags are fundamental for apportioning costs\nacross departments, environments (dev, test, prod), projects, or lines\nof business. Tags can also support [inheritance](https://docs.snowflake.com/en/user-guide/object-tagging/inheritance) and [propagation](https://docs.snowflake.com/en/user-guide/object-tagging/propagation) ,\nsimplifying tagging across dependent objects. For example, instead of\ntagging each individual table underneath a schema, tagging the schema\nwill cause all tables to inherit the tag of the schema.\nSection Title: Cost Optimization > ... > Overview > Establish a consistent and granular cost attribution strategy\nContent:\nThis\nsignificantly reduces the manual effort required for tagging and\nensures that new objects created within a tagged schema or propagated\nworkflow automatically inherit the correct cost attribution. Snowflake\nstrongly recommends tags for warehouses, databases, tables, and users\nto enable granular cost breakdowns. You can use the [TAG_REFERENCES view](https://docs.snowflake.com/sql-reference/account-usage/tag_references) in SNOWFLAKE.ACCOUNT_USAGE to combine with common usage views like\nWAREHOUSE_METERING_HISTORY and TABLE_STORAGE_METRICS to allocate usage\nto relevant business groups. Object Tags are best utilized when\nSnowflake objects are not shared across cost owners.\nSection Title: Cost Optimization > ... > Overview > Establish a consistent and granular cost attribution strategy\nContent:\n**Query tags for granular workload attribution:** [Query tags](https://docs.snowflake.com/en/user-guide/cost-attributing) can be set via session parameters (e.g., ALTER SESSION SET QUERY_TAG =\n'your_tag';) or directly within SQL clients or ETL tools. This\nassociates individual queries with specific departments, projects, or\napplications, even when using shared warehouses. This is extremely\nvaluable for shared warehouses where multiple teams or applications\nuse the same compute resource, allowing for granular showback. It is\nalso easy to programmatically make changes to query tags within\nscripts or processes to allocate costs appropriately. Query tags can\nbe found in the QUERY_HISTORY view of the SNOWFLAKE.ACCOUNT_USAGE\nschema.\nSection Title: Cost Optimization > ... > Overview > Establish a consistent and granular cost attribution strategy\nContent:\n**Tagging models**\nIn the initial setup of a business unit or use case, it is important to\nconsider the [model for tagging](https://docs.snowflake.com/en/user-guide/cost-attributing) costs within the platform via shared or dedicated resources. These fall\ninto three large buckets:\nSection Title: Cost Optimization > ... > Overview > Establish a consistent and granular cost attribution strategy\nContent:\n**Resources used exclusively by a single cost center or department:** An example of this is using object tags to associate warehouses with a\ndepartment. You can use object tags to attribute the costs incurred by\nthose warehouses to that department entirely. **Resources shared by users from multiple departments:** An example of\nthis is a warehouse shared by users from different departments. In\nthis case, you use object tags to associate each user with a\ndepartment. The costs of queries are attributed to the users. Using\nthe object tags assigned to users, you can break down the costs by\ndepartment. **Applications or workflows shared by users from different departments:** An example of this is an application that issues\nqueries on behalf of its users.\n ... \nSection Title: Cost Optimization > ... > Overview > Establish a consistent and granular cost attribution strategy\nContent:\nEach model has its pros and cons, including how to handle concepts such\nas idle time or whether to show/charge back attributed or billed\ncredits. Review each model before deploying resources. If an\norganization is caught between models, a common approach is to start in\na shared resource environment and graduate to dedicated resources as the\nworkload increases.\n**Tag enforcement**\nSection Title: Cost Optimization > ... > Overview > Establish a consistent and granular cost attribution strategy\nContent:\nClear and consistent naming conventions for accounts, warehouses,\ndatabases, schemas, and tables facilitate immediate cost understanding. Enforcing robust tagging policies (e.g., requiring specific tags for new\nresource creation and using automated scripts to identify untagged\nresources) is crucial for accurate data interpretation and effective\ncost management. Without tag enforcement, it is difficult to accurately\nallocate all costs and can require manual effort, like extensive\ntag-mapping tables. Tag values are enforced within an account, but if a\nmulti-account strategy is needed for your organization, a tag [database can be replicated](https://docs.snowflake.com/en/user-guide/cost-attributing) and leveraged across all accounts to ensure consistent values are used.\nSection Title: Cost Optimization > ... > Overview > Establish a consistent and granular cost attribution strategy\nContent:\nFor best-in-class visibility, it is recommended to have a tagging\nstrategy and tag all resources in an organization to allocate costs to\nrelevant owners.\n ... \nSection Title: Cost Optimization > Visibility > Overview > Deliver clear historical consumption insights\nContent:\n| Metric Category | Description | Key Metrics | Primary Data Sources |\n| Compute & query metrics | Understand the cost of query execution, warehouse consumption, and overall compute health. These are often the most dynamic and largest portion of your spend. | - Credits used: total credits by warehouse |  |\n| - Query performance: execution time, bytes scanned, compilation time, parameterized query hash |  |  |  |\n| - Warehouse health: % idle time, queueing, spilling, concurrency | - `ACCOUNT_USAGE.WAREHOUSE_METERING_HISTORY` (hourly warehouse credit usage) |  |  |\n| - `ACCOUNT_USAGE.QUERY_HISTORY` (detailed query metrics and associated warehouses) |  |  |  |\n| - Table access (stale/unused) | - `ACCOUNT_USAGE.TABLE_STORAGE_METRICS` |  |  |\n| - `ACCOUNT_USAGE.DATABASE_STORAGE_USAGE_HISTORY` |  |  |  |\n| - `ACCOUNT_USAGE.ACCESS_HISTORY` |  |  |  |\n ... \nSection Title: Cost Optimization > Visibility > Overview > Deliver clear historical consumption insights\nContent:\n| Metric Category | Description | Key Metrics | Primary Data Sources |\n| Compute & query metrics | Understand the cost of query execution, warehouse consumption, and overall compute health. These are often the most dynamic and largest portion of your spend. | - Credits used: total credits by warehouse |  |\n| - Query performance: execution time, bytes scanned, compilation time, parameterized query hash |  |  |  |\n| - Warehouse health: % idle time, queueing, spilling, concurrency | - `ACCOUNT_USAGE.WAREHOUSE_METERING_HISTORY` (hourly warehouse credit usage) |  |  |\n| - `ACCOUNT_USAGE.QUERY_HISTORY` (detailed query metrics and associated warehouses) |  |  |  |\n| - `ORGANIZATION_USAGE.METERING_DAILY_HISTORY` |  |  |  |\n| - AI views such as `CORTEX_FUNCTIONS_USAGE_HISTORY` , `CORTEX_ANALYST_USAGE_HISTORY` , `DOCUMENT_AI_USAGE_HISTORY` |  |  |  |\n ... \nSection Title: Cost Optimization > Visibility > Overview > Deliver clear historical consumption insights\nContent:\n| Metric Category | Description | Key Metrics | Primary Data Sources |\n| Compute & query metrics | Understand the cost of query execution, warehouse consumption, and overall compute health. These are often the most dynamic and largest portion of your spend. | - Credits used: total credits by warehouse |  |\n| - Query performance: execution time, bytes scanned, compilation time, parameterized query hash |  |  |  |\n| - Warehouse health: % idle time, queueing, spilling, concurrency | - `ACCOUNT_USAGE.WAREHOUSE_METERING_HISTORY` (hourly warehouse credit usage) |  |  |\n| - `ACCOUNT_USAGE.QUERY_HISTORY` (detailed query metrics and associated warehouses) |  |  |  |\n| - Replication vs. egress | - `ACCOUNT_USAGE.DATA_TRANSFER_HISTORY` |  |  |\n| - `ORGANIZATION_USAGE.DATA_TRANSFER_DAILY_HISTORY` |  |  |  |\nSection Title: Cost Optimization > Visibility > Overview > Deliver clear historical consumption insights\nContent:\n| Metric Category | Description | Key Metrics | Primary Data Sources |\n| Compute & query metrics | Understand the cost of query execution, warehouse consumption, and overall compute health. These are often the most dynamic and largest portion of your spend. | - Credits used: total credits by warehouse |  |\n| - Query performance: execution time, bytes scanned, compilation time, parameterized query hash |  |  |  |\n| - Warehouse health: % idle time, queueing, spilling, concurrency | - `ACCOUNT_USAGE.WAREHOUSE_METERING_HISTORY` (hourly warehouse credit usage) |  |  |\n| - `ACCOUNT_USAGE.QUERY_HISTORY` (detailed query metrics and associated warehouses) |  |  |  |\n| Financial metrics | Translate credits to currency and provide org‑wide spend view. | - Overall dollar spend (daily) |  |\n| - Spend by service type | - `ORGANIZATION_USAGE.USAGE_IN_CURRENCY_DAILY` |  |  |\n ... \nSection Title: Cost Optimization > Control > Overview > Forecast consumption based on business needs\nContent:\n**Identify demand drivers and unit economics:** To understand what\ndrives Snowflake spend, correlate historical credit, storage, and data\ntransfer usage with key business metrics like cost per customer or per\ntransaction. Use Snowflake's [ACCOUNT_USAGE](https://docs.snowflake.com/en/sql-reference/account-usage) schema, including the WAREHOUSE_METERING_HISTORY and QUERY_HISTORY\nviews, as the primary data sources for this analysis.\n**Granular cost attribution:** Accurately tie costs back to business\nteams or workloads by implementing a mandatory tagging strategy for\nall warehouses and queries. Align these tags with your organization's\nfinancial structure to provide clear cost segmentation.\n**Build the predictive model**\nThis phase integrates historical trends with strategic business inputs\nto create forward-looking projections.\n ... \nSection Title: Cost Optimization > Control > Overview > Govern resource creation and administration\nContent:\nThis ensures every credit spent can be\naccurately attributed to the correct department or project, enabling\nrobust chargeback and accountability. **Automate deactivation:** To prevent object sprawl, implement\npolicies that identify and deactivate stale resources after a\npredetermined period of disuse."]},{"url":"https://docs.snowflake.com/en/user-guide/cost-exploring-compute","title":"Exploring compute cost | Snowflake Documentation","excerpts":["Section Title: Exploring compute cost [¶]( \"Link to this heading\")\nContent:\nTotal compute cost consists of the overall use of:\nVirtual warehouses (user-managed compute resources)\nServerless features such as Automatic Clustering and Snowpipe that use Snowflake-managed compute resources\nCloud services layer of the Snowflake architecture\nvCPU usage for [Openflow BYOC cost and scaling considerations](data-integration/openflow/cost-byoc) and [Openflow Snowflake Deployment cost and scaling considerations](data-integration/openflow/cost-spcs) .\nSee [Openflow components](data-integration/openflow/about.html) for more information about Openflow components including runtimes.\nSection Title: Exploring compute cost [¶]( \"Link to this heading\")\nContent:\nThis topic describes how to gain insight into historical compute costs using [Snowsight](ui-snowsight-gs.html) , or by writing queries against views in\nthe [ACCOUNT_USAGE](../sql-reference/account-usage) and [ORGANIZATION_USAGE](../sql-reference/organization-usage) schemas.\nSnowsight allows you to quickly and easily obtain information about cost from a visual dashboard. Queries against the usage views\nallow you to drill down into cost data and can help generate custom reports and dashboards.\nIf you need more information about how compute costs are incurred, refer to [Understanding compute cost](cost-understanding-compute) .\nNote\n ... \nSection Title: ... > Viewing credit usage [¶]( \"Link to this heading\")\nContent:\nAll compute resources (virtual warehouses, serverless, cloud services) consume Snowflake credits. Users can use Snowsight to\nview the overall cost of compute usage for any given day, week, or month.\nTo explore compute cost:\nSign in to [Snowsight](ui-snowsight-gs.html) .\nSwitch to a role with [access to cost and usage data](cost-access-control) .\nIn the navigation menu, select Admin » Cost management .\nSelect a warehouse to use to view the usage data. Snowflake recommends using an XS warehouse for this purpose.\nSelect Consumption .\nSelect Compute from the Usage Type drop-down.\nFor usage notes related to the Consumption page, see [Usage notes](cost-exploring-overall.html) .\nSection Title: ... > Filter by tag [¶]( \"Link to this heading\")\nContent:\nYou can use tags to [attribute the cost](cost-attributing) of using resources to a logical\nunit within your organization. A tag is a Snowflake object that can have one or more values associated with it. A user with the\nappropriate privileges applies a tag/value pair to each resource that is used by a cost center or other logical unit (e.g. the Development\nenvironment, a business unit, or business line). Once resources have been tagged, you can isolate costs based on a\nspecific tag/value pair, allowing you to attribute this cost to a specific logical unit.\nTo filter the Consumption dashboard to show costs associated with a specific tag/value combination:\nSection Title: ... > Filter by tag [¶]( \"Link to this heading\")\nContent:\nSign in to [Snowsight](ui-snowsight-gs.html) .\nSwitch to a role with [access to cost and usage data](cost-access-control) .\nIn the navigation menu, select Admin » Cost management .\nSelect a warehouse to use to view the usage data. Snowflake recommends using an XS warehouse for this purpose.\nSelect Consumption .\nSelect Compute from the Usage Type drop-down.\nFrom the Tags drop-down, select the tag.\nSelect the value from the list of the tag’s values.\nSelect Apply .\nFor example, you can use the drop-down to select the `COST_CENTER` tag and the `SALES` value to show usage associated with resources\ntagged with `COST_CENTER = SALES` while excluding all other usage from the dashboard.\nYou can also display all resources with a tag regardless of their tag value. Use the drop down to select a\ntag, then choose All instead of a specific value.\nSection Title: ... > View consumption by type, service, or resource [¶]( \"Link to this heading\")\nContent:\nWhen viewing the bar graph that displays compute history, you can filter the data By Type , By Service or By Resource .\nBy Type :\nSeparates resource consumption into compute (virtual warehouses and serverless resources) and cloud services. For the purpose\nof this filter, cloud services is separated out from the other types of compute resources.\nBy Service :\nSeparates resource consumption into warehouse consumption and consumption by each serverless feature. For example,\nWAREHOUSE_METERING represents credits consumed by warehouses while PIPE represents credits consumed by the serverless Snowpipe feature.\nCloud services compute is included in warehouse consumption.\nBy Resource :\nSeparates resource consumption by the Snowflake object that consumed credits. For example, each warehouse is represented,\nas is every table that incurred serverless costs.\nSection Title: ... > Querying data for compute cost [¶]( \"Link to this heading\")\nContent:\nSnowflake provides two schemas, [ORGANIZATION_USAGE](../sql-reference/organization-usage) and [ACCOUNT_USAGE](../sql-reference/account-usage) , that contain data related to usage and cost. The ORGANIZATION_USAGE schema provides\ncost information for all of the accounts in the organization while the ACCOUNT_USAGE schema provides similar information for a single\naccount. Views in these schemas provide granular, analytics-ready usage data to build custom reports or dashboards.\nMost views in the ORGANIZATION_USAGE and ACCOUNT_USAGE schemas contain the cost of compute resources in terms of [credits](cost-understanding-compute.html) consumed. To explore compute cost in currency, rather than credits, write queries against the [USAGE_IN_CURRENCY_DAILY view](../sql-reference/organization-usage/usage_in_currency_daily) . This view converts credits consumed into cost in currency using the daily\nprice of a credit.\nSection Title: ... > General cost views [¶]( \"Link to this heading\")\nContent:\nThe following views contain information related to the compute costs of all Snowflake features. You can focus on a particular feature by filtering on the `service_type` column.\nFor additional views that focus on the cost of a specific feature, see [Feature-specific cost views]() .\nSection Title: ... > General cost views [¶]( \"Link to this heading\")\nContent:\n| View | Compute resource | Description | Schema |\n| METERING_DAILY_HISTORY | Warehouses |  |  |\nSection Title: ... > General cost views [¶]( \"Link to this heading\")\nContent:\nServerless\nCloud Services\nOpenflow runtimes |Credits consumed by all compute resources (warehouses, serverless, cloud services and Openflow) in a given day.\nCan be used to determine whether cloud services compute costs were actually billed for a specific day (that is, cloud services credit\nconsumption exceeded 10% of warehouse consumption). |[ORGANIZATION_USAGE](../sql-reference/organization-usage/metering_daily_history) [ACCOUNT_USAGE](../sql-reference/account-usage/metering_daily_history) |\n|METERING_HISTORY |Warehouses\nServerless\nCloud Services\nOpenflow runtimes |Credits consumed by warehouses, cloud services, serverless, and Openflow features on an hourly basis. To see how many credits an individual\nwarehouse is consuming, query the WAREHOUSE_METERING_HISTORY view. |[ACCOUNT_USAGE](../sql-reference/account-usage/metering_history) |\n|[USAGE_IN_CURRENCY_DAILY](../sql-reference/organization-usage/usage_in_currency_daily) |Warehouses\nSection Title: ... > General cost views [¶]( \"Link to this heading\")\nContent:\nServerless\nCloud Services |Daily credit consumption by all compute resources along with the cost of that usage in the organization’s currency. |[ORGANIZATION_USAGE](../sql-reference/organization-usage/usage_in_currency_daily) |\n ... \nSection Title: ... > Feature-specific cost views [¶]( \"Link to this heading\")\nContent:\n| View | Compute resource | Description |\n| APPLICATION_DAILY_USAGE_HISTORY | Warehouses |  |\n ... \nSection Title: ... > Feature-specific cost views [¶]( \"Link to this heading\")\nContent:\n|\n|LISTING_AUTO_FULFILLMENT_\nREFRESH_DAILY |Warehouses |Credits used to refresh data fulfilled to other regions by Cross-Cloud Auto-Fulfillment. |\n|LISTING_AUTO_FULFILLMENT_\nUSAGE_HISTORY |Warehouses |Estimated usage associated with fulfilling data products to other regions by using Cross-Cloud Auto-Fulfillment. Refer to the SERVICE_TYPE of REPLICATION. |\n|MATERIALIZED_VIEW_REFRESH_\nHISTORY |Serverless |Credits consumed the refreshing of materialized views. |\n|OPENFLOW_USAGE_HISTORY |Openflow |Credits consumed by Openflow runtimes. This view is available in the ACCOUNT_USAGE schema only. |\n|PIPE_USAGE_HISTORY |Serverless |Credits consumed by Snowpipe. |\n|QUERY_ACCELERATION_HISTORY |Serverless |Credits consumed by the query acceleration service. |\n|QUERY_ATTRIBUTION_HISTORY |Warehouses |Credits consumed [per query](cost-attributing.html) for warehouse usage.\nSection Title: ... > Feature-specific cost views [¶]( \"Link to this heading\")\nContent:\n|\n|REPLICATION_USAGE_HISTORY |Serverless |Credits consumed and number of bytes transferred during database replication. If possible, use the [DATABASE_REPLICATION_USAGE_HISTORY view](../sql-reference/account-usage/database_replication_usage_history) instead. |\n|REPLICATION_GROUP_USAGE_\nHISTORY |Serverless |Credits consumed and number of bytes transferred during replication for a specific replication group. |\n|SEARCH_OPTIMIZATION_HISTORY |Serverless |Credits consumed by the search optimization service. |\n|SERVERLESS_ALERT_HISTORY |Serverless |Credits consumed by serverless alerts. |\n|SERVERLESS_TASK_HISTORY |Serverless |Credits consumed by serverless tasks. |\n|SNOWPIPE_STREAMING_FILE_\nMIGRATION_HISTORY |Serverless |Credits consumed by Snowpipe Streaming compute (does not include client costs). |\n|WAREHOUSE_METERING_HISTORY |Warehouses\nSection Title: ... > Feature-specific cost views [¶]( \"Link to this heading\")\nContent:\nCloud Services |Hourly credit usage of each warehouse, including the cloud services cost associated with using the warehouse. |\nNote\nThe views and table functions of the [Snowflake Information Schema](../sql-reference/info-schema) also provide usage data related to cost. Though\nthe ACCOUNT_USAGE schema is preferred, the Information Schema can be faster in some circumstances.\nSection Title: ... > Example queries [¶]( \"Link to this heading\")\nContent:\nThe following queries drill-down into data in ACCOUNT_USAGE views to gain insight into compute costs.\nNote\nQueries executed against views in the Account Usage schema can be modified to gain insight into cost for the entire organization by\nusing the corresponding view in the Organization Usage schema. For example, both schemas include a WAREHOUSE_METERING_HISTORY view.\nClick the name of a query below to see the full SQL example.\nCompute for Warehouses :\n* [Query: Average hour-by-hour Snowflake spend (across all warehouses) over the past m days]()\n[Query: Credit consumption by warehouse over specific time period]()\n[Query: Warehouse usage over m-day average]()\n[Query: Warehouse cost attribution by query tag](cost-attributing.html) .\n[Query: Warehouse cost attribution by user](cost-attributing.html) .\nCompute for Cloud Services :\n* [Query: Billed cloud services]()\n ... \nSection Title: ... > Compute for Snowflake Notebooks [¶]( \"Link to this heading\")\nContent:\n[Understanding compute cost](/user-guide/cost-understanding-compute)\n[Exploring overall cost](/user-guide/cost-exploring-overall)\n[Attributing cost](/user-guide/cost-attributing)\nLanguage: **English**\n[English](/en/user-guide/cost-exploring-compute)\n[Français](/fr/user-guide/cost-exploring-compute)\n[Deutsch](/de/user-guide/cost-exploring-compute)\n[日本語](/ja/user-guide/cost-exploring-compute)\n[한국어](/ko/user-guide/cost-exploring-compute)\n[Português](/pt/user-guide/cost-exploring-compute)"]},{"url":"https://docs.snowflake.com/en/user-guide/cost-exploring-overall","title":"Exploring overall cost - Snowflake Documentation","excerpts":["Section Title: Exploring overall cost [¶]( \"Link to this heading\")\nContent:\nYou can explore historical cost using Snowsight, or by writing queries against views in the [ACCOUNT_USAGE](../sql-reference/account-usage) and [ORGANIZATION_USAGE](../sql-reference/organization-usage) schemas.\nSnowsight allows you to quickly and easily obtain information about cost from a visual dashboard. Queries against the usage\nviews allow you to drill down into cost data and can help generate custom reports and dashboards.\nIf you need an introduction to how costs are incurred in Snowflake, refer to [Understanding overall cost](cost-understanding-overall) .\nTo obtain a billing statement that contains information about historical usage, see [Access a billing usage statement](billing-usage-statement) .\n ... \nSection Title: ... > Overview of organization-level costs [¶]( \"Link to this heading\")\nContent:\nSign in to the [organization account](organization-accounts) or an [ORGADMIN-enabled account](organization-administrators.html) .\nSwitch to a role with [access to cost-related features](cost-access-control) .\nIn the navigation menu, select Admin » Cost management .\nSelect a warehouse to use to view the usage data. Snowflake recommends using an X-Small warehouse for this purpose.\nSelect Organization Overview .\nThe Account Spend Summary tile has a View All option to expand the contents of the tile to include all of the accounts in the\norganization, not just the accounts that have spent the most. To display the SQL query used to populate this tile, select View All » View query ( [](../_images/view-query-icon.png) ) .\n ... \nSection Title: ... > Overview of account-level costs [¶]( \"Link to this heading\")\nContent:\nTo display the SQL query used to populate a tile, select View All » View query ( [](../_images/view-query-icon.png) ) . For example, if\nyou view the query for the Top warehouses by cost tile, you see that the data comes from querying the [WAREHOUSE_METERING_HISTORY](../sql-reference/account-usage/warehouse_metering_history) view in the ACCOUNT_USAGE schema of the shared\nSNOWFLAKE database.\nNote\nCustomers who signed a contract through a Snowflake reseller cannot see the price of a credit or usage in a currency.\nSection Title: ... > Drilling down into incurred costs [¶]( \"Link to this heading\")\nContent:\nYou can use the Consumption page to drill down into the overall cost of using Snowflake for\nany given day, week, or month.\nTo use Snowsight to drill down into the overall cost:\nSign in to [Snowsight](ui-snowsight-gs.html) .\nSwitch to a role with [access to cost-related features](cost-access-control) .\nIn the navigation menu, select Admin » Cost management .\nSelect a warehouse to use to view the usage data. Snowflake recommends using an X-Small warehouse for this purpose.\nSelect Consumption .\nSelect All Usage Types from the drop-down list.\nThis totals the cost of compute, storage, and data transfer resources and displays them in a bar graph using the organization’s currency.\nThe total cost of these resources during the selected time period appears above the bar graph.\nTo isolate the cost of compute, storage, or data transfer, adjust your selection in the All Usage Types filter.\n ... \nSection Title: ... > Querying data for overall cost [¶]( \"Link to this heading\")\nContent:\nSnowflake provides two schemas, [ORGANIZATION_USAGE](../sql-reference/organization-usage) and [ACCOUNT_USAGE](../sql-reference/account-usage) , that contain data related to usage and cost. The ORGANIZATION_USAGE schema provides\ncost information for all of the accounts in the organization while the ACCOUNT_USAGE schema provides similar information for a single\naccount. Views in these schemas provide granular, analytics-ready usage data to build custom reports or dashboards.\nThe following query combines data from the USAGE_IN_CURRENCY view in the ORGANIZATION_USAGE schema in order to gain insight into the\noverall cost of using Snowflake."]},{"url":"https://docs.snowflake.com/en/release-notes/2024/other/2024-08-30-per-query-cost-attribution","title":"August 30, 2024 — Query attribution costs - Snowflake Documentation","excerpts":["Aug 30, 2024 · The new QUERY_ATTRIBUTION_HISTORY view in the ACCOUNT_USAGE schema provides information about the warehouse cost for queries and enables the attribution of ... Aug 30, 2024 · The new QUERY_ATTRIBUTION_HISTORY view in the ACCOUNT_USAGE schema provides information about the warehouse cost for queries and enables the attribution of ... Missing: controls | Show results with: controls"]},{"url":"https://blog.greybeam.ai/snowflake-cost-per-query/","title":"Deep Dive: Snowflake's Query Cost and Idle Time Attribution","publish_date":"2024-10-22","excerpts":["[](https://www.greybeam.ai/)\n[Blog](https://blog.greybeam.ai/)\n[Waitlist](https://greybeam.ai)\n[Customer Stories](https://blog.greybeam.ai/tag/customer-story/)\n[Sign in](#/portal/signin) [Subscribe](#/portal/signup)\nSep 9, 2024 13 min read [How-To](/tag/how-to/ \"How-To\")\nSection Title: A Deep Dive into Snowflake's Query Cost Attribution: Finding Cost per Query\nContent:\nSnowflake's new QUERY_ATTRIBUTION_HISTORY view\nSnowflake recently released a new feature for granular cost attribution down to individual queries through the `QUERY_ATTRIBUTION_HISTORY` view in `ACCOUNT_USAGE` . As a company focused on SQL optimization, we at Greybeam were eager to dive in and see how this new capability compares to our own custom cost attribution logic. What we found was surprising - and it led us down a rabbit hole of query cost analysis.\nSection Title: ... > The Promise and Limitations of QUERY_ATTRIBUTION_HISTORY\nContent:\nThe new view aims to provide visibility into the compute costs associated with each query. Some key things to note:\nData is only available from July 1, 2024 onwards\nShort queries (<100ms) are excluded\nIdle time is not included in the attributed costs\nThere can be up to a 6 hour delay in data appearing\nThere's also a `WAREHOUSE_UTILIZATION` view that displays cost of idle time. At the time of writing, this must be enabled by your Snowflake support team.\n ... \nSection Title: A Deep Dive into Snowflake's Query Cost Attribution: Finding Cost per Query > ... > Potential Issues\nContent:\nAt the time of writing, we’ve identified a few potential problems with the new view:\nWarehouse ID mismatch — The `warehouse_id` in `QUERY_ATTRIBUTION_HISTORY` doesn't match the actual `warehouse_id` from `QUERY_HISTORY` .\nInflated query costs — The credits attributed to short queries seem disproportionately high in some cases.\nIdle time accounting — It’s unclear how idle time factors into the attribution, if at all.\nWe’ve raised these concerns with Snowflake, and they’ve recommended filing a support ticket for further investigation. In the meantime, we’ll continue to rely on our custom attribution logic for accuracy.\nSection Title: ... > Our Approach to Query Cost Attribution\nContent:\nGiven the discrepancies we’ve found, we wanted to share our methodology for calculating per-query costs, including idle time. Here’s an overview of our process:\nGather warehouse suspend events\nEnrich query data with execution times and idle periods\nCreate a timeline of all events (queries and idle periods)\nJoin with `WAREHOUSE_METERING_HISTORY` to attribute costs\nBefore we dive in, let’s cover a few basics:\nSnippet of WAREHOUSE_METERING_HISTORY\n ... \nSection Title: A Deep Dive into Snowflake's Query Cost Attribution: Finding Cost per Query > Conclusion\nContent:\nWhile Snowflake’s new `QUERY_ATTRIBUTION_HISTORY` view is a promising step towards easier cost attribution, our initial testing reveals some potential issues that need to be addressed. For now, we recommend carefully validating the results against your own calculations and metering history.\nWe’re excited to see how this feature evolves and will continue to monitor its accuracy. In the meantime, implementing your own cost attribution logic can provide valuable insights into query performance and resource utilization.\nBy accounting for idle time and carefully tracking query execution across hour boundaries, we’re able to get a more complete and accurate picture of costs. This level of detail is crucial for optimizing Snowflake usage and controlling costs effectively."]}],"usage":[{"name":"sku_search","count":1}]}