{"search_id":"search_64de7f1b60d7488d90b56860e717388e","results":[{"url":"https://www.snowflake.com/en/product/features/native-apps/","title":"Snowflake Native Apps","excerpts":["Section Title: Snowflake Native Apps\nContent:\nFrom development to distribution to monetization,\nbuild your app — as well as your business — natively in the AI Data Cloud.\n[explore current apps](https://app.snowflake.com/marketplace?shareType=application)\n[](https://www.snowflake.com/webinars/virtual-hands-on-labs/vhol-building-and-deploying-data-apps-using-python-on-snowflake-2025-06-11/?utm_cta=website-native-apps-resource)\nSection Title: Snowflake Native Apps > ... > Building and Deploying Data Apps Using Python on Snowflake\nContent:\n[register now](https://www.snowflake.com/webinars/virtual-hands-on-labs/vhol-building-and-deploying-data-apps-using-python-on-snowflake-2025-06-11/?utm_cta=website-native-apps-resource)\n ... \nSection Title: ... > How Snowflake’s Native App Simplifies Technical Orchestration for My Data Outlet Customers ...\nContent:\nOverview:\nSnowflake Native Apps\n[](https://www.snowflake.com/snowflake-native-app-bootcamp/?utm_cta=website-solution-native-apps-timely-content-snowflake-native-app-bootcamp)\nSection Title: Snowflake Native Apps > ... > Snowflake Native App Bootcamp\nContent:\nLearn how the Snowflake Native App Framework enables you to build, market, monetize, and distribute apps to customers across the AI Data Cloud in this comprehensive 120 minute bootcamp.\n[register today](https://www.snowflake.com/snowflake-native-app-bootcamp/?utm_cta=website-solution-native-apps-timely-content-snowflake-native-app-bootcamp)\nSection Title: Snowflake Native Apps > Build Faster, Deploy More Easily, Operate Effortlessly\nContent:\nAvoid the complex costs that come from multiple services and the manual expertise required to optimize. Switch to a fully managed service to efficiently support users and workload while reducing time and effort.* With Snowflake Native App Framework’s support for Snowpark Container Services,** you can bring sophisticated logic, AI/ML models and compute to your app, and boost your development time to value.\n**Snowflake Native App Framework in general availability on AWS, Azure and GCP* ***In general availability on AWS, public preview on Azure*\nSection Title: Snowflake Native Apps > ... > Snowflake Native App Developer Toolkit\nContent:\nGet immediate access to these exclusive app dev resources plus links to bootcamps, community forums and more.\n[access now](https://www.snowflake.com/snowflake-native-app-developer-toolkit/?utm_cta=workload-page-native-apps)\nSection Title: Snowflake Native Apps > Secured Data + Controlled Code = Accelerated Adoption\nContent:\nSince a Snowflake Native App runs in the customer's account, there is no need for customers to move or provide external access to their data. This results in happier security teams, reduced procurement hurdles and faster time to value for customers.\nSection Title: ... > How Snowflake Native App Helps DTCC Bring Hypothetical Market Scenarios to Customers Read More\nContent:\nExplore Snowflake\nNative Apps\n[](https://app.snowflake.com/marketplace/providers/GZT0ZBEKCNO/Affinity%20Solutions)\n[](https://app.snowflake.com/marketplace/providers/GZT0ZQP41EE/Capital%20One%20Software)\n[](https://app.snowflake.com/marketplace/providers/GZTSZAS2KCS/Cybersyn%2C%20Inc)\n[](https://app.snowflake.com/marketplace/providers/GZT0Z11US76L/LiveRamp)\n[](https://app.snowflake.com/marketplace/providers/GZTSZY7HHV6/Maxa)\n[](https://app.snowflake.com/marketplace/providers/GZTSZ67EU4B/My%20Data%20Outlet)\n[](https://app.snowflake.com/marketplace/providers/GZTYZT5BVG/Sundeck)\n[](https://app.snowflake.com/marketplace/providers/GZSYZMNVC6/SNP)\n[explore app listings](https://app.snowflake.com/marketplace?shareType=application)\nSection Title: Snowflake Native Apps > Developer Quickstarts\nContent:\nFollow along with Snowflake's Quickstart Tutorials to get you up and running with Snowflake Native Apps or join the Snowflake Native Apps Forum to connect with other developers.\n[snowflake native apps forum](https://snowflake.discourse.group/c/snowflake-native-apps/26)\n[##### Build a Snowflake Native App to analyze chairlift sensor data View Quickstart](https://quickstarts.snowflake.com/guide/native-app-chairlift/index.html?index=..%2F..index)\n[##### Build a native push-based Java connector View Quickstart](https://quickstarts.snowflake.com/guide/connectors_example_push_based_java)\n[##### Build a native Github connector with Python View Quickstart](https://quickstarts.snowflake.com/guide/connectors_github_python/)\n[##### Map Data in Snowflake Native Apps using Streamlit View Quickstart](https://quickstarts.snowflake.com/guide/data_mapping_in_native_apps/index.html?index=..%2F..index)\nSection Title: Snowflake Native Apps > Developer Quickstarts\nContent:\n[##### Build a native Github connector with Java View Quickstart](https://quickstarts.snowflake.com/guide/connectors_github_java)\n[##### Get started with Snowflake Native Apps View Quickstart](https://quickstarts.snowflake.com/guide/getting_started_with_native_apps/)\nSection Title: Snowflake Native Apps > Snowflake Native App Resources\nContent:\n[REPORT #### Startup VC Report Read Now](https://www.snowflake.com/en/lp/building-startup-ai-age/?utm_cta=website-native-apps-resource)\n[Event #### The Snowflake Startup Challenge Is Here! Register your interest](https://www.snowflake.com/startupchallenge/?utm_cta=website-native-apps-resource)\n[Virtual Event #### Attend BUILD 2024, the Dev Conference for AI & Apps Register Now](https://www.snowflake.com/build/?utm_cta=website-native-apps-resource)\nSection Title: Snowflake Native Apps > Where Data Does More\nContent:\n30-day free trial\nNo credit card required\nCancel anytime\n[start for free](https://signup.snowflake.com/)\nwatch a demo\n**Subscribe to our monthly newsletter** Stay up to date on Snowflake’s latest products, expert insights and resources—right in your inbox!\nLearn * Resource Library\nLive Demos\nFundamentals\nTraining\nCertifications\nSnowflake University\nDeveloper Guides\nDocumentation\nPrivacy Policy\nSite Terms\nCommunication Preferences\nCookie Settings\nDo Not Share My Personal Information\nLegal\n[](https://x.com/Snowflake \"X (Twitter)\")\n[](https://www.linkedin.com/company/3653845 \"LinkedIn\")\n[](https://www.facebook.com/snowflakedb/ \"Facebook\")\n[](https://www.youtube.com/user/snowflakecomputing \"YouTube\")"]},{"url":"https://docs.snowflake.com/en/developer-guide/native-apps/native-apps-about","title":"About the Snowflake Native App Framework | Snowflake Documentation","excerpts":["Developer Snowflake Native App Framework\nSection Title: About the Snowflake Native App Framework ¶\nContent:\nFeature — Generally Available\nThe Snowflake Native App Framework is generally available on supported cloud platforms. For additional information, see Support for private connectivity, VPS, and government regions .\nThis topic provides general information about the Snowflake Native App Framework.\nSection Title: About the Snowflake Native App Framework ¶ > Introduction to the Snowflake Native App Framework ¶\nContent:\nThe Snowflake Native App Framework allows you to create data applications that leverage core Snowflake functionality.\nThe Snowflake Native App Framework allows you to:\nExpand the capabilities of other Snowflake features by sharing data and related\nbusiness logic with other Snowflake accounts. The business logic of an application can include a Streamlit app,\nstored procedures, and functions written using Snowpark API ,\nJavaScript, and SQL.\nShare an application with consumers through listings. A listing can be either free or paid.\nYou can distribute and monetize your apps in the Snowflake Marketplace or distribute them to\nspecific consumers using private listings.\nInclude rich visualizations in your application using Streamlit.\nThe Snowflake Native App Framework also supports an enhanced development experience that provides:\nSection Title: About the Snowflake Native App Framework ¶ > Introduction to the Snowflake Native App Framework ¶\nContent:\nA streamlined testing environment where you can test your applications from a single account.\nA robust developer workflow. While your data and related database objects remain within Snowflake,\nyou can manage supporting code files and resources within source control using your preferred\ndeveloper tools.\nThe ability to release versions and patches for your application that allows you, as a provider,\nto change and evolve the logic of your applications and release them incrementally to consumers.\nSupport for logging of structured and unstructured events so that you can troubleshoot and monitor\nyour applications.\nSection Title: About the Snowflake Native App Framework ¶ > Components of the Snowflake Native App Framework ¶\nContent:\nThe following diagram shows a high-level view of the Snowflake Native App Framework.\nThe Snowflake Native App Framework is built around the concept of provider and consumer used by other\nSnowflake features, including Snowflake Collaboration and Secure Data Sharing\nProvider\nA Snowflake user who wants to share data content and application logic with other Snowflake users.\nConsumer\nA Snowflake user who wants to access the data content and application logic shared by providers.\nSection Title: About the Snowflake Native App Framework ¶ > ... > Develop and Test an Application Package ¶\nContent:\nTo share data content and application logic with a consumer, providers create an application package.\nApplication package\nAn application package encapsulates the data content, application logic,\nmetadata, and setup script required by an application. An application package also contains\ninformation about versions and patch levels defined for the application. See Create and manage an application package for details.\nAn application package can include references to data content and external code files that a provider\nwants to include in the application. An application package requires a manifest file and a setup script.\nSection Title: About the Snowflake Native App Framework ¶ > ... > Develop and Test an Application Package ¶\nContent:\nManifest file\nDefines the configuration and setup properties required by the application, including the location of\nthe setup script, versions, etc. See Create the manifest file for an app for details.\nSetup script\nContains SQL statements that are run when the consumer installs or upgrades an application or when\na provider installs or upgrades an application for testing. The location of the setup script is\nspecified in the manifest file. See Create the setup script for details.\nSection Title: About the Snowflake Native App Framework ¶ > ... > Publish an Application Package ¶\nContent:\nAfter developing and testing an application package, a provider can share an application with consumers by\npublishing a listing containing the application package as the data product of a listing. The listing can be a Snowflake Marketplace\nlisting or a private listing.\nSnowflake Marketplace listing\nAllows providers to market applications across the Snowflake Data Cloud. Offering a listing on the Snowflake Marketplace\nlets providers share applications with many consumers simultaneously, rather than maintain\nsharing relationships with each individual consumer.\nPrivate listing\nAllows providers to take advantage of the capabilities of listings to share applications directly with another\nSnowflake account in any Snowflake region supported by the Snowflake Native App Framework.\nSee About listings for details.\nSection Title: About the Snowflake Native App Framework ¶ > ... > Install and Manage an Application ¶\nContent:\nAfter a provider publishes a listing containing an application package, consumers can discover the listing and\ninstall the application.\nSnowflake Native App\nA Snowflake Native App is the database object installed in the consumer account. When a consumer installs the Snowflake Native App,\nSnowflake creates the application and runs the setup script to create the required objects within the application.\nSee Install and test an app locally for details.\nAfter installing the application, consumers can perform additional tasks, including:\n[Enable logging and event sharing](https://other-docs.snowflake.com/en/native-apps/consumer-enable-logging) to help providers troubleshoot the application.\n[Grant privileges required by the application](https://other-docs.snowflake.com/en/native-apps/consumer-granting-privs) .\nSection Title: About the Snowflake Native App Framework ¶ > ... > Install and Manage an Application ¶\nContent:\nSee [Working with Applications as a Consumer](https://other-docs.snowflake.com/en/native-apps/consumer-about) for details on how consumers install and manage an application.\nSection Title: ... > About Snowflake Native Apps with Snowpark Container Services ¶\nContent:\nA Snowflake Native App with Snowpark Container Services (app with containers) is a Snowflake Native App that runs container workloads in Snowflake.\nContainer apps can run any containerized service supported by Snowpark Container Services.\nApps with containers leverage all of the features of the Snowflake Native App Framework, including provider IP protection, security\nand governance, data sharing, monetization, and integration with compute resources.\nLike any Snowflake Native App, an app with containers is comprised of an application package and application\nobject. However, there are some differences as shown in the following image:\nSection Title: ... > About Snowflake Native Apps with Snowpark Container Services ¶\nContent:\nApplication package:\nTo manage containers, the application package must have access to a services specification file on a\nstage. Within this file, there are references to the container images required by the app. These images\nmust be stored in an image repository in the provider account.\nApplication object:\nWhen a consumer installs an app with containers, the application object that is created contains a\ncompute pool that stores the containers required by the app.\nCompute pool:\nA compute pool is a collection of one or more virtual machine (VM) nodes on which Snowflake runs your\nSnowpark Container Services jobs and services. When a consumer installs an app with containers, they can\ngrant the CREATE COMPUTE POOL privilege to the app or they can create the compute pools manually.\nSection Title: ... > Protect provider intellectual property in an app with containers ¶\nContent:\nWhen an app with containers is installed in the consumer account, the query history of the services\nis available in the consumer account. To protect a provider’s confidential information, the Snowflake Native App Framework redacts\nthe following information:\nThe query text is hidden from the QUERY_HISTORY view .\nAll information in the ACCESS_HISTORY view is hidden.\nThe Query Profile graph for the service’s query is collapsed\ninto a single empty node instead of displaying the full query profile tree.\nSection Title: ... > Multi-factor requirements for users in a provider account ¶\nContent:\nDepending on the type of user, Snowflake requires different types of authentication for\nusers in the provider account.\nSection Title: About the Snowflake Native App Framework ¶ > ... > Non-service users ¶\nContent:\nSnowflake recommends that users in a provider account enroll in multi-factor authentication (MFA) if they do not have the TYPE property set to SERVICE. In a future update, multi-factor\nauthentication will be mandatory for these types of users. Non-service users who use federated authentication and single sign-on (SSO)\nmust have MFA enabled as part of their authentication process.\nSection Title: About the Snowflake Native App Framework ¶ > ... > Service users ¶\nContent:\nUsers who have the TYPE parameter set to SERVICE must use key-pair authentication or OAuth .\nWas this page helpful?\nYes No\n[Visit Snowflake](https://www.snowflake.com)\n[Join the conversation](https://community.snowflake.com/s/)\n[Develop with Snowflake](https://developers.snowflake.com)\nShare your feedback\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n[Get your own certification](https://learn.snowflake.com)\nOn this page\nIntroduction to the Snowflake Native App Framework\nComponents of the Snowflake Native App Framework\nAbout Snowflake Native Apps with Snowpark Container Services\nProtect provider intellectual property in an app with containers\nMulti-factor requirements for users in a provider account\nRelated content\nSnowflake Native App Framework workflow\nTutorial 1: Create a basic Snowflake Native App\nSnowflake Native Apps commands\nSection Title: About the Snowflake Native App Framework ¶ > Privacy Preference Center\nContent:\nYour Opt Out Preference Signal is Honored\nYour Privacy\nStrictly Necessary Cookies\nPerformance Cookies\nFunctional Cookies\nTargeting Cookies\n ... \nSection Title: About the Snowflake Native App Framework ¶ > ... > Your Privacy > Functional Cookies\nContent:\nFunctional Cookies\nThese cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages.    If you do not allow these cookies then some or all of these services may not function properly.\nCookies Details‎\nSection Title: About the Snowflake Native App Framework ¶ > ... > Your Privacy > Targeting Cookies\nContent:\nTargeting Cookies\nThese cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly identifiable personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising.\nCookies Details‎\nSection Title: About the Snowflake Native App Framework ¶ > Privacy Preference Center > Cookie List\nContent:\nConsent Leg.Interest\ncheckbox label label\ncheckbox label label\ncheckbox label label\nClear\ncheckbox label label\nApply Cancel\nConfirm My Choices\nAllow All\n[](https://www.onetrust.com/products/cookie-consent/)"]},{"url":"https://docs.snowflake.com/en/developer-guide/logging-tracing/logging-tracing-enabling","title":"Enabling telemetry collection - Snowflake Documentation","excerpts":["[DOCUMENTATION](https://docs.snowflake.com)\n/\nGet started\nGuides\nDeveloper\nReference\nRelease notes\nTutorials\n[Status](https://status.snowflake.com)\nOverview\nBuilders\nSnowflake DevOps\nObservability\nSnowpark Library\nSnowpark API\nSpark workloads on Snowflake\nMachine Learning\nSnowflake ML\nSnowpark Code Execution Environments\nSnowpark Container Services\nFunctions and procedures\nLogging, Tracing, and Metrics\nSnowflake APIs\nSnowflake Python APIs\nSnowflake REST APIs\nSQL API\nApps\nStreamlit in Snowflake\nAbout Streamlit in Snowflake\nGetting started\nDeploy a sample app\nCreate and deploy Streamlit apps using Snowsight\nCreate and deploy Streamlit apps using SQL\nCreate and deploy Streamlit apps using Snowflake CLI\nStreamlit object management\nBilling considerations\nSecurity considerations\nPrivilege requirements\nUnderstanding owner's rights\nPrivateLink\nLogging and tracing\nApp development\nRuntime environments\nDependency management\nFile organization\nSecrets and configuration\nEditing your app\nMigrations and upgrades\nIdentify your app type\nMigrate to a container runtime\nMigrate from ROOT_LOCATION\nFeatures\nGit integration\nExternal access\nRow access\npolicies\nSleep timer\nLimitations and library changes\nTroubleshooting Streamlit in Snowflake\nRelease notes\n[Streamlit open-source library documentation](https://docs.streamlit.io/)\nSnowflake Native App Framework\nSnowflake Declarative Sharing\nSnowflake Native SDK for Connectors\nExternal Integration\nExternal Functions\nKafka and Spark Connectors\nSnowflake Scripting\nSnowflake Scripting Developer Guide\nTools\nSnowflake CLI\nGit\nDrivers\nOverview\nConsiderations when drivers reuse sessions\nScala versions\nReference\nAPI Reference\nDeveloper Logging, Tracing, and Metrics Enabling monitoring\nSection Title: Enabling telemetry collection ¶\nContent:\nYou must enable telemetry collection before you can use telemetry data — including log messages, trace event data, and metrics data —\nto debug, optimize, and troubleshoot your Snowflake applications.\nUse this topic to confirm that you’re set up to capture data.\n**To enable telemetry collection:**\nSection Title: Enabling telemetry collection ¶\nContent:\nEnsure that you have an active event table .By default, Snowflake includes a predefined event table that is active for your account\nuntil you deactivate it or specify an event table you create .\nSet logging, tracing, and metrics levels.You must set levels for the data you want to capture. For example, you\nmust set the tracing level to a level other than `OFF` for tracing data to be collected.\nAdd code to your applications, if needed.For some telemetry data, data is emitted without your needing to add your own code. For example, Snowflake can record metrics data\nwithout your needing to add code. For other cases, such as logging and tracing, you can add code to emit your own data to be\ncaptured in an event table.For information on languages supported to emit your own data, see the following:\nLogging from handler code\nEvent tracing from handler code\nWas this page helpful?\nYes No\n[Visit Snowflake](https://www.snowflake.com)\nSection Title: Enabling telemetry collection ¶\nContent:\n[Join the conversation](https://community.snowflake.com/s/)\n[Develop with Snowflake](https://developers.snowflake.com)\nShare your feedback\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n[Get your own certification](https://learn.snowflake.com)\nRelated content\nLogging, tracing, and metrics\nLogging messages from functions and procedures\nTrace events for functions and procedures\nCollecting metrics data\nLanguage: **English**\nEnglish\nFrançais\nDeutsch\n日本語\n한국어\nPortuguês"]},{"url":"https://docs.snowflake.com/en/developer-guide/declarative-sharing/monitoring","title":"Monitoring Usage with Declarative Sharing in the Native Application Framework | Snowflake Documentation","excerpts":["Developer Snowflake Declarative Sharing Monitoring\nSection Title: Monitoring Usage with Declarative Sharing in the Native Application Framework ¶\nContent:\nFeature — Generally Available\nSupport for Snowflake Declarative Native Apps is available to all accounts.\nAs a provider, you can monitor the usage of your Declarative Native App to gain insights into how consumers are interacting with your data product.\nThis topic describes the views available in Snowflake to track application usage, access history, and the current state of installed applications.\nSection Title: ... > Monitor app usage ¶\nContent:\nTo monitor the usage of your Declarative Native Apps, you can use the following views:\nAPPLICATION_DAILY_USAGE_HISTORY view .\nLISTING_ACCESS_HISTORY view .\nAPPLICATION_STATE view .\nFor more information, see Data Sharing Usage .\nWas this page helpful?\nYes No\n[Visit Snowflake](https://www.snowflake.com)\n[Join the conversation](https://community.snowflake.com/s/)\n[Develop with Snowflake](https://developers.snowflake.com)\nShare your feedback\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n[Get your own certification](https://learn.snowflake.com)\nSection Title: ... > Privacy Preference Center\nContent:\nYour Opt Out Preference Signal is Honored\nYour Privacy\nStrictly Necessary Cookies\nPerformance Cookies\nFunctional Cookies\nTargeting Cookies\nSection Title: Monitoring Usage with Declarative Sharing in the Native Application Framework ¶ > ... > Your Privacy\nContent:\nWhen you visit any website, it may store or retrieve information on your browser, mostly in the form of cookies. This information might be about you, your preferences or your device and is mostly used to make the site work as you expect it to. The information does not usually directly identify you, but it can give you a more personalized web experience. Because we respect your right to privacy, you can choose not to allow some types of cookies. Click on the different category headings to find out more and change our default settings. However, blocking some types of cookies may impact your experience of the site and the services we are able to offer.\n[More information](https://cookiepedia.co.uk/giving-consent-to-cookies)\nSection Title: ... > Strictly Necessary Cookies\nContent:\nAlways Active\nThese cookies are necessary for the website to function and cannot be switched off. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.\nCookies Details‎\n ... \nSection Title: ... > Functional Cookies\nContent:\nFunctional Cookies\nThese cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages.    If you do not allow these cookies then some or all of these services may not function properly.\nCookies Details‎\nSection Title: ... > Targeting Cookies\nContent:\nTargeting Cookies\nThese cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly identifiable personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising.\nCookies Details‎\nSection Title: Monitoring Usage with Declarative Sharing in the Native Application Framework ¶ > ... > Cookie List\nContent:\nConsent Leg.Interest\ncheckbox label label\ncheckbox label label\ncheckbox label label\nClear\ncheckbox label label\nApply Cancel\nConfirm My Choices\nAllow All\n[](https://www.onetrust.com/products/cookie-consent/)"]},{"url":"https://www.snowflake.com/en/blog/collect-logs-traces-snowflake-apps/","title":"Collect Logs and Traces From Your Snowflake Applications","publish_date":"2024-08-21","excerpts":["blog\nSection Title: Category\nContent:\nAI/ML At Snowflake Partner & Customer Value Industry Solutions Product & Technology Strategy & Insights\nData Engineering\nOCT 30, 2023 | 4 min read\nSection Title: Collect Logs and Traces From Your Snowflake Applications With Event Tables\nContent:\nWe are excited to announce the general availability of Snowflake\nEvent Tables\nfor logging and tracing, an essential feature to boost application observability and supportability for Snowflake developers.\nIn our conversations with developers over the last year, we’ve heard that monitoring and observability are paramount to effectively develop and monitor applications. But previously, developers didn’t have a centralized, straightforward way to capture application logs and traces.\nEnter the new Event Tables feature, which helps developers and data engineers easily instrument their code to capture and analyze logs and traces for all languages: Java, Scala, JavaScript, Python and Snowflake Scripting.\nSection Title: Collect Logs and Traces From Your Snowflake Applications With Event Tables\nContent:\nWith Event Tables, developers can instrument logs and traces from their UDFs, UDTFs, stored procedures, Snowflake Native Apps and Snowpark Container Services, then seamlessly route them to a secure, customer-owned Event Table. Developers can then query Event Tables to troubleshoot their applications or gain insights into performance and code behavior.\nLogs and traces are collected and propagated via Snowflake’s telemetry APIs, then automatically ingested into your Snowflake Event Table.\nSection Title: ... > Simplify troubleshooting in Snowflake Native Apps\nContent:\nEvent Tables are also supported for Snowflake Native Apps. When a Snowflake Native App runs, it is running in the consumer’s account, generating telemetry data that’s ingested into their active Event Table.\nOnce the consumer enables event sharing, new telemetry data will be ingested into both the consumer and provider Event Tables. Now the provider has the ability to debug the application that’s running in the consumer’s account. The provider only sees the telemetry data that is being shared from this data application—nothing else.\nSection Title: ... > Improve reliability across a variety of use cases\nContent:\nYou can use Event Tables to capture and analyze logs for various use cases: * As a data engineer building UDFs and stored procedures within queries and tasks, you can instrument your code to analyze its behavior based on input data.\nAs a Snowpark developer, you can instrument logs and traces for your Snowflake applications to troubleshoot and improve their performance and reliability.\nAs a Snowflake Native App provider, you can analyze logs and traces from various consumers of your applications to troubleshoot and improve performance.\n ... \nSection Title: ... > Improve reliability across a variety of use cases\nContent:\n. “Before Event Tables, we had almost no way to see what was happening inside the UDF and correct issues. Once we rolled out Event Tables, the amount of time we spent testing dropped significantly and allowed us to have debug and info-level access to the logs we were generating in Java.”\nOne large communications service provider also uses logs in Event Tables to capture and analyze failed records during data ingestion from various external services to Snowflake. And a Snowflake Native App provider offering geolocation data services uses Event Tables to capture logs and traces from their UDFs to improve application reliability and performance.\nWith Event Tables, you now have a built-in place to easily and consistently manage logging and tracing for your Snowflake applications. And in conjunction with other features such as Snowflake Alerts and Email Notifications, you can be notified of new events and errors in your applications.\nSection Title: ... > Try Event Tables today\nContent:\nTo learn more about Event Tables, join us at [BUILD](https://www.snowflake.com/build/)\n,\nSnowflake’s developer conference. Or get started with Event Tables today with a [tutorial](https://docs.snowflake.com/en/developer-guide/logging-tracing/tutorials/logging-tracing-getting-started)\nand quickstarts for [logging](https://quickstarts.snowflake.com/guide/alert_on_events/index.html)\nand [tracing](https://quickstarts.snowflake.com/guide/java_trace_events/index.html)\n. For further information about how Event Tables work, visit Snowflake product [documentation](https://docs.snowflake.com/en/developer-guide/logging-tracing/logging-tracing-overview)\n.\nSection Title: ... > The Data Engineer’s Guide to Python for Snowflake\nContent:\n[download now](https://www.snowflake.com/resource/the-data-engineers-guide-to-python-for-snowflake/)\nSection Title: Collect Logs and Traces From Your Snowflake Applications With Event Tables > ... > Author\nContent:\nAshwin Kamath\nSection Title: Collect Logs and Traces From Your Snowflake Applications With Event Tables > ... > Share Article\nContent:\n[](https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fwww.snowflake.com%2Fcontent%2Fsnowflake-site%2Fglobal%2Fen%2Fblog%2Fcollect-logs-traces-snowflake-apps&title=Collect+Logs+and+Traces+From+Your+Snowflake+Applications+With+Event+Tables)\n[](https://x.com/intent/post?url=https%3A%2F%2Fwww.snowflake.com%2Fcontent%2Fsnowflake-site%2Fglobal%2Fen%2Fblog%2Fcollect-logs-traces-snowflake-apps&text=Collect+Logs+and+Traces+From+Your+Snowflake+Applications+With+Event+Tables)\n[](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.snowflake.com%2Fcontent%2Fsnowflake-site%2Fglobal%2Fen%2Fblog%2Fcollect-logs-traces-snowflake-apps)\nSubscribe to our blog newsletter\nGet the best, coolest and latest delivered to your inbox each week\nBy submitting this form, I understand Snowflake will process my personal information in accordance with their Privacy Notice.\nSection Title: Collect Logs and Traces From Your Snowflake Applications With Event Tables > Where Data Does More\nContent:\n30-day free trial\nNo credit card required\nCancel anytime\n[start for free](https://signup.snowflake.com/)\nwatch a demo\n**Subscribe to our monthly newsletter** Stay up to date on Snowflake’s latest products, expert insights and resources—right in your inbox!\nIndustries * [Advertising, Media & Entertainment](https://www.snowflake.com/en/solutions/industries/advertising-media-entertainment/)\nSection Title: Collect Logs and Traces From Your Snowflake Applications With Event Tables > Where Data Does More\nContent:\n[Financial Services](https://www.snowflake.com/en/solutions/industries/financial-services/)\n[Healthcare & Life Sciences](https://www.snowflake.com/en/solutions/industries/healthcare-and-life-sciences/)\n[Manufacturing](https://www.snowflake.com/en/solutions/industries/manufacturing/)\n[Public Sector](https://www.snowflake.com/en/solutions/industries/public-sector/)\n[Retail & Consumer Goods](https://www.snowflake.com/en/solutions/industries/retail-consumer-goods/)\n[Technology](https://www.snowflake.com/en/solutions/industries/technology/)\nLearn * [Resource Library](https://snowflake.com/en/resources/)\nSection Title: Collect Logs and Traces From Your Snowflake Applications With Event Tables > Where Data Does More\nContent:\nLive Demos\n[Fundamentals](https://www.snowflake.com/en/fundamentals/)\n[Training](https://www.snowflake.com/en/resources/learn/training/)\n[Certifications](https://www.snowflake.com/en/resources/learn/certifications/)\n[Snowflake University](https://learn.snowflake.com/en/)\n[Developer Guides](https://www.snowflake.com/en/developers/guides)\n[Documentation](https://docs.snowflake.com/)\n[Privacy Policy](https://www.snowflake.com/en/legal/privacy/privacy-policy/)\n[Site Terms](https://snowflake.com/en/legal/snowflake-site-terms/)\n[Communication Preferences](https://info.snowflake.com/2024-Preference-center.html)\nCookie Settings\n[Do Not Share My Personal Information](https://www.snowflake.com/en/legal/privacy/privacy-policy/)\n[Legal](https://www.snowflake.com/en/legal/)\n[](https://x.com/Snowflake \"X (Twitter)\")\n[](https://www.linkedin.com/company/3653845 \"LinkedIn\")\nSection Title: Collect Logs and Traces From Your Snowflake Applications With Event Tables > Where Data Does More\nContent:\n[](https://www.facebook.com/snowflakedb/ \"Facebook\")\n[](https://www.youtube.com/user/snowflakecomputing \"YouTube\")"]},{"url":"https://docs.snowflake.com/en/developer-guide/builders/observability","title":"Observability in Snowflake apps | Snowflake Documentation","excerpts":["Section Title: Observability in Snowflake apps ¶ > What is observability? ¶\nContent:\nIn an observable system, you can understand what’s happening internally through external evidence generated by the system—evidence\nthat includes telemetry data, alerts, and notifications.\nThrough the evidence of internal functioning it provides, observability makes it easier for you to troubleshoot hard-to-understand behaviors\non a production system. This is especially true in a distributed system, where evidence collected from observation provides a view of\nbehavior across multiple components. Rather than disrupting a production environment to diagnose issues, you can analyze the collected\ndata from it.\nWith an observable system, you can start to answer questions such as the following:\nHow well is the system performing?\nWhere is there latency and what’s causing it?\nWhy is a particular component or process not working as it should?\nWhat improvements can be made?\nSection Title: Observability in Snowflake apps ¶ > Observability in Snowflake ¶\nContent:\nSnowflake supports a model that provides built-in observable data while also giving you ways to add more instrumentation where you need it.\nWhile Snowflake provides support for telemetry data such as logs, metrics, and traces (which are typical of observability), it also\nincludes other features you can use to keep track of system usage and performance.\nThe following lists features you can use to receive and analyze system performance and usage.\n|Collected telemetry data |As your application generates logs, metrics, and traces, Snowflake collects that telemetry data in an event table. Using\nSnowsight, you can explore the data, looking for patterns.\nYou can emit custom telemetry into the event table to provide contextual, domain-specific information to expedite debugging. |\n| --- | --- |\n|History Tables |Use the following views and their associated tables to monitor all usage in your account.\nSection Title: Observability in Snowflake apps ¶ > Observability in Snowflake ¶\nContent:\nQuery History\nCopy History\nTasks |\n|Alerts and notifications |Alerts allow for customizable triggering conditions, actions, and a schedule, in combination with notification integrations for proactive monitoring. |\n|Extensibility with third-party tools |The Snowflake event table adopts [OpenTelemetry](https://opentelemetry.io/docs/) standards, so your\nSnowflake telemetry can easily be consumed by other ecosystem tools. |\nSection Title: Observability in Snowflake apps ¶ > Telemetry data collected for analysis ¶\nContent:\nAs code in your application executes, you can have Snowflake collect data from the code that tells you about the application’s internal\nstate. Using this telemetry data—collected in a Snowflake event table (your account has one by default )—you can look for bottlenecks and other opportunities to optimize.\nTelemetry data must be emitted as your code executes. Snowflake emits some of this data on your code’s behalf without\nyou needing to instrument your code. You can use also APIs included with Snowflake to emit telemetry data from specific parts of your code.\nAs described below, you can analyze the collected data by querying the event table or using the visualizations that capture the data\nin Snowsight.\nSection Title: Observability in Snowflake apps ¶ > ... > Types of telemetry data ¶\nContent:\nTo ensure that the telemetry data you collect is broadly useful, Snowflake telemetry is built on the standard [OpenTelemetry](https://opentelemetry.io/docs/) (sometimes called OTel) framework, an incubating project of the Cloud Native Compute Foundation. Through this framework (and APIs and\ntools designed for it), you can reuse collected data with tools besides Snowflake .\nThrough OpenTelemetry, you can instrument application code to add observability where you want it.\nSnowflake event tables collect log, span, and metrics data in the OpenTelemetry data model. The following describes each type of telemetry\ndata collected in an event table.\n|Logs |Logs record individual operations performed by code. Each log message is generated at\na discrete point during the execution of the code.\nSection Title: Observability in Snowflake apps ¶ > ... > Types of telemetry data ¶\nContent:\n**Instrumenting code** You can log from your code using libraries standard for the language you’re using, as listed in Logging from handler code .\n**Viewing data** You can view log messages for analysis\neither by querying the event table or looking at the visualizations provided in Snowsight.\nThe following image from Snowsight shows a list of collected log messages for a two-hour period in a single database.\n|\n| --- | --- |\n|Metrics |Metrics are measurements calculated over a time period. These values include CPU and memory measurements.\n**Instrumenting code** Snowflake emits metrics data automatically as your code executes, so you don’t need to instrument your code.\n**Viewing data** You can view metrics data for analysis either by\nquerying the event table or looking at the visualizations provided in Snowsight.\nSection Title: Observability in Snowflake apps ¶ > ... > Types of telemetry data ¶\nContent:\nThe following image from Snowsight shows changes in collected metrics data for the execution of a user-defined function.\n|\n|Traces |Traces show distributed events as data flows through a system. In a trace, you can see where time is spent as processing flows\nfrom component to component.\nYou can emit trace events—both within the default span Snowflake creates or from a custom span you create—using libraries\nstandard for the language you’re using, as listed in Logging from handler code .\n**Instrumenting code** You can emit trace events from your code using libraries standard for the language you’re using, as listed in Event tracing from handler code .\n**Viewing data** You can view trace events for analysis either by\nquerying the event table or looking at the visualizations provided in Snowsight.\nThe following image from Snowsight shows the spans resulting as a UDF executes.\n|\nSection Title: Observability in Snowflake apps ¶ > Telemetry best practices ¶\nContent:\nUse the following best practices to get the most out of observablity in Snowflake.\nSet up your environment to capture telemetry data before you need it\nOptimize procedures with query telemetry\nCache redundant DataFrame operations\nManage the amount of telemetry data received for UDFs\nOptimize user-defined functions with query telemetry\n ... \nSection Title: Observability in Snowflake apps ¶ > ... > Manage the amount of telemetry data received for UDFs ¶\nContent:\nWhen adding code to collect telemetry data with UDFs, remember that the UDF execution model can mean many more rows in the event table\nthan for a procedure.\nWhen a UDF is called on every input row, your handler code emits logging statements or span events for every row of the input dataset.\nFor example, a dataset of 10 million rows passed to a UDF would emit 10 million log entries.\nConsider using the following patterns when adding logs and span events to UDFs:\n ... \nSection Title: Observability in Snowflake apps ¶ > ... > Optimize user-defined functions with query telemetry ¶\nContent:\nThe following image shows a span for each row passed to a UDF, where one span’s longer duration suggests that the row might have larger\ndata than the others.\nSection Title: Observability in Snowflake apps ¶ > Alerts and notifications for time-sensitive response ¶\nContent:\nYou can use Snowflake alerts and notifications to have your system reveal what’s going on inside, then take action or send information\nabout system state. Unlike telemetry data, which you collect and analyze later, alerts and notifications are useful when you want an\nimmediate response to what’s happening in the system.\nSection Title: Observability in Snowflake apps ¶ > Alerts and notifications for time-sensitive response ¶\nContent:\nWith an alert , you can specify a condition, action, and schedule, then specify that the action should take\nplace when the condition and schedule details are met.For example, you might use an alert to monitor complex conditions that you specify in SQL. The most common action after an alert\ncondition is met is to send a notification. Snowflake supports sending notifications to email, cloud service provider queues, Slack,\nPagerDuty, and Microsoft Teams.\nWith a notification , you can use included stored procedures to send messages to\ndestinations such as email addresses , webhooks (for client tool integrations such as a chat tool), or to a queue hosted by a cloud service .\n ... \nSection Title: Observability in Snowflake apps ¶ > ... > Alerts and notifications best practices ¶\nContent:\nFor example, you might do this if you’ll take an action in Snowflake each time the alert condition is met.If you intend to perform a complex action after a condition is met, ensure that your warehouse is an appropriate size.\nSection Title: Observability in Snowflake apps ¶ > Tools for analysis and visualization ¶\nContent:\nYou can use the telemetry data collected in your event table with other tools that support the OpenTelemetry data model.\nThrough Snowflake support of OpenTelemetry, you can use APIs, SDKs, and other tools to instrument, generate, collect, and export telemetry\ndata. Using these tools, you can more thoroughly analyze software performance and behavior. Because a Snowflake event table uses this\nwidely-adopted standard, you might also be able to integrate your organization’s observability tools with event tables with little overhead.\nConsider integrating your external tools in one of the following ways:\nIf your observability tools can read from external sources, point them to the event table.\nIf your tools use a push model—in which telemetry data must be sent to the tool—consider using a stored procedure with external access to regularly read telemetry data from\nthe event table and emit it to your tool.\nSection Title: Observability in Snowflake apps ¶ > Tools for analysis and visualization ¶\nContent:\nThe following lists tools you might integrate with Snowflake event tables:\n[Snowflake integration for Datadog](https://docs.datadoghq.com/integrations/snowflake_web/)\nSnowflake integration for Grafana dashboardFor an introduction to using Grafana with Snowflake, see [How to monitor Snowflake with Grafana Cloud](https://grafana.com/blog/2023/05/24/how-to-monitor-snowflake-with-grafana-cloud/) .\n[Snowflake data source for Grafana](https://grafana.com/docs/plugins/grafana-snowflake-datasource/latest/)\n[Snowflake integration for Grafana Cloud](https://grafana.com/docs/grafana-cloud/monitor-infrastructure/integrations/integration-reference/integration-snowflake/)\n[Observe for Snowflake](https://app.snowflake.com/marketplace/listing/GZTYZY3AR0U/observe-inc-observe-for-snowflake) , Observe’s native app for observability\nWas this page helpful?\nYes No\n[Visit Snowflake](https://www.snowflake.com)\n ... \nSection Title: Observability in Snowflake apps ¶ > Privacy Preference Center > Your Privacy > Functional Cookies\nContent:\nFunctional Cookies\nThese cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages.    If you do not allow these cookies then some or all of these services may not function properly.\nCookies Details‎"]},{"url":"https://docs.snowflake.com/en/developer-guide/native-apps/ui-consumer-about","title":"Use and manage Snowflake Native Apps as a consumer | Snowflake Documentation","excerpts":["[DOCUMENTATION](https://docs.snowflake.com)\n/\nGet started\nGuides\nDeveloper\nReference\nRelease notes\nTutorials\n[Status](https://status.snowflake.com)\nOverview\nSnowflake Horizon Catalog\nApplications and tools for connecting to Snowflake\nVirtual warehouses\nDatabases, Tables, & Views\nData types\nData Integration\nSnowflake Openflow\nApache Iceberg™\nApache Iceberg™ Tables\nSnowflake Open Catalog\nData engineering\nData loading\nDynamic Tables\nStreams and Tasks\ndbt Projects on Snowflake\nData Unloading\nStorage Lifecycle Policies\nMigrations\nQueries\nListings\nCollaboration\nSnowflake AI & ML\nSnowflake Postgres\nAlerts & Notifications\nSecurity\nData Governance\nPrivacy\nOrganizations & Accounts\nBusiness continuity & data recovery\nPerformance optimization\nCost & Billing\nGuides Listings Snowflake Marketplace listings Use applications as a consumer\nSection Title: Use and manage Snowflake Native Apps as a consumer ¶\nContent:\nFeature — Generally Available\nThe Snowflake Native App Framework is generally available on supported cloud platforms. For additional information, see Support for private connectivity, VPS, and government regions .\nConsumers can discover and install apps published to the Snowflake Marketplace or shared\nusing private listings.\nThe Native Apps Framework allows consumers to perform the following:\nUse the app by accessing data via Snowflake worksheets.\nView Streamlit apps created by the provider.\nGrant privileges on the app object to users in your organization.\nAssociate references that allow access to object required by the app.\nShare event and logging information with the provider.\nSection Title: ... > Consumer workflow for working with a Snowflake Native App ¶\nContent:\nThe following workflow is what consumers typically do when working with apps:\nBecome a consumer .\nInstall an app from a listing .\nReview the access requests from the app .This includes granting the privileges and creating references required by the app.\n(Optional) Set up an event table to enable logging and\nevent sharing for an app.\nSection Title: Use and manage Snowflake Native Apps as a consumer ¶ > Apps installed from trial listings ¶\nContent:\nWhen the trial period ends for an app installed from a trial listing, Snowflake\nautomatically suspends the app unless the consumer converts the app to a full listing.\nWhen the trial period is about to expire, Snowflake sends an email notification before the app is\nsuspended.\nSnowflake recommends that consumers convert the trial listing into a full listing before the\ntrial period expires. After the app is suspended it may not be possible to resume the app. For example,\nif the provider removes the current version of the app or there are unresolved state changes, the\napp cannot be resumed.\nWhen an app installed from a trial listing is suspended, all data written inside the app is retained\nas long as the consumer does not delete the app.\nSection Title: Use and manage Snowflake Native Apps as a consumer ¶ > Apps installed from trial listings ¶\nContent:\nIf the app installed from a trial listing creates objects in the consumer account outside\nthe application object, consumers can retain these objects after the app is uninstalled. However, they\nmust transfer ownership of the objects before uninstalling the app. See Uninstall a Snowflake Native App .\nWas this page helpful?\nYes No\n[Visit Snowflake](https://www.snowflake.com)\n[Join the conversation](https://community.snowflake.com/s/)\n[Develop with Snowflake](https://developers.snowflake.com)\nShare your feedback\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n[Get your own certification](https://learn.snowflake.com)\nOn this page\nConsumer workflow for working with a Snowflake Native App\nApps installed from trial listings\nRelated content\nInstall an app from a listing\nManage apps\nAllow access to a consumer account\nSet up event tracing for an app\nLanguage: **English**\nSection Title: Use and manage Snowflake Native Apps as a consumer ¶ > Apps installed from trial listings ¶\nContent:\nEnglish\nFrançais\nDeutsch\n日本語\n한국어\nPortuguês"]},{"url":"https://hakkoda.io/resources/native-apps-for-snowflake/","title":"Native Apps for Snowflake: A Monetization Guide | Blog - Hakkoda","publish_date":"2024-05-23","excerpts":["BACK TO RESOURCE PAGE\nSection Title: Native Apps for Snowflake: A Monetization Guide\nContent:\nExplore the flexible pricing models available for businesses looking to monetize their data using Native Apps for Snowflake.\nHakkoda,\nEmpowering Data-driven organizations\nMay 23, 2024\nShare\n[Data Cloud Summit 2024](https://www.snowflake.com/summit/?utm_source=google&utm_medium=paidsearch&utm_campaign=na-us-en-brand-summit-phrase&utm_content=go-rsa-evp-evp-summit2024&utm_term=c-g-data%20cloud%20summit-p-692483594630&gad_source=1&gclid=CjwKCAjwr7ayBhAPEiwA6EIGxGz8CzcwwSEndtlI1XikPxDtiS_Nx9rUddz8_06h3Sc1UrhKMK_KpxoCApwQAvD_BwE) is right around the corner, and [no one is surprised to see AI make an appearance](https://hakkoda.io/resources/ai-solutions-for-enterprise/) in this year’s event messaging: “Build the Future with AI and Apps.” But the other, softly overshadowed, half of that tagline gestures to another major trend that says just as much about Snowflake’s position in the marketplace: the cross-industry data monetization craze.\nSection Title: Native Apps for Snowflake: A Monetization Guide\nContent:\nWith [64% of organizations reporting that they plan to monetize their data by the end of this year](https://hakkoda.io/state-of-data-report-2024/) , [Native Apps for Snowflake](https://www.snowflake.com/en/data-cloud/workloads/applications/native-apps/) are uniquely positioned to help achieve that goal—providing businesses with a secure, scalable, and flexible way to share data products with other Snowflake users. The same flexibility of the Snowflake Marketplace, however, can make it difficult for newcomers to navigate as they begin to build a monetization strategy that aligns with their business model.\nIn this short guide, we will explore the different pricing models offered on the Snowflake Marketplace and provide valuable insights on how to maximize return on investment for your Native App.\nSection Title: Native Apps for Snowflake: A Monetization Guide > Understanding the Snowflake Marketplace\nContent:\nThe [Snowflake Marketplace](https://www.snowflake.com/en/data-cloud/marketplace/) serves as a dynamic ecosystem where providers showcase Snowflake-native applications, enabling users to discover and utilize data-driven solutions without requiring providers to move or provide external access to their data. It functions as a bridge between the creators of data products and their prospective consumers, offering a platform for the latter to try out or purchase data, applications, or AI solutions.\nSection Title: Native Apps for Snowflake: A Monetization Guide > Understanding the Snowflake Marketplace\nContent:\nThis digital marketplace not only facilitates data monetization, but also enhances the visibility of Native Apps to a broader audience of Snowflake users, which in turn amplifies potential revenue streams. It’s a space where the value of data products is recognized and can be effectively commercialized, making it an essential avenue for developers and companies aiming to capitalize on their data-centric applications.\nSection Title: Native Apps for Snowflake: A Monetization Guide > The Two Main Pricing Models Explained\nContent:\nIn the Snowflake marketplace, providers have the flexibility to select between two distinct pricing models tailored to accommodate the diverse needs of their consumers and the nature of their offerings.\nThe first model, known as the **usage-based plan** , operates on a pay-as-you-go principle where consumers are billed retrospectively for their actual usage over any given month. This model is particularly appealing for apps whose usage may vary significantly over time, offering a cost-effective solution for consumers while allowing providers to align their revenue with the app’s consumption levels.\nSection Title: Native Apps for Snowflake: A Monetization Guide > The Two Main Pricing Models Explained\nContent:\nConversely, the **subscription-based plan** provides a more predictable payment model where consumers commit to a fixed term, typically benefiting from uninterrupted access to the application. This model can include options for recurring billing, facilitating a consistent revenue stream for providers with data products that see more consistent, higher volume use. This model is well-suited for apps that offer ongoing value or require regular engagement, thereby encouraging long-term commitments from buyers.\nBoth of these models present unique advantages, making it crucial for providers to carefully assess their app’s characteristics and customer usage patterns when choosing the most appropriate pricing strategy.\nSection Title: ... > Choosing the Right Pricing Model for Your Native App\nContent:\nSelecting an optimal pricing model for your Native App in the Snowflake marketplace demands a strategic approach.\nIt’s crucial to understand your app’s utility and how your target customers will engage with it. If your app’s usage is expected to fluctuate, offering a usage-based plan might align better with your users’ needs, providing them with the flexibility to pay according to their consumption. This model is beneficial for encouraging trials and adoption, as it lowers the entry barrier for potential customers wary of making a significant upfront investment.\nSection Title: ... > Choosing the Right Pricing Model for Your Native App\nContent:\nOn the other hand, if your app delivers continuous value, such as regular data insights or ongoing service enhancements, a subscription-based model could be more fitting. This approach assures a predictable revenue stream and can help build customer loyalty by establishing long-term relationships. It’s particularly effective for apps that are integral to users’ daily operations or decision-making processes.\nIn making your decision, it’s imperative to also analyze your competitive environment. Understanding how similar apps are priced and the preferences of your target market can offer invaluable insights. Additionally, consider the perceived value of your app. Pricing too low might undervalue your offering, while too high a price could deter potential users. Finding the right balance is key to ensuring your pricing model supports both user acquisition and revenue growth.\nSection Title: Native Apps for Snowflake: A Monetization Guide > Maximizing Revenue with Strategic Pricing\nContent:\nTo ensure your Native App achieves its revenue potential on the Snowflake marketplace, a nuanced approach to pricing is paramount.\nThis means moving beyond merely setting a price to embracing a comprehensive strategy that includes engaging with the marketplace dynamics, understanding the needs of your audience, and aligning your pricing with the value delivered.\nOne key element of this process involves using market research to identify trends and preferences, ensuring your app’s pricing is competitive while adequately reflecting its unique value proposition. Experimentation also plays a critical role. Additionally, leveraging analytics to monitor how pricing changes affect user acquisition and retention can provide actionable insights, enabling ongoing optimization.\nSection Title: Native Apps for Snowflake: A Monetization Guide > Maximizing Revenue with Strategic Pricing\nContent:\nBy adopting a data-driven and flexible approach to pricing, you can adjust your strategies in response to market feedback, competitive pressures, and evolving consumer needs, ensuring your pricing strategy remains both appealing to users and conducive to your revenue goals.\nSection Title: ... > Monetizing Your Native Apps in Snowflake with Hakkōda\nContent:\nNavigating the monetization landscape of the Snowflake marketplace can be challenging, especially for organizations new to data product offerings or assetizing their existing data. Fortunately for those organizations not yet sure how to begin their monetization journey, Hakkoda’s Snowflake consulting services offer tailored guidance and support to ensure your Snowflake Native App not only makes it onto the market, but is set up for success as a long-term revenue stream for your business.\nSection Title: ... > Monetizing Your Native Apps in Snowflake with Hakkōda\nContent:\nOur teams of modern data stack experts have worked with businesses in complex and highly regulated industries unlock revenue streams hidden in their data, [leveraging the power of Snowflake and other best-in-breed tools to create bespoke data applications](https://hakkoda.io/customers/how-vgs-built-a-streamlit-app-to-perform-tokenization-in-snowflake/) . We help our clients make informed decisions throughout their Native App’s development and deployment, and help them land on a pricing model that aligns best with their business objectives.\nBy partnering with Hakkoda, you gain access to a comprehensive suite of services designed to amplify your app’s success, from strategic pricing consultancy to actionable market entry strategies. Let us help you transform your data into a profitable asset, leveraging the full power of the Snowflake ecosystem to achieve your monetization goals.\nSection Title: ... > Monetizing Your Native Apps in Snowflake with Hakkōda\nContent:\nReady to begin your monetization journey today? [Let’s talk](https://hakkoda.io/contact/) .\n[Contact us](https://hakkoda.io/contact/)\nRelated topics\n[data innovation](https://hakkoda.io/resources/tag/data-innovation/) [data monetization](https://hakkoda.io/resources/tag/data-monetization/) [pricing models](https://hakkoda.io/resources/tag/pricing-models/) [snowflake marketplace](https://hakkoda.io/resources/tag/snowflake-marketplace/) [snowflake native apps](https://hakkoda.io/resources/tag/snowflake-native-apps/)\nBlog\nFebruary 25, 2026\n[Why Customer Trust Will Define AI Success in 2026](https://hakkoda.io/resources/customer-trust-will-define-ai-success/)\nLearn why customer trust, transparency, and engagement are becoming the defining drivers of AI product success.\n ... \nSection Title: ... > Monetizing Your Native Apps in Snowflake with Hakkōda\nContent:\n[agentic ai](https://hakkoda.io/resources/tag/agentic-ai/) [data in healthcare](https://hakkoda.io/resources/tag/data-in-healthcare/) [hybrid cloud](https://hakkoda.io/resources/tag/hybrid-cloud/)\n[Read more](https://hakkoda.io/resources/interoperability-ai-and-the-future-of-healthcare-delivery/)\nSection Title: Native Apps for Snowflake: A Monetization Guide > Never miss an update​\nContent:\nJoin our mailing list to stay updated with everything Hakkoda.\nSection Title: Native Apps for Snowflake: A Monetization Guide > Ready to learn more?\nContent:\nSpeak with one of our experts.\nLet's talk"]},{"url":"https://www.flexera.com/blog/finops/snowflake-native-apps/","title":"Snowflake Native Apps 101: Build and monetize data apps (2026)","publish_date":"2026-01-27","excerpts":["Section Title: ... > 3) **Monetization via Snowflake Marketplace**\nContent:\nProviders can list and sell Snowflake apps in the Snowflake Marketplace . Consumers install these apps directly into their Snowflake accounts, simplifying deployment and making app monetization straightforward.\nSection Title: ... > 4) **Security and Governance**\nContent:\nSnowflake Native Applications don’t transfer data outside the platform. Providers can package their logic securely, protecting intellectual property. Users maintain control of access permissions, with data security managed by Snowflake’s encryption and governance features .\n ... \nSection Title: ... > What Are the Benefits of Snowflake Native Apps — For Providers?\nContent:\nSnowflake Native Apps offer significant advantages for providers looking to build, distribute and monetize their applications within the Snowflake ecosystem. Here are some of the benefits:\n ... \nSection Title: ... > ➥ **On-Platform Monetization Opportunities**\nContent:\nProviders can easily sell and monetize their Snowflake apps directly within the Snowflake ecosystem via Snowflake Marketplace , bypassing the need for third-party systems.\n ... \nSection Title: ... > What Are the Benefits of Snowflake Native Apps — For Consumers?\nContent:\nSnowflake Native Apps offer significant advantages for end-users, enhancing their ability to integrate, utilize and manage data applications seamlessly within the Snowflake ecosystem. Here are some of the key benefits of Native Snowflake apps for consumers:\nSection Title: Snowflake Native Apps 101: Build and monetize data apps (2026) > ... > ➥ **Quick and Easy Access**\nContent:\nConsumers can easily search for Snowflake Native Applications on the Snowflake Marketplace or in private listings and directly install and use them with a single click.\nSection Title: Snowflake Native Apps 101: Build and monetize data apps (2026) > ... > ➥ **Secure Data Use**\nContent:\nSince Snowflake Native Applications run directly in the consumer’s Snowflake account, data does not need to leave the platform. This eliminates the risks associated with data transfers and ensures compliance with Snowflake’s robust governance and security controls.\n ... \nSection Title: ... > How Do Snowflake Native Applications Work?\nContent:\nSnowflake Native Applications leverage the *Snowflake Native App Framework* to build and deploy data-driven applications directly within the Snowflake ecosystem. These Snowflake apps harness Snowflake’s core features—secure data sharing, analytics, compute and governance—enabling seamless integration and monetization, without requiring data to move outside the platform. The framework supports applications ranging from analytical tools to fully containerized services.\nSnowflake Native App Framework allows:\n ... \nSection Title: ... > Architecture of the Snowflake Native App Framework\nContent:\nThe architecture of the Snowflake Native App Framework operates on a provider-consumer model:\n**Provider** — Creates and shares data and application logic using the framework.\n**Consumer** — Installs and interacts with applications shared by providers.\nSnowflake Native Applications are packaged as **Application Packages** , which contains the necessary logic, metadata and configuration to deploy a Snowflake Native App. This includes:\n**Manifest file** : Configuration details, including setup script locations and versioning.\n**Setup script** : Contains SQL commands for installation and updates.\nThe provider publishes the Snowflake Native app via:\n**Marketplace Listings** — Accessible to all Snowflake users for broad distribution.\n**Private Listings** — Targeted sharing with specific accounts across regions.\n ... \nSection Title: ... > How do Snowflake Native Applications work with Snowpark Container Services?\nContent:\nFor advanced use cases, Snowflake Native Applications can utilize [**Snowpark Container Services**](https://docs.snowflake.com/en/developer-guide/snowpark-container-services/overview) , which enable Snowflake apps to manage containerized workloads within Snowflake. This approach supports high-performance applications, such as machine learning and AI-driven analytics, without externalizing data.\nComponents unique to containerized Snowflake apps:\n**Services specification file** — Applications reference container images stored in the provider’s repository.\n**Compute pool** — A collection of virtual machine nodes where containerized workloads execute.\nSnowflake Native App with Snowpark Container Architecture\nFeatures of Snowpark Container Services include:\n ... \nSection Title: ... > Monetization and Distribution of Snowflake Native App\nContent:\nRaw datasets\nRefined and enriched data\nHistorical datasets for forecasting and machine learning\nReal-time data streams (like weather or traffic updates)\nSpecialized identity or audience data for analytics\nSnowflake Native Applications\nPre-built data pipelines and transformations\nSnowflake Marketplace leverages Snowflake’s architecture to facilitate the secure sharing of data and applications. Transactions are managed natively, eliminating the need for third-party billing systems. Vendors can offer their products through various pricing models, such as pay-as-you-go, one-time payment, usage-based payment, or subscription-based plans, while benefiting from Snowflake’s built-in analytics to track customer engagement.\nLet’s jump right into the juicy part of the article: a step-by-step guide to monetizing Snowflake Native Applications via Snowflake Marketplace.\n ... \nSection Title: ... > **Step 3** —Create and Configure a Private Listing on the Snowflake Marketplace\nContent:\nTo share your app via the Snowflake Marketplace, start by signing in to Snowsight and navigating to **Data Products > Provider Studio** .\nNavigating to Provider Studio in Snowflake\nClick **+ Listing** to create a new listing and proceed with configuration. Enter a name for the listing and specify the discovery permissions, choosing whether the listing will be public or restricted to specific consumers (e.g., select “ **Only specified consumers** ” for private sharing and select “ **Anyone on the Marketplace** ” for public listing).\nCreating a private listing for only specified consumers – Snowflake Native App\nSection Title: ... > **Step 3** —Create and Configure a Private Listing on the Snowflake Marketplace\nContent:\nAttach the application package you prepared earlier as the core data content for the listing. Provide a detailed description outlining your app’s features and usage scenarios. If creating a private listing, add the account identifiers of intended consumers in the “ **Add** **Consumer accounts** ” section. Finally, publish your listing for approval.\nCreating a private listing for only specified consumers – Snowflake Native App\nSection Title: ... > **Step 4** —Create and Configure a Public Paid Listing on the Snowflake Marketplace\nContent:\nNow, to create a public listing, you need to first contact your Snowflake business development partner to approve your paid listing. If you don’t have a business development partner, you’ll need to [submit a case with Marketplace Operations](https://snowflakecommunity.force.com/s/provider-onboarding-case) . Before proceeding, verify that your [role has the required privileges to create a listing](https://other-docs.snowflake.com/en/collaboration/provider-becoming) .\nOnce everything is in place, you need to log in to Snowsight and go to Data Products > Provider Studio from the menu. Select **+ Listing** to open the Create Listing window. Here, name your listing and set its visibility. To make the listing publicly discoverable, choose “ **Anyone on the Marketplace** ” under the discovery settings.\nCreating a paid private listing for only specified consumers – Snowflake Marketplace\n ... \nSection Title: ... > **Step 5** —Submit Listing for Approval\nContent:\nAll listings on the Snowflake Marketplace must undergo a review and approval process before publication. If a listing is rejected, review the provided feedback, make the necessary updates and resubmit it for approval.\nBefore publishing make sure that your listing configuration is complete, you have the **ACCOUNTADMIN** role or **OWNERSHIP** privilege for the associated data product and all sample SQL queries in the listing are validated successfully. To submit your listing, sign in to Snowsight, navigate to **Data Products ➤ Provider Studio** , go to the Listings tab, select your draft listing and click **Submit for Approval** .\nSubmitting listing for final approval from Snowflake\nSection Title: ... > **Step 6** —Final Approval and Publishing\nContent:\nOnce submitted, Snowflake will review your listing and provide an **Approved** or **Denied** status. If denied, review the feedback, make the necessary updates and resubmit the listing. After receiving approval, return to the **Listings** tab, select your approved listing and click **Publish** . Upon publication, the listing will be visible to consumers in all current and future Snowflake Marketplace regions. Regional availability can be managed through cross-cloud auto-fulfillment settings and you can create referral links for direct access to your listing.\n ... \nSection Title: Snowflake Native Apps 101: Build and monetize data apps (2026) > Conclusion\nContent:\nAnd that’s a wrap! Snowflake Native Apps are built using the Snowflake Native App Framework. This allows developers to create, test and launch apps right in Snowflake. The framework simplifies the process of building, launching and integrating advanced tools. It ensures security and governance by tapping into the Snowflake ecosystem. For providers, these apps provide an easy way to sell their solutions on the Snowflake Marketplace, reaching thousands of customers. Meanwhile, consumers get instant access to the apps without needing a complex setup.\nIn this article, we have covered:\nSection Title: Snowflake Native Apps 101: Build and monetize data apps (2026) > Conclusion\nContent:\nWhat are Native Apps in Snowflake?\nKey features and characteristics of Snowflake Native Apps\nWhat are the benefits of Snowflake Native Apps for providers?\nWhat are the benefits of Snowflake Native Apps for consumers?\nHow do Snowflake Native Apps work?\nStep-by-step guide to create a Snowflake Native App\nMonetization and distribution of Snowflake Native Apps\nStep-by-step monetization process via Snowflake Marketplace\n… and so much more!\nSection Title: Snowflake Native Apps 101: Build and monetize data apps (2026) > FAQs\nContent:\n**What are Native Apps in Snowflake?**\nSnowflake Native Apps are designed specifically to operate within the Snowflake ecosystem without requiring external access or movement of sensitive data outside its environment.\n**How can I develop and test a Snowflake Native App locally?**\nDevelopers can set up their environments using tools like VSCode along with necessary extensions provided by Snowflakes such as CLI support.\n**Can I share my Snowflake Native App with other users?**\nYes! Once published on the marketplace after meeting compliance requirements.\n**Does the Snowflake Native App framework support logging and monitoring?**\nYes! Snowflake Native App framework includes telemetry tools that allow developers to monitor application performance post-deployment.\n**What is Streamlit’s role in Snowflake Native apps?**\n ... \nSection Title: Snowflake Native Apps 101: Build and monetize data apps (2026) > FAQs > Want to know more?\nContent:\nTechnology is evolving rapidly—and it's important to stay on top of the latest trends and critical insights. Check out the latest blogs related to FinOps below.\nFinOps\n ... \nSection Title: ... > [FinOps enters its technology value era: Insights from the State of FinOps 2026](https://ww...\nContent:\nFebruary 20, 2026\n×\nGet updates delivered to your inbox\nSubscribe"]},{"url":"https://www.snowflake.com/en/developers/guides/getting-started-with-native-apps/","title":"Getting Started with Snowflake Native Apps","excerpts":["Section Title: Getting Started with Snowflake Native Apps\nContent:\nBuild\nDaniel Myers\n[fork repo](https://github.com/Snowflake-Labs/sfquickstarts/tree/master/site/sfguides/src/getting-started-with-native-apps)\nSection Title: Getting Started with Snowflake Native Apps > Overview\nContent:\nIn this Quickstart, you'll build your first Snowflake Native Application.\nSnowflake Native Applications provide developers a way to package applications for consumption by other Snowflake users. The Snowflake Marketplace is a central place for Snowflake users to discover and install Snowflake Native Applications.\nThe application you'll build will visualize data from suppliers of raw material, used for inventory and supply chain management. Let's explore the application from the perspective of the application provider and an application consumer.\n– **Provider** – In this Quickstart, the provider of the app is a supply chain management company. They have proprietary data on all sorts of shipments. They've built the app, bundled it with access to their shipping data, and listed it on the Snowflake Marketplace so that manufacturers can use it in combination with manufacturing supply chain data to get a view of the supply chain.\nSection Title: Getting Started with Snowflake Native Apps > Overview\nContent:\n– **Consumer** – The consumer of the app manufactures a consumer product – in this case it's ski goggles. They work with several suppliers of the raw material used to manufacture the ski goggles. When the consumer runs the application in their account, the application will render multiple charts to help them visualize information related to:\n**Lead Time Status** The lead time status of the raw material procurement process.\n**Raw Material Inventory** Inventory levels of the raw materials.\n**Purchase Order Status** The status of all the purchase orders (shipped, in transit; completed)\n**Supplier Performance** The performance of each raw material supplier, measured in terms lead time, quality, and cost of raw materials delivered by the supplier.\nSection Title: Getting Started with Snowflake Native Apps > Overview\nContent:\nThe data powering the charts is a combination of the consumer's own supply chain data (orders and site recovery data) in their Snowflake account, while the provider is sharing shipping data to provide an enriched view of the overall supply chain.\nNote that this Quickstart is limited to a single-account installation. You'll use a single Snowflake account to experience the app from the provider's perspective and from the consumer's perspective. Listing to the Snowflake Marketplace and versions / release directives are outside of the scope of this guide.\nLet's get started!\n ... \nSection Title: Getting Started with Snowflake Native Apps > Architecture & Concepts\nContent:\nSnowflake Native Apps are a new way to build data intensive applications. Snowflake Native Apps benefit from running *inside* Snowflake and can be installed from the Snowflake Marketplace, similar to installing an app on a smart phone. Snowflake Native Apps can read and write data to a user's database (when given permission to do so). Snowflake Native Apps can even bring in new data to their users, providing new insights.\nWhen discussing Snowflake Native Apps, there are two personas to keep in mind: **Providers** and **Consumers** .\n**Providers:** Developers of the app. The developer or company publishing an app to the Snowflake Marketplace is an app provider.\n**Consumer:** Users of an app. When a user installs an app from the Snowflake Marketplace, they are a consumer of the app.\nThe diagram below demonstrates this model:\n ... \nSection Title: Getting Started with Snowflake Native Apps > Upload Necessary Data > Upload provider shipping data\nContent:\nNow, let's create a database that we will use to store provider's shipping data. This is the data that we will share with the application so that the consumer can enrich their own supply chain data with it when they install the app in their account.\nThis commands are run by executing the **prepare_data.sh** file. But first we are going to explain its contents.\nFirst the file creates the database, warehouse, schema, and defines the table that will hold the shipping data.\nsnow sql -q \"\nCREATE OR REPLACE WAREHOUSE NATIVE_APP_QUICKSTART_WH WAREHOUSE_SIZE=SMALL INITIALLY_SUSPENDED=TRUE;\n-- this database is used to store our data\nCREATE OR REPLACE DATABASE NATIVE_APP_QUICKSTART_DB;\nUSE DATABASE NATIVE_APP_QUICKSTART_DB;\nCREATE OR REPLACE SCHEMA NATIVE_APP_QUICKSTART_SCHEMA;\nUSE SCHEMA NATIVE_APP_QUICKSTART_SCHEMA;\n ... \nSection Title: Getting Started with Snowflake Native Apps > ... > Upload Consumer Supply Chain Data\nContent:\nIn this scenario, consumers will provide their own supply chain data (orders and site recovery data) from their own Snowflake account. The app will use the consumer's data to render graphs representing different aspects of the supply chain.\nWe'll use the `NATIVE_APP_QUICKSTART_DB` to store the consumer supply chain data.\nsnow sql -q \"\nUSE WAREHOUSE NATIVE_APP_QUICKSTART_WH;\n-- this database is used to store our data\nUSE DATABASE NATIVE_APP_QUICKSTART_DB;\nUSE SCHEMA NATIVE_APP_QUICKSTART_SCHEMA;\nCREATE OR REPLACE TABLE MFG_ORDERS (\norder_id NUMBER(38,0),\nmaterial_name VARCHAR(60),\nsupplier_name VARCHAR(60),\nquantity NUMBER(38,0),\ncost FLOAT,\nprocess_supply_day NUMBER(38,0)\n);\nCREATE OR REPLACE TABLE MFG_SITE_RECOVERY (\nevent_id NUMBER(38,0),\nrecovery_weeks NUMBER(38,0),\nlat FLOAT,\nlon FLOAT\n);\"\n```\n\nCopy\n```\nSection Title: Getting Started with Snowflake Native Apps > ... > Upload Consumer Supply Chain Data\nContent:\nOnce we have created the necessary tables in the provider and consumer side, the next step is to load the csv files to the corresponding tables.\nA stage is available and directly linked to every table created in Snowflake, so we are going to take advantage of that dedicated stage and upload the files directly to the table associated stage. You can find more information about stages types **[here](https://docs.snowflake.com/en/user-guide/data-load-overview)** That is accomplished using the `snow stage copy` command:\n ... \nSection Title: loading site recovery data into table stage > Share the Provider Shipping Data\nContent:\nIn order for this data to be available to the application consumer, we'll need to share it in the application package via reference usage.\nThe following steps are performed by the **setup-package-script.sql** file, which is automatically run whenever we deploy the application:\nCreates a schema in the application package that will be used for sharing the shipping data\nCreate a view within that schema\nGrants usage on the schema to the application package\nGrants reference usage on the database holding the provider shipping data to the application package\nGrants SELECT privileges on the view to the application package, meaning the app will be able to SELECT on the view once it is installed\nSection Title: loading site recovery data into table stage > Share the Provider Shipping Data\nContent:\n-- ################################################################\n-- Create SHARED_CONTENT_SCHEMA to share in the application package\n-- ################################################################\nuse database NATIVE_APP_QUICKSTART_PACKAGE;\ncreate schema shared_content_schema;\nuse schema shared_content_schema;\ncreate or replace view MFG_SHIPPING as select * from NATIVE_APP_QUICKSTART_DB.NATIVE_APP_QUICKSTART_SCHEMA.MFG_SHIPPING;\ngrant usage on schema shared_content_schema to share in application package NATIVE_APP_QUICKSTART_PACKAGE;\ngrant reference_usage on database NATIVE_APP_QUICKSTART_DB to share in application package NATIVE_APP_QUICKSTART_PACKAGE;\ngrant select on view MFG_SHIPPING to share in application package NATIVE_APP_QUICKSTART_PACKAGE;\n```\n\nCopy\n```\nSection Title: loading site recovery data into table stage > Share the Provider Shipping Data\nContent:\nThis flow ensures that the data is able to be shared securely with the consumer through the application. The objects containing the provider's proprietary shipping data are **never** shared directly with the consumer via a Snowflake Native Application. This means the provider's proprietary data remains safe, secure, and in the provider's Snowflake account. Instead, the application package has reference usage on objects (databases) corresponding to the provider's data, and when a consumer install the app (i.e., instantiates the application package), they are able to use the shared data through the application.\nSection Title: loading site recovery data into table stage > Manifest.yml\nContent:\nThe `manifest.yml` file is an important aspect of a Snowflake Native App. This file defines some metadata about the app, configuration options, and provides references to different artifacts of the application.\nLet's take a look at the one provided in the GitHub repository:\n#version identifier\nmanifest_version: 1\nversion:\nname: V1\nlabel: Version One\ncomment: The first version of the application\n#artifacts that are distributed from this version of the package\nartifacts:\nsetup_script: scripts/setup.sql\ndefault_streamlit: app_instance_schema.streamlit\nextension_code: true\n#runtime configuration for this version\nconfiguration:\nlog_level: debug\ntrace_level: off\nreferences:\n ... \nSection Title: loading site recovery data into table stage > Installation Script\nContent:\n-- Grant usage and permissions on objects\ngrant usage on schema app_instance_schema to application role app_instance_role;\ngrant usage on function app_instance_schema.cal_lead_time(int,int,int) to application role app_instance_role;\ngrant usage on procedure app_instance_schema.billing_event(int) to application role app_instance_role;\ngrant usage on function app_instance_schema.cal_distance(float,float,float,float) to application role app_instance_role;\ngrant SELECT on view app_instance_schema.MFG_SHIPPING to application role app_instance_role;\ngrant usage on streamlit app_instance_schema.streamlit to application role app_instance_role;\ngrant usage on procedure app_instance_schema.update_reference(string, string, string) to application role app_instance_role;\n```\n\nCopy\n```\n ... \nSection Title: process_supply_day + duration + recovery_weeks * 7 (days) > Install the Application\nContent:\nTo use the application, we'll first need to install it in the account. Normally you would click an install button in the Snowflake Marketplace, but since we're building the application and using a single account to demonstrate the provider and consumer experiences, you'll run the same `snow app run` CLI command as we mentioned before. This command creates and/or updates the application package and also deploys the application. If you'd like to instead install the application yourself, you can do so like this:\n-- ################################################################\n-- INSTALL THE APP IN THE ACCOUNT\n-- ################################################################\nUSE DATABASE NATIVE_APP_QUICKSTART_DB;\nUSE SCHEMA NATIVE_APP_QUICKSTART_SCHEMA;\nUSE WAREHOUSE NATIVE_APP_QUICKSTART_WH;\n ... \nSection Title: process_supply_day + duration + recovery_weeks * 7 (days) > ... > What we've covered\nContent:\nPrepare data to be included in your application.\nCreate an application package that contains the data and business logic of your application.\nShare data with an application package.\nAdd business logic to an application package.\nView and test the application in Snowsight.\nUpdated Dec 20, 2025\nThis content is provided as is, and is not maintained on an ongoing basis. It may be out of date with current Snowflake instances\n**Subscribe to our monthly newsletter** Stay up to date on Snowflake’s latest products, expert insights and resources—right in your inbox!\nIndustries * [Advertising, Media & Entertainment](https://www.snowflake.com/en/solutions/industries/advertising-media-entertainment/)"]}],"usage":[{"name":"sku_search","count":1}]}