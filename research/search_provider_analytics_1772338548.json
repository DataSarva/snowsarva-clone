{"search_id":"search_20d16dca8bae45b49f7929c3a87883e1","results":[{"url":"https://www.snowflake.com/en/developers/guides/enriching-consumer-data-through-a-snowflake-native-app/","title":"Enriching Consumer Data Through a Snowflake Native App","excerpts":["Section Title: Enriching consumer data through a Snowflake Native App\nContent:\nBy: Hartland Brown | Published: Aug. 08, 2024\n[view quickstart](https://medium.com/snowflake/api-enrichment-framework-c5703a01463b)\n[fork repo](https://github.com/Snowflake-Labs/emerging-solutions-toolbox/tree/main/sfguide-getting-started-with-api-enrichment-framework)\nSection Title: Enriching consumer data through a Snowflake Native App\nContent:\n```\nname: app_environment\nchannels:\n  - snowflake\ndependencies:\n  - matplotlib=*\n  - modin=0.28.1\n  - seaborn=*\n  - snowflake=*\n\ngit clone  [[email protected]](/cdn-cgi/l/email-protection) :Snowflake-Labs/sfguide-data-engineering-pipelines-with-pandas-on-snowflake.git\n\n{\n  \"cells\": [\n    {\n      \"cell_type\": \"markdown\",\n      \"id\": \"1dde02fa-0044-4b20-b7bb-10f1a5b3fabb\",\n      \"metadata\": {\n        \"collapsed\": false,\n        \"name\": \"cell1\"\n      },\n      \"source\": [\n        \"### Data Engineering Pipelines with pandas on Snowflake\\n\",\n        \"\\n\",\n        \"This demo is using the [Snowflake Sample TPC-H dataset](https://docs.snowflake.com/en/user-guide/sample-data-tpch) that should be in a shared database named `SNOWFLAKE_SAMPLE_DATA`. You can run this notebook in a Snowflake Notebook.\nSection Title: Enriching consumer data through a Snowflake Native App\nContent:\n\\n\",\n        \"\\n\",\n        \"During this demo you will learn how to use [pandas on Snowflake](https://docs.snowflake.com/developer-guide/snowpark/python/snowpark-pandas) to:\\n\",\n        \"* Create datframe from a Snowflake table\\n\",\n        \"* Aggregate and transform data to create new features\\n\",\n        \"* Save the result into a Snowflake table\\n\",\n        \"* Create a serverless task to schedule the feature engineering\\n\",\n        \"\\n\",\n        \"pandas on Snowflake is delivered through the Snowpark pandas API as part of the Snowpark Python library (preinstalled with Snowflake Notebooks), which enables scalable data processing of Python code within the Snowflake platform.\n ... \nSection Title: Enriching consumer data through a Snowflake Native App > Overview\nContent:\nThis solution helps a provider setup a native app that allows a consumer to push snowflake data to an API and enrich it with the response of the API. The supporting features allow the provider to: * Control the outbound fields necessary for the API call with the included Enrichment Manager Application, the changes here will automatically be sent to all consumers\nCustomize the parsing logic for the outbound call as well as parse the returned API load\nAutomatically request all necessary permissions for the API and scheduled tasks using the Python Permissions API\nSchedule a configured enrichment on the consumer side to run regularly\n ... \nSection Title: Enriching consumer data through a Snowflake Native App > Overview > About the Architecture\nContent:\nThis framework leverages External Access Functions to expose a Provider API to a consumer to enrich a table with the API response\nThe Python permissions API is used to provide no-code setup\nA SIS app is provided to help provider configure metadata\n ... \nSection Title: Enriching consumer data through a Snowflake Native App > what‚Äôs next?\nContent:\nExplore more developer content and build your skills.\n[docs](https://docs.snowflake.com/)\nguides\n[engineering blog](https://www.snowflake.com/engineering-blog)\n**Subscribe to our monthly newsletter** Stay up to date on Snowflake‚Äôs latest products, expert insights and resources‚Äîright in your inbox!\nProduct * [Platform](https://www.snowflake.com/en/product/platform/)\nSnowflake Intelligence\n[Data Engineering](https://www.snowflake.com/en/product/data-engineering/)\n[Analytics](https://www.snowflake.com/en/product/analytics/)\n[AI](https://www.snowflake.com/en/product/ai/)\n[Applications & Collaboration](https://www.snowflake.com/en/product/applications-and-collaboration/)\n[Pricing](https://www.snowflake.com/en/pricing-options/)\nSupport * [Support](https://www.snowflake.com/en/support/)"]},{"url":"https://www.snowflake.com/en/pricing-options/cost-and-performance-optimization/","title":"FinOps on Snowflake: Built-In Cost and Performance Control","excerpts":["Data for Breakfast Around the World\nDrive impact across your organization with data and agentic intelligence.\n[register now](https://www.snowflake.com/en/data-for-breakfast/)\npricing options\noverview\ncost & performance optimization\npricing calculator\n ... \nSection Title: FinOps on Snowflake > Go from painstaking configurations to a proven, fully-managed service\nContent:\nSince its founding in 2012, Snowflake has provided automated cluster management, maintenance and upgrades ‚Äî all without downtime ‚Äî so you can spend time on valuable data projects\nGet **out-of-the-box governance and security through Snowflake Horizon Catalog** without extra configurations or protocols\nSection Title: FinOps on Snowflake > Go from piecemeal dashboards to built-in cost & performance management\nContent:\nGet granular visibility, control and optimization of Snowflake spend through a unified Cost Management Interface .\nCheck query performance easily to proactively save on costs.\nAutomatically benefit from regular rollouts of performance improvements across all workloads.\nSection Title: FinOps on Snowflake > Maximize your Snowflake spend\nContent:\nAdd flexibility in how you use funds committed in your Snowflake Capacity contract.\nDeploy partner solutions faster by simplifying finance and procurement processes.\nBundle your spend to increase your buying power with Snowflake and partners.\nlearn more\nSection Title: FinOps on Snowflake > Saving time on platform admin. Getting to market faster.\nContent:\nTravelpass CTC Natwest\nTravel and Hospitality ‚ÄúNow, we aren‚Äôt so focused on how to build things. We are focused more on what to build.‚Äù Dan Shah\nManager of Data Science Read the story * **1 week** for 130 Dynamic Tables to be in production after migration\n**65%** cost savings switching from Databricks to Snowflake\nRead the case study Financial Services ‚ÄúNow with fewer ephemeral failures and higher visibility in Snowflake, we have a platform that‚Äôs much easier and cost-effective to operate than managed Spark.‚Äù David Trumbell\nHead of Data Engineering, CTC Read the story * **1st** data availability deadline was hit everyday for the 1st time\n**54%** cost savings switching from managed Spark to Snowflake\nSection Title: FinOps on Snowflake > Saving time on platform admin. Getting to market faster.\nContent:\nRead the case study Financial Services ‚ÄúThe speed at which we‚Äôve delivered wouldn‚Äôt have been possible with other providers.‚Äù Kaushik Ghosh Dastidar\nHead of ESG Cloud Solutions, NatWest Read the story * **6x** reduction in onboarding time from 3 months to 2 weeks\n**$750K** saved in salaries & staff training costs\nRead the case study\n[Resource #### Snowflake Joins the FinOps Foundation Snowflake joins The FinOps Foundation as a Premier Enterprise Member to provide thought leadership and set industry financial best practices. Read more](https://www.finops.org/members/snowflake/)\nResource #### Snowflake Pricing Calculator Curious about Snowflake pricing? Our Snowflake pricing calculator shows credit usage, warehouse costs, and total expenses. Access calculator\n ... \nSection Title: FinOps on Snowflake > Where Data Does More\nContent:\n30-day free trial\nNo credit card required\nCancel anytime\n[start for free](https://signup.snowflake.com/)\nwatch a demo\n**Subscribe to our monthly newsletter** Stay up to date on Snowflake‚Äôs latest products, expert insights and resources‚Äîright in your inbox!\nLearn * Resource Library\nLive Demos\nFundamentals\nTraining\nCertifications\nSnowflake University\nDeveloper Guides\nDocumentation\nPrivacy Policy\nSite Terms\nCommunication Preferences\nCookie Settings\nDo Not Share My Personal Information\nLegal\n[](https://x.com/Snowflake \"X (Twitter)\")\n[](https://www.linkedin.com/company/3653845 \"LinkedIn\")\n[](https://www.facebook.com/snowflakedb/ \"Facebook\")\n[](https://www.youtube.com/user/snowflakecomputing \"YouTube\")\n* Private preview, ‚Ä† Public preview, ‚Ä° Coming soon"]},{"url":"https://www.snowflake.com/en/blog/introducing-snowflake-native-application-framework/","title":"Introducing the Snowflake Native Application Framework","publish_date":"2023-12-21","excerpts":["Section Title: ... > Bring Your Application to Your Customer‚Äôs Data\nContent:\nAlready we are seeing Powered by Snowflake partners‚Äîsuch as Securonix, AuditBoard, Hunters, Supergrain, and MessageGears‚Äîadopt the connected app model for their apps. The Native Application Framework takes connected applications to the next level by allowing providers to bring their application code to their customers‚Äô data (see Figure 1).\nSection Title: ... > Bring Your Application to Your Customer‚Äôs Data\nContent:\nThe Native Application Framework makes it easy to build, sell, and deploy applications within the Data Cloud. You can build applications using Snowflake core functionalities such as UDFs and stored procedures, and even the Streamlit integration (currently in development), then sell them to customers across the Data Cloud via Snowflake Marketplace . The framework also provides telemetry tools to make it easy to monitor and support your applications. What‚Äôs really powerful is that native apps are deployed in the customer‚Äôs account in a way that gives the customer control over their data, while still protecting the provider‚Äôs intellectual property. The native application deployment model complements both connected and managed application deployment models, providing a new degree of flexibility when developing applications. These models are not mutually exclusive.\nSection Title: ... > Bring Your Application to Your Customer‚Äôs Data\nContent:\nWe expect that many developers will implement applications across multiple models, depending on their use case.\n ... \nSection Title: ... > Provider Benefits: Build, Distribute, and Deploy in the Data Cloud\nContent:\nBy publishing their apps in Snowflake Marketplace, they join the Snowflake Marketplace Partner Program and enable thousands of Snowflake customers globally to easily discover, install, and pay for their applications. Finally, applications built on the Native Application Framework can be deployed faster and with improved margins. Because customers don‚Äôt need to move or share access to data, sales and deployment cycles are shorter, especially for customers who may be concerned about vendor risk or data exfiltration issues. Providers also simplify their operations by not having to manage sensitive data, since customers grant data access directly to the application without having to share it with the providers. And because applications use the compute in their customers‚Äô accounts, application providers improve their margins by lowering their own compute costs.\nSection Title: ... > Customer Benefits: Put Your Data to Work, Faster and More Securely\nContent:\nNative applications are also a game changer for customers. They retain control of their data and can get more value from it. Customers can reduce data silos and improve data governance because data doesn‚Äôt need to be moved to or exposed to the app provider. They can control what an application can do in their accounts by granting granular permissions such as external access or log sharing to the application directly using role-based access controls (RBAC). With Snowflake Marketplace, customers can dramatically simplify and shorten application procurement cycles from months to just a few clicks. By discovering out-of-the-box applications in Snowflake Marketplace, customers can immediately put their data to work and get more value from it, compared to building applications themselves. It takes only a few clicks for customers to discover, buy, and use trusted applications, accelerating their time to value."]},{"url":"https://www.flexera.com/blog/finops/snowflake-native-apps/","title":"Snowflake Native Apps 101: Build and monetize data apps (2026)","publish_date":"2026-01-27","excerpts":["Section Title: Snowflake Native Apps 101: Build and monetize data apps (2026) > ... > 8) **Streamlit Integration**\nContent:\nYou can integrate your apps with Streamlit , which allows you to create interactive dashboards within Snowflake. While the integration is still evolving, it supports embedding visualizations in your apps for end-user analytics.\n ... \nSection Title: ... > Architecture of the Snowflake Native App Framework\nContent:\nThe architecture of the Snowflake Native App Framework operates on a provider-consumer model:\n**Provider** ‚Äî Creates and shares data and application logic using the framework.\n**Consumer** ‚Äî Installs and interacts with applications shared by providers.\nSnowflake Native Applications are packaged as **Application Packages** , which contains the necessary logic, metadata and configuration to deploy a Snowflake Native App. This includes:\n**Manifest file** : Configuration details, including setup script locations and versioning.\n**Setup script** : Contains SQL commands for installation and updates.\nThe provider publishes the Snowflake Native app via:\n**Marketplace Listings** ‚Äî Accessible to all Snowflake users for broad distribution.\n**Private Listings** ‚Äî Targeted sharing with specific accounts across regions.\n ... \nSection Title: ... > **Step 3** ‚ÄîCreate and Configure a Private Listing on the Snowflake Marketplace\nContent:\nAttach the application package you prepared earlier as the core data content for the listing. Provide a detailed description outlining your app‚Äôs features and usage scenarios. If creating a private listing, add the account identifiers of intended consumers in the ‚Äú **Add** **Consumer accounts** ‚Äù section. Finally, publish your listing for approval.\nCreating a private listing for only specified consumers ‚Äì Snowflake Native App\n ... \nSection Title: Snowflake Native Apps 101: Build and monetize data apps (2026) > Conclusion\nContent:\nAnd that‚Äôs a wrap! Snowflake Native Apps are built using the Snowflake Native App Framework. This allows developers to create, test and launch apps right in Snowflake. The framework simplifies the process of building, launching and integrating advanced tools. It ensures security and governance by tapping into the Snowflake ecosystem. For providers, these apps provide an easy way to sell their solutions on the Snowflake Marketplace, reaching thousands of customers. Meanwhile, consumers get instant access to the apps without needing a complex setup.\nIn this article, we have covered:\nSection Title: Snowflake Native Apps 101: Build and monetize data apps (2026) > Conclusion\nContent:\nWhat are Native Apps in Snowflake?\nKey features and characteristics of Snowflake Native Apps\nWhat are the benefits of Snowflake Native Apps for providers?\nWhat are the benefits of Snowflake Native Apps for consumers?\nHow do Snowflake Native Apps work?\nStep-by-step guide to create a Snowflake Native App\nMonetization and distribution of Snowflake Native Apps\nStep-by-step monetization process via Snowflake Marketplace\n‚Ä¶ and so much more!\nSection Title: Snowflake Native Apps 101: Build and monetize data apps (2026) > FAQs\nContent:\n**What are Native Apps in Snowflake?**\nSnowflake Native Apps are designed specifically to operate within the Snowflake ecosystem without requiring external access or movement of sensitive data outside its environment.\n**How can I develop and test a Snowflake Native App locally?**\nDevelopers can set up their environments using tools like VSCode along with necessary extensions provided by Snowflakes such as CLI support.\n**Can I share my Snowflake Native App with other users?**\nYes! Once published on the marketplace after meeting compliance requirements.\n**Does the Snowflake Native App framework support logging and monitoring?**\nYes! Snowflake Native App framework includes telemetry tools that allow developers to monitor application performance post-deployment.\n**What is Streamlit‚Äôs role in Snowflake Native apps?**"]},{"url":"https://www.snowflake.com/en/product/features/native-apps/","title":"Snowflake Native Apps","excerpts":["Data for Breakfast Around the World\nDrive impact across your organization with data and agentic intelligence.\n[register now](https://www.snowflake.com/en/data-for-breakfast/)\n ... \nSection Title: ... > How Snowflake‚Äôs Native App Simplifies Technical Orchestration for My Data Outlet Customers ...\nContent:\nOverview:\nSnowflake Native Apps\n[](https://www.snowflake.com/snowflake-native-app-bootcamp/?utm_cta=website-solution-native-apps-timely-content-snowflake-native-app-bootcamp)\nSection Title: Snowflake Native Apps > ... > Snowflake Native App Bootcamp\nContent:\nLearn how the Snowflake Native App Framework enables you to build, market, monetize, and distribute apps to customers across the AI Data Cloud in this comprehensive 120 minute bootcamp.\n[register today](https://www.snowflake.com/snowflake-native-app-bootcamp/?utm_cta=website-solution-native-apps-timely-content-snowflake-native-app-bootcamp)\nSection Title: Snowflake Native Apps > Build Faster, Deploy More Easily, Operate Effortlessly\nContent:\nAvoid the complex costs that come from multiple services and the manual expertise required to optimize. Switch to a fully managed service to efficiently support users and workload while reducing time and effort.* With Snowflake Native App Framework‚Äôs support for Snowpark Container Services,** you can bring sophisticated logic, AI/ML models and compute to your app, and boost your development time to value.\n**Snowflake Native App Framework in general availability on AWS, Azure and GCP* ***In general availability on AWS, public preview on Azure*\nSection Title: Snowflake Native Apps > ... > Snowflake Native App Developer Toolkit\nContent:\nGet immediate access to these exclusive app dev resources plus links to bootcamps, community forums and more.\n[access now](https://www.snowflake.com/snowflake-native-app-developer-toolkit/?utm_cta=workload-page-native-apps)\nSection Title: Snowflake Native Apps > Secured Data + Controlled Code = Accelerated Adoption\nContent:\nSince a Snowflake Native App runs in the customer's account, there is no need for customers to move or provide external access to their data. This results in happier security teams, reduced procurement hurdles and faster time to value for customers.\nSection Title: ... > How Snowflake Native App Helps DTCC Bring Hypothetical Market Scenarios to Customers Read More\nContent:\nExplore Snowflake\nNative Apps\n[](https://app.snowflake.com/marketplace/providers/GZT0ZBEKCNO/Affinity%20Solutions)\n[](https://app.snowflake.com/marketplace/providers/GZT0ZQP41EE/Capital%20One%20Software)\n[](https://app.snowflake.com/marketplace/providers/GZTSZAS2KCS/Cybersyn%2C%20Inc)\n[](https://app.snowflake.com/marketplace/providers/GZT0Z11US76L/LiveRamp)\n[](https://app.snowflake.com/marketplace/providers/GZTSZY7HHV6/Maxa)\n[](https://app.snowflake.com/marketplace/providers/GZTSZ67EU4B/My%20Data%20Outlet)\n[](https://app.snowflake.com/marketplace/providers/GZTYZT5BVG/Sundeck)\n[](https://app.snowflake.com/marketplace/providers/GZSYZMNVC6/SNP)\n[explore app listings](https://app.snowflake.com/marketplace?shareType=application)\n ... \nSection Title: Snowflake Native Apps > Where Data Does More\nContent:\n30-day free trial\nNo credit card required\nCancel anytime\n[start for free](https://signup.snowflake.com/)\nwatch a demo\n**Subscribe to our monthly newsletter** Stay up to date on Snowflake‚Äôs latest products, expert insights and resources‚Äîright in your inbox!\nLearn * Resource Library\nLive Demos\nFundamentals\nTraining\nCertifications\nSnowflake University\nDeveloper Guides\nDocumentation\nPrivacy Policy\nSite Terms\nCommunication Preferences\nCookie Settings\nDo Not Share My Personal Information\nLegal\n[](https://x.com/Snowflake \"X (Twitter)\")\n[](https://www.linkedin.com/company/3653845 \"LinkedIn\")\n[](https://www.facebook.com/snowflakedb/ \"Facebook\")\n[](https://www.youtube.com/user/snowflakecomputing \"YouTube\")"]},{"url":"https://docs.snowflake.com/en/developer-guide/native-apps/requesting-about","title":"Create and access objects in a consumer account - Snowflake Documentation","excerpts":["Developer Snowflake Native App Framework Access objects in a consumer account\nSection Title: Create and access objects in a consumer account ¬∂\nContent:\nFeature ‚Äî Generally Available\nThe Snowflake Native App Framework is generally available on supported cloud platforms. For additional information, see Support for private connectivity, VPS, and government regions .\nThis topic describes how providers can develop a Snowflake Native App to create objects in the\nconsumer account or access existing objects.\nSection Title: ... > Overview of creating and accessing objects in a consumer account ¬∂\nContent:\nSnowflake Native Apps often need to create or access objects in a consumer account. For example,\neven a basic app that allows the consumer to query shared data would require the app\nto create and use a warehouse in the consumer account. An app may also need to connect to external\nservices that are outside Snowflake.\nThe Snowflake Native App Framework provides two ways of requesting privileges to create objects in the consumer account.\n ... \nSection Title: Create and access objects in a consumer account ¬∂ > Comparison of automatic and manual privileges ¬∂\nContent:\nConsumers must approve external access using app specifications. |Consumers must manually create the required network rules and external access integrations and\nbind the integration using references. |\n|Access external identity providers |Apps can create security integrations for external API Authentication.\nConsumers must approve the external connection using app specification. |Consumers must manually create the required security integrations and bind the integration\nwith references |\n|Access to existing objects |Providers must use references to access existing objects.\nConsumers approve access to the references. |Providers must use references to access existing objects.\nSection Title: Create and access objects in a consumer account ¬∂ > Comparison of automatic and manual privileges ¬∂\nContent:\nConsumers approve access to the references. |\n|App development |Providers do not have to write code to determine if the consumer has granted a certain privilege. |Providers must write code that checks if the consumer has granted a certain privilege. |\n|App installation |Consumers do not have to manually create objects or grant privileges. |Consumers must manually create objects in their account or explicitly grant privileges to the app\nusing Snowsight or SQL. |\nSection Title: ... > Security considerations when using auto privileges with app specifications ¬∂\nContent:\nApp specifications only control communications to endpoints outside\nSnowflake. Consumers can approve or decline app specifications to\nallow or prevent the app making connection to these endpoints.\nApp specifications do not prevent the app from creating\nSnowflake objects that control external connections: network rules,\nexternal access integrations, and security integrations. Privileges\nto create these objects are granted using automated granting of\nprivileges.\nApp specifications do not provide data validation. In addition,\nthey do not place any restrictions on secrets or tokens referenced\nby an external access integration or security integration.\nFor example, if a provider configures an external access integration\nof an app to use ALLOWED_AUTHENTICATION_SECRETS and the consumer\napproves the app specification for that integration, the app can later\nmodify the secrets and tokens that it uses."]},{"url":"https://medium.com/@DhamanS/building-a-snowflake-finops-dashboard-with-streamlit-cortex-ai-f05c921565b9","title":"Building a Snowflake FinOps Dashboard with Streamlit + Cortex AI | by Dhaman=DataShaman | Jan, 2026 | Medium","publish_date":"2026-01-19","excerpts":["Sitemap\n[Open in app](https://play.google.com/store/apps/details?id=com.medium.reader&referrer=utm_source%3DmobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)\nWrite\nSearch\nMember-only story\nSection Title: Building a Snowflake FinOps Dashboard with Streamlit + Cortex AI\nContent:\nDhaman=DataShaman\n5 min read\n¬∑\nJan 19, 2026\n--\nShare\nSection Title: ... > A Deep, Production-Grade End-to-End Guide\nContent:\nSnowflake cost optimization is no longer optional.\nAs organizations scale analytics, machine learning, and data products, Snowflake becomes one of the largest ‚Äî and least understood ‚Äî line items in cloud spend. Credits are consumed invisibly, warehouses grow quietly, and by the time finance asks questions, engineering is already on the defensive.\nI‚Äôve seen this story repeat across startups, mid-size companies, and large enterprises.\nIn this article, I‚Äôll walk through **how to build a true FinOps platform inside Snowflake** using:\nNative **ACCOUNT_USAGE**\nA curated **FinOps data model**\n**Streamlit running inside Snowflake**\n**Snowflake Cortex AI** for insights *and* conversational analysis\nThis is not a dashboard tutorial.\nThis is a **system design guide for cost intelligence** .\nPress enter or click to view image in full size\nSection Title: ... > Why Most Snowflake Cost Dashboards Fail\nContent:\nMost teams try one of three approaches:\nQuery `SNOWFLAKE.ACCOUNT_USAGE` directly from BI tools\nExport usage data to an‚Ä¶\n--\n--\nSection Title: Building a Snowflake FinOps Dashboard with Streamlit + Cortex AI > Written by Dhaman=DataShaman\nContent:\n45 followers\n¬∑ 13 following\nAI & Data Advisor | Expert in AI/ML, Data Solutions, Cloud, & Analytics | Driving innovation, automation, & strategy for data-driven success. üöÄ #AI #Data\nSection Title: Building a Snowflake FinOps Dashboard with Streamlit + Cortex AI > No responses yet\nContent:\n[](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--f05c921565b9---------------------------------------)\n[Help](https://help.medium.com/hc/en-us?source=post_page-----f05c921565b9---------------------------------------)\n[Status](https://status.medium.com/?source=post_page-----f05c921565b9---------------------------------------)\nAbout\nCareers\nPress\n[Blog](https://blog.medium.com/?source=post_page-----f05c921565b9---------------------------------------)\n[Privacy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----f05c921565b9---------------------------------------)\n[Rules](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----f05c921565b9---------------------------------------)\n[Terms](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----f05c921565b9---------------------------------------)\nSection Title: Building a Snowflake FinOps Dashboard with Streamlit + Cortex AI > No responses yet\nContent:\n[Text to speech](https://speechify.com/medium?source=post_page-----f05c921565b9---------------------------------------)"]},{"url":"https://www.snowflake.com/en/blog/collect-logs-traces-snowflake-apps/","title":"Collect Logs and Traces From Your Snowflake Applications","publish_date":"2024-08-21","excerpts":["Section Title: Collect Logs and Traces From Your Snowflake Applications With Event Tables\nContent:\nWith Event Tables, developers can instrument logs and traces from their UDFs, UDTFs, stored procedures, Snowflake Native Apps and Snowpark Container Services, then seamlessly route them to a secure, customer-owned Event Table. Developers can then query Event Tables to troubleshoot their applications or gain insights into performance and code behavior.\nLogs and traces are collected and propagated via Snowflake‚Äôs telemetry APIs, then automatically ingested into your Snowflake Event Table.\nSection Title: ... > Simplify troubleshooting in Snowflake Native Apps\nContent:\nEvent Tables are also supported for Snowflake Native Apps. When a Snowflake Native App runs, it is running in the consumer‚Äôs account, generating telemetry data that‚Äôs ingested into their active Event Table.\nOnce the consumer enables event sharing, new telemetry data will be ingested into both the consumer and provider Event Tables. Now the provider has the ability to debug the application that‚Äôs running in the consumer‚Äôs account. The provider only sees the telemetry data that is being shared from this data application‚Äînothing else.\nSection Title: ... > Improve reliability across a variety of use cases\nContent:\nYou can use Event Tables to capture and analyze logs for various use cases: * As a data engineer building UDFs and stored procedures within queries and tasks, you can instrument your code to analyze its behavior based on input data.\nAs a Snowpark developer, you can instrument logs and traces for your Snowflake applications to troubleshoot and improve their performance and reliability.\nAs a Snowflake Native App provider, you can analyze logs and traces from various consumers of your applications to troubleshoot and improve performance.\nSection Title: ... > Improve reliability across a variety of use cases\nContent:\nSnowflake customers ranging from Capital One to phData are already using Event Tables to unlock value in their organization. ‚ÄúThe Event Tables feature simplifies capturing logs in the observability solution we built to monitor the quality and performance of Snowflake data pipelines in Capital One Slingshot,‚Äù says Yudhish Batra, Distinguished Engineer, Capital One Software. ‚ÄúEvent Tables has abstracted the complexity associated with logging from our data pipelines‚Äîspecifically, the central Event Table gives us the ability to monitor and alert from a single location.‚Äù\nAs phData migrates its Spark and Hadoop applications to Snowpark, the Event Tables feature has helped architects save time and hassle.\n‚ÄúWhen working with Snowpark UDFs, some of the logic can become quite complex. In some instances, we had thousands of lines of Java code that needed to be monitored and debugged,‚Äù says Nick Pileggi,\nPrincipal Solutions Architect at phData\nSection Title: ... > Improve reliability across a variety of use cases\nContent:\n. ‚ÄúBefore Event Tables, we had almost no way to see what was happening inside the UDF and correct issues. Once we rolled out Event Tables, the amount of time we spent testing dropped significantly and allowed us to have debug and info-level access to the logs we were generating in Java.‚Äù\nOne large communications service provider also uses logs in Event Tables to capture and analyze failed records during data ingestion from various external services to Snowflake. And a Snowflake Native App provider offering geolocation data services uses Event Tables to capture logs and traces from their UDFs to improve application reliability and performance.\nWith Event Tables, you now have a built-in place to easily and consistently manage logging and tracing for your Snowflake applications. And in conjunction with other features such as Snowflake Alerts and Email Notifications, you can be notified of new events and errors in your applications."]}],"usage":[{"name":"sku_search","count":1}]}
