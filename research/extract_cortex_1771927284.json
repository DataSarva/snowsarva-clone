{"extract_id":"extract_1ade39ed590842d092c37697b2d0b002","results":[{"url":"https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-search/cortex-search-costs","title":"Understanding cost for Cortex Search Services | Snowflake Documentation","publish_date":null,"excerpts":["Guides Snowflake AI & ML Cortex Search Understanding cost\n ... \nSection Title: Understanding cost for Cortex Search Services ¶ > Cost categories ¶\nContent:\n| Category | Description |\n| Virtual warehouse compute | A Cortex Search Service requires a virtual warehouse to refresh the service: to |\n| run queries against base objects when they are initialized and refreshed, including orchestrating text embedding jobs |  |\n| and building the search index. These operations use compute resources, which consume credits . |  |\n| If no changes are identified during a refresh, virtual warehouse credits aren’t consumed since there’s no new data to refresh. |  |\n| EMBED_TEXT tokens compute | A Cortex Search Service automatically embeds each text row in the search column specified in the `ON` parameter into vector space to enable semantic search, |\n| which incurs a credit cost per token embedded. This involves calling EMBED_TEXT_768 or EMBED_TEXT_1024 to convert each document |  |\n| as a series of numbers that encodes its meaning. Embeddings are computed each time a row is inserted or updated. |  |\n| Embeddings are processed incrementally in the evaluation of the source query, so the embedding cost is only incurred for added or |  |\n| changed documents. See Vector Embeddings for more information on vector embedding costs. |  |\nSection Title: Understanding cost for Cortex Search Services ¶ > Cost categories ¶\nContent:\n| Category | Description |\n| Virtual warehouse compute | A Cortex Search Service requires a virtual warehouse to refresh the service: to |\n| run queries against base objects when they are initialized and refreshed, including orchestrating text embedding jobs |  |\n| and building the search index. These operations use compute resources, which consume credits . |  |\n| If no changes are identified during a refresh, virtual warehouse credits aren’t consumed since there’s no new data to refresh. |  |\n| Multi-index Cortex Search | Multi-index Cortex Search Services have costs dependent on how you embed tokens and the number of columns you index. Larger embedding vectors or higher numbers of index columns incur higher costs. Embeddings are computed each time a row is inserted or updated. Embeddings are processed incrementally in the evaluation of the source query, so the embedding cost is only incurred for added or changed documents. |\n| Serving compute | A Cortex Search Service uses multi-tenant serving compute, separate from a user-provided Virtual Warehouse, to establish a low-latency, high-throughput service. |\n| The compute cost for this component is incurred per GB per month (GB/mo) of uncompressed indexed data, where indexed data is the |  |\n| user-provided data in the Cortex Search source query, plus vector embeddings computed on the user’s behalf. |  |\nSection Title: Understanding cost for Cortex Search Services ¶ > Cost categories ¶\nContent:\n| Category | Description |\n| Virtual warehouse compute | A Cortex Search Service requires a virtual warehouse to refresh the service: to |\n| run queries against base objects when they are initialized and refreshed, including orchestrating text embedding jobs |  |\n| and building the search index. These operations use compute resources, which consume credits . |  |\n| If no changes are identified during a refresh, virtual warehouse credits aren’t consumed since there’s no new data to refresh. |  |\n| You incur these costs while the service is available to respond to queries, even if |  |\n| no queries are served during a given period. For the Cortex Search Serving credit rate per GB/mo of indexed data, |  |\n| see the [Snowflake Service Consumption Table](https://www.snowflake.com/legal-files/CreditConsumptionTable.pdf) . |  |\n| Storage | Cortex Search Services materialize the source query into a table stored in your account. This table is transformed into data |\n| structures that are optimized for low-latency serving, also stored in your account. Storage for the table and intermediate data |  |\n| structures are based on a flat rate per terabyte (TB). |  |\n| Cloud services compute | Cortex Search Services use Cloud Services compute to identify changes in underlying base objects and whether the virtual warehouse needs to be invoked. |\nSection Title: Understanding cost for Cortex Search Services ¶ > Cost categories ¶\nContent:\n| Category | Description |\n| Virtual warehouse compute | A Cortex Search Service requires a virtual warehouse to refresh the service: to |\n| run queries against base objects when they are initialized and refreshed, including orchestrating text embedding jobs |  |\n| and building the search index. These operations use compute resources, which consume credits . |  |\n| If no changes are identified during a refresh, virtual warehouse credits aren’t consumed since there’s no new data to refresh. |  |\n| Cloud services compute cost is subject to the constraint that Snowflake only bills if the daily cloud services cost is |  |\n| greater than 10% of the daily warehouse cost for the account. |  |\nSection Title: Understanding cost for Cortex Search Services ¶ > Cost categories ¶\nContent:\nThis topic provides information on these costs, as well as recommendations for managing these costs effectively.\nSection Title: Understanding cost for Cortex Search Services ¶ > Managing indexing costs ¶\nContent:\nYou may find the following tips useful in managing the indexing costs of a Cortex Search Service:\n ... \nSection Title: Understanding cost for Cortex Search Services ¶ > Managing indexing costs ¶\nContent:\nTip\nMaterializing data in a table in the source query with a CREATE OR REPLACE command causes the service to fully\nrefresh and embed all vectors again. It’s better to update the source table incrementally (for example, with MERGE INTO). For more information about vector embedding costs, see Vector Embeddings .\nKeep the source query as simple as possible\nJoins or other complex operations can add to indexing cost (and may be better to apply during ETL or at another\nstage). Refer to the Dynamic Tables Best Practices for more information on optimizing pipelines.\n ... \nSection Title: Understanding cost for Cortex Search Services ¶ > Observing costs ¶\nContent:\nTo learn more about the costs of your Cortex Search services, use the following Account Usage views.\nCORTEX_SEARCH_DAILY_USAGE_HISTORY view contains daily totals for EMBED_TEXT tokens compute and serving credit compute usage per service. Snowflake\nintends to also provide virtual warehouse usage in this view in the future.\nCORTEX_SEARCH_SERVING_USAGE_HISTORY view includes hourly serving credits per service.\nSnowflake intends to make this information available in the Cortex Search administration interface in the future.\nSection Title: Understanding cost for Cortex Search Services ¶ > Estimating costs ¶ > EMBED_TEXT tokens compute ¶\nContent:\nEMBED_TEXT tokens compute is charged per token of text in the search column, per document, charged in to\non the cost of the credit rate of the selected embedding model. This compute cost\nis incurred for each row that is inserted or updated, including for each row in the ON column during the initialization\nof the service and every insert or update thereafter. For information on the per-token\ncost of each embedding model, see Cortex Search Embedding Models :\nFor example, if you create a service on a source query with 10 million rows, each with 500 tokens, and the selected embedding model incurs\n0.05 credits per 1 million tokens, you would expect to pay the following for the initial refresh:\n(0.05 credits per 1 million tokens) * (10,000,000 rows) * (500 tokens per row) / (1,000,000 tokens)= **250 credits**\nFor each row inserted or updated thereafter, you’d incur a cost of 0.05 credits per 1 million tokens.\nTip\nAs an approximation, one token is equivalent to about 3/4 of an English word, or around 4 characters.\nTo get an accurate estimate of tokens per row, use the COUNT_TOKENS function with a representative sample of your actual data.\nSection Title: Understanding cost for Cortex Search Services ¶ > Estimating costs ¶ > Serving compute ¶\nContent:\nServing compute is charged per gigabyte-month of indexed data, where indexed data is the user-provided data\nin the Cortex Search source query, plus vector embeddings computed on the user’s behalf. This is an ongoing cost\nthat is incurred as long as the service’s serving status is resumed. This cost is based on the number of rows indexed,\nthe size of the total indexed data, and the dimensionality of the selected vector embedding model. For information on the dimensionality\nof each embedding model, see Cortex Search Embedding Models :\nFor example, if you have a service with 10 million rows, the selected embedding model has dimension of 768, each row\nin the source query is around 1,000 bytes (including the search column), and the credit cost per GB/mo of indexed data is 6.3,\nyou would expect to pay the following cost per month:\n(6.3 credits per GB) * (10,000,000 rows) * (768 dimensions * 4 bytes per dimension + 1,000 bytes per row) / (1,000,000,000 bytes per GB)= **256.5 credits monthly**\nNote\nThe size of the data per row varies by use case and increases with the amount of data (number of rows and columns) indexed by the service,\nregardless of a column’s designation as a search or attribute column.\nSection Title: Understanding cost for Cortex Search Services ¶ > Estimating costs ¶ > Serving compute ¶ > Multi-index Cortex Search ¶\nContent:\nMulti-index search services often store more data per row to account for the additional index columns. The total data used depends on the number of indices in addition to the table size.\nTo estimate the monthly serving cost for a multi-index service, use the following formula, where `n` is the number\nof vector index columns, `d` is the average number of vector dimensions, and `r` is the number of rows:\n(6.3 credits per GB) * r * (n * d * (4 bytes per dimension) + 1,000 bytes per row) / (1,000,000,000 bytes per GB)\nFor example, if you have a service with 10 million rows and 2 vector indexes each of 768 dimensional vectors, you would expect to pay the following cost per month:\n(6.3 credits per GB) * (10,000,000 rows) * ((2 vector index columns) * (768 vector dimensions) * (4 bytes per dimension) + 1,000 bytes per row) / (1,000,000,000 bytes per GB)= **448.1 credits monthly**\nSection Title: Understanding cost for Cortex Search Services ¶ > Estimating costs ¶ > Warehouse compute ¶\nContent:\nThe virtual warehouse compute cost for Cortex Search Services can vary based on the change rate of your data, target lag, and warehouse size.\nIn general, Cortex Search Services with lower target lag values and higher change rates on underlying data will incur higher Warehouse-related\ncompute costs.\nTipTo get a clear understanding of Warehouse costs related to your Cortex Search pipelines, test\nCortex Search using dedicated warehouses so that the virtual warehouse consumption attributed to Cortex Search refreshes\ncan be isolated. You can move your Cortex Search Service to a shared warehouse after you establish a cost\nbaseline.\n ... \nSection Title: Understanding cost for Cortex Search Services ¶ > Estimating costs ¶ > Cloud Services ¶\nContent:\nCortex Search Services use Cloud Services compute to trigger refreshes when an underlying base object has changed. These costs\ncan vary based on the change rate of your data, target lag, and warehouse size. Cloud services\ncost for change tracking in Cortex Search tend to be lower for use-cases with low change rates. Cloud services compute cost\nis subject to the constraint that Snowflake only bills if the daily cloud services cost is greater than 10% of the daily warehouse\ncost for the account.\nWas this page helpful?\nYes No\n[Visit Snowflake](https://www.snowflake.com)\n[Join the conversation](https://community.snowflake.com/s/)\n[Develop with Snowflake](https://developers.snowflake.com)\nShare your feedback\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n[Get your own certification](https://learn.snowflake.com)\nOn this page\nCost categories\nManaging indexing costs\nManaging serving costs\nObserving costs\nEstimating costs\nRelated content\nCortex Search\nCREATE CORTEX SEARCH SERVICE"],"full_content":null},{"url":"https://docs.snowflake.com/en/sql-reference/account-usage/cortex_functions_usage_history","title":"CORTEX_FUNCTIONS_USAGE_HISTORY view | Snowflake Documentation","publish_date":"2026-01-01","excerpts":["Reference General reference SNOWFLAKE database Account Usage CORTEX_FUNCTIONS_USAGE_HISTORY\nSchema:\nACCOUNT_USAGE\nSection Title: CORTEX_ FUNCTIONS_ USAGE_ HISTORY view ¶\nContent:\nImportant\nThis view is no longer updated. Use the CORTEX_AISQL_USAGE_HISTORY view instead.\nThis Account Usage view can be used to query the usage history of Cortex Functions such\nas COMPLETE and TRANSLATE. The information in the view includes the number of tokens and credits consumed each time a Cortex Function is\ncalled, aggregated in one hour increments based on function and model. The view also includes relevant metadata, such as the warehouse ID,\nstart and end times of the function execution, and the name of the function and the model, if specified.\nNote\nThe view might not include usage information on functions called with recently added models. A new model can take up to 2 weeks to\nbe included in this view.\nSection Title: CORTEX_ FUNCTIONS_ USAGE_ HISTORY view ¶ > Columns ¶\nContent:\n| Column Name | Data Type | Description |\n| START_TIME | TIMESTAMP_LTZ | Start of the specified time range in which the Cortex LLM function usage took place. |\n| END_TIME | TIMESTAMP_LTZ | End of the specified time range in which the Cortex LLM function usage took place. |\n| FUNCTION_NAME | VARCHAR | Name of the Cortex LLM function. |\n| MODEL_NAME | VARCHAR | Model name. Empty for Cortex LLM functions where a model is not specified as an argument. |\n| WAREHOUSE_ID | NUMBER | System-generated identifier for the warehouse used by the query calling the Cortex LLM function. |\n| TOKENS | NUMBER | Number of tokens billed. |\n| TOKEN_CREDITS | NUMBER | Number of credits billed for Cortex LLM functions usage based on tokens processed for the specified function and model (if applicable) during the START_TIME and END_TIME window. |\nSection Title: CORTEX_ FUNCTIONS_ USAGE_ HISTORY view ¶ > Usage notes ¶\nContent:\nThe view provides up-to-date credit usage for an account within the last 365 days (1 year).\nThe credit rate usage is determined based on the function called, model used and the tokens processed as outlined in the [Snowflake Service Consumption Table](https://www.snowflake.com/legal-files/CreditConsumptionTable.pdf) .\nIn some cases where a model is used but is not billed, the model column may be empty.\nWas this page helpful?\nYes No\n[Visit Snowflake](https://www.snowflake.com)\n[Join the conversation](https://community.snowflake.com/s/)\n[Develop with Snowflake](https://developers.snowflake.com)\nShare your feedback\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n[Get your own certification](https://learn.snowflake.com)\nOn this page\nColumns\nUsage notes\nSection Title: CORTEX_ FUNCTIONS_ USAGE_ HISTORY view ¶ > Privacy Preference Center\nContent:\nYour Opt Out Preference Signal is Honored\nYour Privacy\nStrictly Necessary Cookies\nPerformance Cookies\nFunctional Cookies\nTargeting Cookies\nSection Title: CORTEX_ FUNCTIONS_ USAGE_ HISTORY view ¶ > Privacy Preference Center > Your Privacy\nContent:\nWhen you visit any website, it may store or retrieve information on your browser, mostly in the form of cookies. This information might be about you, your preferences or your device and is mostly used to make the site work as you expect it to. The information does not usually directly identify you, but it can give you a more personalized web experience. Because we respect your right to privacy, you can choose not to allow some types of cookies. Click on the different category headings to find out more and change our default settings. However, blocking some types of cookies may impact your experience of the site and the services we are able to offer.\n[More information](https://cookiepedia.co.uk/giving-consent-to-cookies)\n ... \nSection Title: CORTEX_ FUNCTIONS_ USAGE_ HISTORY view ¶ > Privacy Preference Center > Your Privacy > Performance Cookies\nContent:\nPerformance Cookies\nThese cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site.    All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance.\nCookies Details‎\nSection Title: CORTEX_ FUNCTIONS_ USAGE_ HISTORY view ¶ > Privacy Preference Center > Your Privacy > Functional Cookies\nContent:\nFunctional Cookies\nThese cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages.    If you do not allow these cookies then some or all of these services may not function properly.\nCookies Details‎\nSection Title: CORTEX_ FUNCTIONS_ USAGE_ HISTORY view ¶ > Privacy Preference Center > Your Privacy > Targeting Cookies\nContent:\nTargeting Cookies\nThese cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly identifiable personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising.\nCookies Details‎"],"full_content":null},{"url":"https://docs.snowflake.com/en/release-notes/2026/other/2026-01-27-ai-count-tokens-function-ga","title":"Jan 27, 2026: Estimate token usage with AI_COUNT_TOKENS (General availability) | Snowflake Documentation","publish_date":"2026-01-29","excerpts":["Release notes Snowflake server release notes and feature updates Earlier 2026 server release notes and feature updates Feature updates Jan 27, 2026 - Estimate token usage with AI_COUNT_TOKENS (General availability)\nSection Title: Jan 27, 2026: Estimate token usage with AI_ COUNT_ TOKENS ( *General availability* ) ¶\nContent:\nAI_COUNT_TOKENS, a Cortex AI helper function that helps users estimate token consumption and understand how prompt\ncontext impacts cost, is now generally available. AI_COUNT_TOKENS takes into account the function, the LLM model (if\napplicable), and any additional inputs that affect token count, such as categories/labels for classification tasks.\nIn general, token usage increases as prompts become more descriptive and complex. Minimal prompts with limited context\nconsume fewer tokens, while deeper context, task descriptions, and examples increase token counts. With AI_COUNT_TOKENS,\nusers can evaluate how these tradeoffs affect token usage and therefore cost while developing their AI workloads.\nThis capability is especially useful for establishing best practices around:\nHow much context to include in prompts\nWhen richer prompts meaningfully improve accuracy\nWhen examples are worth the additional token cost\nHow best to standardize prompt design across teams and workloads\nThe supported functions include:\nAI_CLASSIFY\nAI_COMPLETE\nAI_EMBED\nAI_SENTIMENT\nAI_SIMILARITY\nAI_TRANSLATE\nFor more information, see AI_COUNT_TOKENS .\nWas this page helpful?\nYes No\n[Visit Snowflake](https://www.snowflake.com)\n[Join the conversation](https://community.snowflake.com/s/)\n[Develop with Snowflake](https://developers.snowflake.com)\nShare your feedback\n[Read the latest on our blog](https://www.snowflake.com/blog/)"],"full_content":null},{"url":"https://medium.com/@angelamarieharney/cortex-ai-cost-queries-in-snowflake-07331811d42d","title":"Cortex AI Cost Queries in Snowflake | by Angela Harney | Jan, 2026 | Medium","publish_date":"2026-02-10","excerpts":["Section Title: Cortex AI Cost Queries in Snowflake > Know how to track your AI Costs and increase Trust\nContent:\nAngela Harney\n14 min read\n·\nJan 19, 2026\n--\nListen\nShare\nPress enter or click to view image in full size\n**Contents**\n- Ingest Costs\n- Ingress Costs\n- Egress Costs\n- Compute Costs\n- Counting Tokens\n- Monthly Invoice Amount\n- Cortex AI Usage History Views\n- My Cost Queries\n- Other Cost Considerations and Monitoring\n-Cost Summary\n-Cortex Code Costs\n-Appendix I: Invoice Cost Details\n- Appendix II: Individual AI Query Details\n- Appendix III: Second-Level Cost Details\nSection Title: Cortex AI Cost Queries in Snowflake > Introduction\nContent:\nI recently had to provide a breakdown of the AI services costs that are listed on the monthly Snowflake invoice so that it was clearly understood where AI costs were being attributed to help make planning decisions.\nSnowflake’s integration of AI services like Cortex AI introduces new dimensions to cost management and understanding AI costs.\nAI costs fall into four main categories: ingest, inference, standard compute, and egress.\nSection Title: Cortex AI Cost Queries in Snowflake > Ingest Costs\nContent:\nIngest costs arise when data is processed by AI models, such as during document parsing or text analysis via Cortex Document AI.\nThese costs are tracked in the `CORTEX_DOCUMENT_PROCESSING_USAGE_HISTORY` view, where `CREDITS_USED` reflects the compute consumed per operation.\nSection Title: Cortex AI Cost Queries in Snowflake > Inference Costs\nContent:\nInference costs occur when AI models are invoked to generate insights, such as through Cortex Search or AI-driven query suggestions or when calling functions like `AI_COMPLETE` or `AI_EMBED` and are billed per token.\nThese can be monitored using the `CORTEX_INFERENCE_USAGE_HISTORY` view. To control costs, teams should add query tags to AI queries, limit high-volume operations, and use serverless compute wisely, especially for one-off AI tasks.\nGenerative functions charge for input and output tokens, whereas Embedding and Similarity functions only charge for input tokens.\nThese costs are tracked in service-specific usage views and are rolled up into the `AI_INFERENCE` line item on the Snowflake monthly invoice.\nSection Title: Cortex AI Cost Queries in Snowflake > Compute Costs\nContent:\nStandard compute costs for AI workloads are tracked separately in `WAREHOUSE_METERING_HISTORY` .\nWhile AI processing uses serverless AI Services compute, the warehouse used to orchestrate the query, such as when using `AI_COMPLETE,` incurs standard compute charges.\nThis cost is independent of AI token usage and must be monitored alongside AI Services credits.\n ... \nSection Title: Cortex AI Cost Queries in Snowflake > Counting Tokens\nContent:\nThe `_AI_COUNT_TOKENS_` function plays a critical role in cost estimation and optimization.\nIt calculates the number of input tokens a given text will consume when processed by a specific AI model, allowing teams to estimate costs before execution, similar to using Explain on a SQL query.\nThis is especially valuable for prompt engineering and avoiding model limits.\nNo AI token charges apply when using `AI_COUNT_TOKENS.` It only incurs standard compute cost, so it is great to use in pre-validating high-volume AI workflows.\nIn this example, it is used in a select query over a table that stores document chunks in columns. Putting document chunks in separate columns takes advantage of Snowflake’s columnar optimization and limits the amount of data scanned for the AI Function being used. This approach is setup to run data through a standard data pipeline.\n```\nselect  \n    SNOWFLAKE.CORTEX.COUNT_TOKENS('llama3-8b',doc_contents) AS token_count, token_count * (.0003/1000) as token_cost;  \n    count_tokens(  \n          , ai_complete  \n          , 'llama3-8b',  \n          , << column_name that stores the document or chunk to assess >>  \n          , 'What are the revenue projections for the next 5 years based on the last two years profit.'  \n        )  \nFROM my_table_name  \n;\n```\nSection Title: Cortex AI Cost Queries in Snowflake > Monthly Invoice Amount\nContent:\nTo get the view of AI costs that will be reflected on your Snowflake invoice at the end of the month, throughout the month you can query the `METERING_DAILY_HISTORY` view filtered by service type.\nThis view contains an aggregation of all AI-related credit consumption and aligns with billing statements. Multiply `CREDITS_USED` by your negotiated credit rate to estimate actual spend.\n```\nSELECT   \n  USAGE_DATE,  \n  SERVICE_TYPE,  \n  CREDITS_USED,  \n  CREDITS_USED * <your_credit_rate> AS estimated_cost_usd  \nFROM SNOWFLAKE.ORGANIZATION_USAGE.METERING_DAILY_HISTORY  \nWHERE SERVICE_TYPE IN ('AI_SERVICES', 'AI_INFERENCE')  \n  AND USAGE_DATE >= DATEADD('month', -3, CURRENT_DATE())  \nORDER BY USAGE_DATE DESC;\n```\nSection Title: Cortex AI Cost Queries in Snowflake > Cortex Usage History Views\nContent:\nCortex AI costs are tracked across different levels in dedicated `ACCOUNT_USAGE` views, each providing granular insights into credit consumption. These views enable monitoring at multiple levels, from high-level trends to individual query costs. Understanding the basics of how usage costs are grouped will help you execute cost queries to review the breakouts.\n*This is not a detailed explanation of all Cortex Usage History views. See cost queries in the Appendixes for alphabetical list of Cortex Usage History views broken out by first-level and second-level views.*\nSection Title: Cortex AI Cost Queries in Snowflake > Cortex Usage History Views > AISQL **Functions**\nContent:\n*The* `CORTEX_FUNCTIONS_QUERY_USAGE_HISTORY` *view provides individual query-level details, including* `_query_id_` *,* `_user_name_` *,* `_warehouse_name_` *,* `_function_name_` *,* `_model_name_` *,* `_tokens_` *, and* `_token_credits_` *. This view is essential for pinpointing expensive queries and optimizing performance and is a first-level consolidation cost on invoices.*\nSection Title: Cortex AI Cost Queries in Snowflake > Cortex Usage History Views > Cortex Analyst\nContent:\n*Usage is metered at a secondary level in the* `CORTEX_ANALYST_USAGE_HISTORY` *view and is aggregated hourly, showing credits consumed and number of messages per user. It does not include* `_query_id_` *, but offers per-user visibility into AI interaction costs. Costs are incurred per successful response (message) not by token count.*\nSection Title: Cortex AI Cost Queries in Snowflake > Cortex Usage History Views > Cortex Search\nContent:\n*Usage is metered at a secondary level in the* `CORTEX_SEARCH_DAILY_USAGE_HISTORY` *view and breaks down costs daily by consumption type (* `_serving_` *,* `_embed_text_tokens_` *) and includes costs for storage, embedding, and serving compute as follows:*\n`CORTEX_SEARCH_DAILY_USAGE_HISTORY` (serving vs. embedding)\n`CORTEX_SEARCH_SERVING_USAGE_HISTORY` (hourly serving credits)\nSection Title: Cortex AI Cost Queries in Snowflake > Cortex Usage History Views > Metering History\nContent:\n*A broader view that can be filtered by* `_SERVICE_TYPE = 'AI_SERVICES'_` *to track overall AI credit usage across all Cortex services, including AI functions, Analyst, and Search.*\nSection Title: Cortex AI Cost Queries in Snowflake > My Cost Queries\nContent:\nMy Snowflake cost queries are broken out by the following practical uses and are filtered to the beginning of the month for 60 days ago including the current month-to-date. So, mid-way through January, the costs for Nov / Dec / Jan will be returned.\n**Invoice Amounts**\n**Invoice Summary** :\n*Invoice line-item alignment*\n**Invoice (First-Level) Detail** :\n*First-level Cortex usage history views that are consolidated within the invoice line items, and also include a standard Compute aggregation from virtual warehouse costs*\n**Activity Details**\n**Individual AI Query Detail** :\n*Cost and performance stats for individual Cortex AI queries*\n**Other Tracking (Second-Level) Detail** :\n*Second-level Cortex usage history views not consolidated for invoicing, but are used for tracking specific activities*\nSection Title: Cortex AI Cost Queries in Snowflake > My Cost Queries > Invoice Summary\nContent:\nUse the following query to isolate warehouse costs at an Organizational billing level to tie-out to the invoice cost for AI INFERENCE and AI SERVICES that are shown in the Snowflake Monthly Invoice Statement.\n```\nSELECT  \n      TO_DATE(USAGE_DATE) AS USAGE_DATE,  \n      'INVOICE SUMMARY' AS SERVICE_GROUP,  \n      SERVICE_TYPE,  \n      SUM(CREDITS_USED) as CREDITS_USED,  \n      SUM(CREDITS_USED) * << your credit price >> AS INVOICE_COST,  \n      0 as TOKENS  \nFROM snowflake.organization_usage.metering_daily_history h  \nWHERE service_type IN ('AI_SERVICES','AI_INFERENCE')   \nAND TO_DATE(USAGE_DATE) >= DATE_TRUNC('MONTH',DATEADD(day, -60, CURRENT_DATE))  \nGROUP BY ALL  \nORDER BY 1  \n;\n```\nSection Title: Cortex AI Cost Queries in Snowflake > My Cost Queries > Invoice and First-Level Details\nContent:\nIn my invoice detail query, AI Inference breaks out to document processing, AI Services breaks out to function usage and there is an aggregation section for Compute as standard compute for virtual warehouse costs. See `APPENDIX I — Invoice Cost Details.`\n*Note: Additional Cortex Usage History views may be added as first-level charges that aggregate to invoice line-items over time as Snowflake enhances their offerings.*\n ... \nSection Title: Cortex AI Cost Queries in Snowflake > My Cost Queries > Second-Level Details\nContent:\nSecond-level charges provided by Snowflake for tracking of specific activities can be found in my query in Appendix II- `APPENDIX III — Second-Level Cost Details.`\nFor example, although the `cortex_search_history_usage` view is consolidated to an invoice line item, the secondary-level `cortex_search_serving_usage_history` view is next-level details for Cortex Search activities.\n*Note: Additional second-level Cortex Usage History views may be added over time as Snowflake enhances their offerings.*\n ... \nSection Title: Cortex AI Cost Queries in Snowflake > Other Cost Considerations and Monitoring > Notebooks\nContent:\nThe `ACCOUNT_USAGE` schema provides granular visibility into AI-related credit consumption. For example, running a query against `SNOWFLAKE.ACCOUNT_USAGE.CORTEX_DOCUMENT_PROCESSING_USAGE_HISTORY` allows you to identify which Notebooks or users trigger the highest AI processing costs.\nSimilarly, `NOTEBOOKS_CONTAINER_RUNTIME_HISTORY` helps track AI workload duration and credit usage for Snowflake Notebooks with AI components.\nBy combining these views with object and query tags, teams can attribute AI costs to specific projects, departments, or users that enable accurate budgeting and chargeback models.\nSection Title: Cortex AI Cost Queries in Snowflake > Other Cost Considerations and Monitoring > Containers\nContent:\nContainers in Snowflake, powered by Snowpark Container Services (SPCS), directly impact AI costs by providing dedicated compute pools (ranging from CPU to GPU), that can be selected for running containerized AI/ML workloads such as fine-tuning LLMs, distributed embedding generation, or deploying custom AI models.\nUnlike standard virtual warehouses, container runtime costs are based on the uptime of the compute pool (small, medium, or GPU-enabled) and are billed per credit hour, with pricing varying by instance type and region.\nRunning AI notebooks or Streamlit apps using container runtime (instead of warehouse runtime) can be more cost-effective, especially for GPU-intensive tasks, since Snowflake manages the underlying infrastructure with no additional fees for registry, networking, or logs.\nHowever, long-running or oversized containers can quickly increase costs, so it’s essential to monitor `CONTAINER_SERVICES_MONITORING_HISTORY` and use auto-suspend settings.\nSection Title: Cortex AI Cost Queries in Snowflake > Other Cost Considerations and Monitoring > Query Patterns and Resource Allocation\nContent:\nEffective cost control still hinges on optimizing query patterns and resource allocation like all other data querying does.\nA common mistake is relying on simple duration-based cost estimates, which ignore concurrency and auto-suspend delays. Instead, use a normalized, warehouse-uptime-based method to allocate costs. Treat each warehouse runtime as a single event, then distribute costs proportionally based on query duration within that window.\nThis method accounts for idle time and concurrency, revealing true cost per query. For AI workloads, this approach helps identify inefficient models or redundant invocations that inflate spend.\nInference costs are especially sensitive to query complexity and model selection.\nReduce data scanned to answer AI prompts that have frequently used data chunks that are flattened and stored in separate columns. This takes advantage of Snowflake’s natural columnar storage optimizations.\nSection Title: Cortex AI Cost Queries in Snowflake > Other Cost Considerations and Monitoring > Complexity\nContent:\nComplex AI models with high token counts or large context windows consume more credits per inference. Teams should evaluate model efficiency, use caching where possible, and avoid overusing AI for simple tasks.\nSection Title: Cortex AI Cost Queries in Snowflake > Other Cost Considerations and Monitoring > Cost Anomalies Feature\nContent:\nSnowflake’s Cost Anomalies feature (released May 2025) can flag unexpected spikes in AI usage, enabling proactive intervention.\n ... \nSection Title: Cortex AI Cost Queries in Snowflake > Other Cost Considerations and Monitoring > Resource Monitors\nContent:\nProactive cost optimization involves continuous monitoring and automation.\nResource monitors in Snowflake are designed to track and control credit consumption primarily for virtual warehouses and cloud services and are limited in their ability to monitor and limit AI Services costs.\nThey can only indirectly control the compute costs associated with executing AI functions by setting credit quotas and triggering alerts or suspensions when usage thresholds are exceeded on virtual warehouses where AI queries run.\nYou can assign a warehouse used for AI workloads to a resource monitor to prevent runaway compute spend, even though the AI token processing cost (serverless) is unaffected. For direct AI cost control, use budgets with monitoring on `AI_SERVICES` usage.\nSection Title: Cortex AI Cost Queries in Snowflake > Other Cost Considerations and Monitoring > Cost Insights and Cloud Services Optimizations Features\nContent:\nSnowflake’s Cost Insights and Cloud Services Optimizations features provide recommendations to reduce inefficiencies, such as unused AI assets or poorly optimized queries.\nSection Title: Cortex AI Cost Queries in Snowflake > Other Cost Considerations and Monitoring > External Tools utilizing Account Usage Views\nContent:\nExternal tools like Atlan can enhance visibility by leveraging metadata from `ACCOUNT_USAGE` to detect unused tables, materialized views, or transient data used in AI pipelines. Regular cleanup of unused AI artifacts and temporary data reduces both storage and compute costs.\nSection Title: Cortex AI Cost Queries in Snowflake > Cost Summary\nContent:\nTo query standard compute costs for AI workloads in Snowflake, focus on the `WAREHOUSE_METERING_HISTORY` view in the `SNOWFLAKE.ACCOUNT_USAGE` schema, which tracks credit consumption for virtual warehouses used during AI operations such as running Cortex Analyst queries, refreshing Cortex Search indexes, or executing embedding jobs.\nSince AI functions like `AI_EXTRACT` or `AI_EMBED` rely on standard warehouses for orchestration, even though the AI processing itself uses AI Services compute, their associated compute costs appear under `CREDITS_USED_COMPUTE` .\nSo, filter by `WAREHOUSE_NAME` and `START_TIME` to isolate usage during AI-related workloads and join with `QUERY_HISTORY` to attribute costs to specific AI queries, such as those using `SNOWFLAKE.CORTEX` functions.\nUse resource monitors or tagging to allocate these costs by team or project, ensuring visibility into AI-driven compute spend alongside general usage.\nSection Title: Cortex AI Cost Queries in Snowflake > Cortex Code Costs\nContent:\nCortex Code charges standard Cloud Services compute costs for accessing metadata in Snowflake such as using `DESCRIBE` or querying `SNOWFLAKE.ACCOUNT_USAGE` tables and these costs can be found in the regular `QUERY_HISTORY` view.\nAt the time of this writing ( *2026–02–09),* Snowflake is not charging for the use of Cortex Code. There are charges being incurred as AI Services for the LLMs that are executed. They will be billed once Snowflake starts charging for the use of Cortex Code with token pricing.\nThese costs show under AI_SERVICES in `WAREHOUSE_METERING_HISTORY` in the following query:\n```\nSELECT  \n  USAGE_DATE,  \n  SERVICE_TYPE,  \n  CREDITS_USED,  \n  CREDITS_USED * <your_credit_rate> AS estimated_cost_usd  \nFROM SNOWFLAKE.ORGANIZATION_USAGE.METERING_DAILY_HISTORY  \nWHERE SERVICE_TYPE IN ('AI_SERVICES', 'AI_INFERENCE')  \n  AND USAGE_DATE >= DATEADD('month', -3, CURRENT_DATE())  \nORDER BY USAGE_DATE DESC;\n```\nSection Title: Cortex AI Cost Queries in Snowflake > Cortex Search Services Cost\nContent:\nThe Cortex Search Service incurs “Serving” compute costs as daily charges even when not actively used.\nYou can run this command to see which Cortex Search Services are running:\nSHOW CORTEX SEARCH SERVICES IN ACCOUNT;\nUnlike virtual warehouses that can auto-suspend, the serving layer of a Cortex Search service runs continuously to enable low-latency queries. You pay a fee based on the uncompressed indexed data size (in GB/month), which includes both your source data and vector embeddings, regardless of whether any queries are executed.\nThis is a “running cost” that persists as long as the service’s SERVING status is RUNNING. For example:\nA very small index < 1 GB ~ less than 1/1000th of a credit/month.\nA 50GB index incurs ~315 credits/month (at $3/credit).\nA 100GB index costs ~630 credits/month (~$1,890), even with zero queries.\nKey Insight: The cost is tied to availability, not usage. To avoid these charges, suspend the service when not in use (e.g., during development). Resuming takes minutes, and it’s a best practice to only keep production services running.\nALTER CORTEX SEARCH SERVICE my_search_service SUSPEND SERVING;\nReplace my_search_service in this statement with your service’s name. This halts billing for the serving layer while preserving your index. To resume later, use RESUME SERVING. You need the OPERATE privilege on the service to perform this action.\nSection Title: Cortex AI Cost Queries in Snowflake > Conclusion\nContent:\nIn conclusion, mastering AI cost querying in Snowflake requires a blend of technical precision and strategic governance.\nFocus on accurate cost attribution, optimized query patterns, smart resource sizing, and vigilance on egress.\nUse native tools like `ACCOUNT_USAGE` , `QUERY_ATTRIBUTION_HISTORY` , and `WAREHOUSE_METERING_HISTORY` to build a transparent cost model.\nCombine this with tagging, budgets, and anomaly detection to turn AI from a cost center into a value-driven capability.\nWith the right approach, Snowflake’s AI Data Cloud can deliver powerful insights without breaking the bank.\n ... \nSection Title: Cortex AI Cost Queries in Snowflake > APPENDIX I — Invoice Cost Details\nContent:\n```\nWITH invoice_cost_details as (  \n  \n    -- COMPUTE - BY WAREHOUSE OR USER NAME  \n    SELECT start_date as USAGE_DATE,  \n        'COMPUTE' as SERVICE_GROUP,  \n        'COMPUTE_WAREHOUSES' AS SERVICE_NAME,  \n        SUM(CREDITS_USED_CLOUD_SERVICES) AS CREDITS_USED,  \n        SUM(CREDITS_USED_CLOUD_SERVICES) * << your credit price here >> AS COST,  \n        0 as TOKENS  \n    FROM snowflake.account_usage.query_history  \n    WHERE TO_DATE(START_DATE) >= DATE_TRUNC('MONTH',DATEADD(day, -60, CURRENT_DATE))  \n    AND WAREHOUSE_NAME = '<< your warehouse name here >>'  \n    GROUP BY ALL  \n    UNION ALL    \n  \n  \n    -- COREX AISQL  \n    SELECT  \n        TO_DATE(USAGE_TIME) AS USAGE_DATE,  \n        'AI SERVICES' as SERVICE_GROUP,  \n        'CORTEX_AISQL' AS SERVICE_NAME,  \n        SUM(TOKEN_CREDITS) AS CREDITS_USED,  \n        SUM(TOKEN_CREDITS) * << your credit price here >> AS COST,  \n        SUM(TOKENS) as TOKENS  \n    FROM SNOWFLAKE.ACCOUNT_USAGE.CORTEX_AISQL_USAGE_HISTORY  \n    WHERE TO_DATE(USAGE_TIME) >= DATE_TRUNC('MONTH',DATEADD(day, -60, CURRENT_DATE))  \n    GROUP BY TO_DATE(USAGE_TIME), DATABASE_NAME  \n    UNION ALL  \n  \n  \n    -- DOCUMENT AI (sequence out of alpha order but placed near other doc ai charges)  \n    SELECT  \n        TO_DATE(START_TIME) AS USAGE_DATE,  \n        'INFERENCE DETAIL' as SERVICE_GROUP,  \n        'DOCUMENT_AI' AS SERVICE_NAME,  \n        SUM(CREDITS_USED) AS CREDITS_USED,\nSection Title: Cortex AI Cost Queries in Snowflake > APPENDIX I — Invoice Cost Details\nContent:\nSUM(CREDITS_USED) * << your credit price here >> AS COST,  \n        0 as TOKENS  \n    FROM SNOWFLAKE.ACCOUNT_USAGE.DOCUMENT_AI_USAGE_HISTORY  \n    WHERE TO_DATE(START_TIME) >= DATE_TRUNC('MONTH',DATEADD(day, -60, CURRENT_DATE))  \n    GROUP BY TO_DATE(START_TIME), DATABASE_NAME  \n    UNION ALL  \n  \n    -- CORTEX FINE_TUNING  \n    SELECT  \n        TO_DATE(START_TIME) AS USAGE_DATE,  \n        'AI SERVICES' as SERVICE_GROUP,  \n        'CORTEX_FINE_TUNING' AS SERVICE_NAME,  \n        SUM(TOKEN_CREDITS) AS CREDITS_USED,  \n        SUM(TOKEN_CREDITS) * << your credit price here >> AS COST,  \n        SUM(TOKENS) as TOKENS  \n    FROM SNOWFLAKE.ACCOUNT_USAGE.CORTEX_FINE_TUNING_USAGE_HISTORY  \n    WHERE TO_DATE(START_TIME) >= DATE_TRUNC('MONTH',DATEADD(day, -60, CURRENT_DATE))  \n    GROUP BY TO_DATE(START_TIME), DATABASE_NAME  \n    UNION ALL  \n  \n    -- CORTEX FUNCTIONS USAGE  \n    SELECT  \n        TO_DATE(START_TIME) AS USAGE_DATE,  \n        'AI SERVICES' as SERVICE_GROUP,  \n        'CORTEX_FUNCTIONS_USAGE' AS SERVICE_NAME,  \n        SUM(TOKEN_CREDITS) AS CREDITS_USED,  \n        SUM(TOKEN_CREDITS) * << your credit price here >> AS COST,  \n        SUM(TOKENS) as TOKENS  \n    FROM SNOWFLAKE.ACCOUNT_USAGE.CORTEX_FUNCTIONS_USAGE_HISTORY  \n    WHERE TO_DATE(START_TIME) >= DATE_TRUNC('MONTH',DATEADD(day, -60, CURRENT_DATE))  \n    GROUP BY TO_DATE(START_TIME), DATABASE_NAME  \n    UNION ALL  \n  \n    -- CORTEX PROVISIONED\nSection Title: Cortex AI Cost Queries in Snowflake > APPENDIX I — Invoice Cost Details\nContent:\nSELECT  \n        TO_DATE(INTERVAL_START_TIME) AS USAGE_DATE,  \n        'AI SERVICES' as SERVICE_GROUP,  \n        'CORTEX_AISQL' AS SERVICE_NAME,  \n        SUM(PTU_CREDITS) AS CREDITS_USED,  \n        SUM(PTU_CREDITS) * << your credit price here >> AS COST,  \n        0 as TOKENS  \n    FROM SNOWFLAKE.ACCOUNT_USAGE.CORTEX_PROVISIONED_THROUGHPUT_USAGE_HISTORY  \n    WHERE TO_DATE(INTERVAL_START_TIME) >= DATE_TRUNC('MONTH',DATEADD(day, -60, CURRENT_DATE))  \n    GROUP BY TO_DATE(INTERVAL_START_TIME), DATABASE_NAME  \n    UNION ALL  \n  \n    -- REST API ACTIVITY  \n    SELECT  \n        TO_DATE(START_TIME) AS USAGE_DATE,  \n        'AI SERVICES' as SERVICE_GROUP,  \n        'CORTEX_REST_API' AS SERVICE_NAME,  \n        0 AS CREDITS_USED,  \n        SUM(0) * << your credit price here >> AS COST,  \n        SUM(TOKENS) as TOKENS  \n    FROM SNOWFLAKE.ACCOUNT_USAGE.CORTEX_REST_API_USAGE_HISTORY  \n    WHERE TO_DATE(START_TIME) >= DATE_TRUNC('MONTH',DATEADD(day, -60, CURRENT_DATE))  \n    GROUP BY TO_DATE(START_TIME), DATABASE_NAME  \n    UNION ALL  \n  \n    -- CORTEX SEARCH (used for serving/text embeddings)  \n    SELECT  \n        TO_DATE(USAGE_DATE) AS USAGE_DATE,  \n        'AI SERVICES' as SERVICE_GROUP,  \n        'CORTEX_SEARCH_DAILY' AS SERVICE_NAME,  \n        SUM(CREDITS) AS CREDITS_USED,  \n        SUM(CREDITS) * << your credit price here >> AS COST,  \n        SUM(TOKENS) as TOKENS  \n    FROM\nSection Title: Cortex AI Cost Queries in Snowflake > APPENDIX I — Invoice Cost Details\nContent:\nSNOWFLAKE.ACCOUNT_USAGE.CORTEX_SEARCH_DAILY_USAGE_HISTORY  \n    WHERE TO_DATE(USAGE_DATE) >= DATE_TRUNC('MONTH',DATEADD(day, -60, CURRENT_DATE))  \n    GROUP BY TO_DATE(USAGE_DATE), DATABASE_NAME  \n  \n)  \nSELECT  \n    USAGE_DATE,  \n    SERVICE_GROUP,  -- AI INFERENCE, AI SERVICES or COMPUTE  \n    SERVICE_NAME,  \n    CREDITS_USED,  \n    COST, -- Adjust multiplier as needed  \n    TOKENS  \nFROM invoice_cost_details  \nORDER BY   \n;\n```\nSection Title: Cortex AI Cost Queries in Snowflake > APPENDIX II— Individual AI Query Details\nContent:\nAny of the Cortex Usage History views that return a Query ID can be applied to the join and query fields in this query.\nSection Title: Cortex AI Cost Queries in Snowflake > APPENDIX II— Individual AI Query Details\nContent:\n```\nSELECT   \n    qh.start_time::date as start_date  \n    , 'aisql_usage' as cost_category  \n    , c.query_id  \n    , qh.warehouse_name  \n    , qh.user_name  \n    , c.model_name  \n    , c.function_name  \n    , c.token_credits  \n    , c.token_credits * << your credit price here >> as cost  \n    , c.tokens  \n    , qh.query_text  \n    , qh.database_name  \n    , qh.schema_name  \n    , qh.query_type  \n    , qh.role_name  \n    , qh.query_tag  \n    , qh.start_time  \n    , qh.end_time  \n    , round(qh.total_elapsed_time / (1000*60),2) duration_mins  \n    , qh.total_elapsed_time as duration_as_ms  \n    , round(div0null(qh.bytes_scanned,(pow(1024,3))),1) as bytes_scan_gb  \n    , round(div0null(qh.bytes_spilled_to_local_storage,pow(1024,3)),2) as local_spill_gb  \n    , round(div0null(qh.bytes_spilled_to_remote_storage,pow(1024,3)),2) as remote_spill_gb  \n    , round(qh.percentage_scanned_from_cache,2) as cache_pct  \n    , round(div0null(qh.bytes_sent_over_the_network,pow(1024,3)),2) as network_gb  \n    , qh.queued_overload_time  \n    , qh.queued_provisioning_time  \n    , qh.transaction_blocked_time  \n    , qh.rows_produced  \n    , qh.rows_inserted  \n    , qh.rows_updated  \n    , qh.rows_deleted  \n    , qh.rows_unloaded  \n    , qh.external_function_total_invocations  \n    , qh.external_function_total_sent_bytes  \n    , qh.external_function_total_sent_rows  \n    , qh.external_function_total_received_bytes\n ... \nSection Title: Cortex AI Cost Queries in Snowflake > `APPENDIX III — Second-Level Cost Details`\nContent:\nThese second-level costs encompass all of the other Cortex Usage History views at the time of the writing of this article and were collected to be able to see the lower layers of activities in Snowflake where Cortex costs are being attributed for tracking purposes.\nSection Title: Cortex AI Cost Queries in Snowflake > `APPENDIX III — Second-Level Cost Details`\nContent:\n```\nWITH second_level_details as (  \n  \n    -- CORTEX ANALYST  \n    SELECT  \n        TO_DATE(START_TIME) AS USAGE_DATE,  \n        'SECOND_LEVEL_DETAIL' as SERVICE_GROUP,  \n        'CORTEX_ANALYST' AS SERVICE_NAME,  \n        'N/A' as DATABASE_NAME,  \n        SUM(CREDITS) AS CREDITS_USED,  \n        SUM(CREDITS) * << your credit price here >> AS COST,  \n        0 as TOKENS  \n    FROM SNOWFLAKE.ACCOUNT_USAGE.CORTEX_ANALYST_USAGE_HISTORY  \n    WHERE TO_DATE(START_TIME) >= DATE_TRUNC('MONTH',DATEADD(day, -60, CURRENT_DATE))  \n    GROUP BY TO_DATE(START_TIME), DATABASE_NAME  \n    UNION ALL  \n  \n    --CORTEX DOCUMENT PROCESSING  \n    SELECT  \n        TO_DATE(START_TIME) AS USAGE_DATE,  \n        'SECOND_LEVEL_DETAIL' as SERVICE_GROUP,  \n        'DOCUMENT_PROCESSING' AS SERVICE_NAME,  \n        'N/A' as DATABASE_NAME,  \n        SUM(CREDITS_USED) AS CREDITS_USED,  \n        SUM(CREDITS_USED) * << your credit price here >> AS COST,  \n        0 as TOKENS  \n    FROM SNOWFLAKE.ACCOUNT_USAGE.CORTEX_DOCUMENT_PROCESSING_USAGE_HISTORY  \n    WHERE TO_DATE(START_TIME) >= DATE_TRUNC('MONTH',DATEADD(day, -60, CURRENT_DATE))  \n    GROUP BY TO_DATE(START_TIME), DATABASE_NAME  \n    UNION ALL  \n  \n    -- CORTEX FUNCTIONS USAGE  \n    SELECT  \n        TO_DATE(START_TIME) AS USAGE_DATE,  \n        'SECOND_LEVEL_DETAIL' as SERVICE_GROUP,  \n        'CORTEX_FUNCTIONS_USAGE' AS SERVICE_NAME,  \n        'N/A' as DATABASE_NAME,\nSection Title: Cortex AI Cost Queries in Snowflake > `APPENDIX III — Second-Level Cost Details`\nContent:\nSUM(TOKEN_CREDITS) AS CREDITS_USED,  \n        SUM(TOKEN_CREDITS) * << your credit price here >> AS COST,  \n        SUM(TOKENS) as TOKENS  \n    FROM SNOWFLAKE.ACCOUNT_USAGE.CORTEX_FUNCTIONS_USAGE_HISTORY  \n    WHERE TO_DATE(START_TIME) >= DATE_TRUNC('MONTH',DATEADD(day, -60, CURRENT_DATE))  \n    GROUP BY TO_DATE(START_TIME), DATABASE_NAME  \n    UNION ALL  \n  \n  \n    -- CORTEX PROVISIONED  \n    SELECT  \n        TO_DATE(INTERVAL_START_TIME) AS USAGE_DATE,  \n        'SECOND_LEVEL_DETAIL' as SERVICE_GROUP,  \n        'CORTEX_AISQL' AS SERVICE_NAME,  \n        'N/A' as DATABASE_NAME,  \n        SUM(PTU_CREDITS) AS CREDITS_USED,  \n        SUM(PTU_CREDITS) * << your credit price here >> AS COST,  \n        0 as TOKENS  \n    FROM SNOWFLAKE.ACCOUNT_USAGE.CORTEX_PROVISIONED_THROUGHPUT_USAGE_HISTORY  \n    WHERE TO_DATE(INTERVAL_START_TIME) >= DATE_TRUNC('MONTH',DATEADD(day, -60, CURRENT_DATE))  \n    GROUP BY TO_DATE(INTERVAL_START_TIME), DATABASE_NAME  \n    UNION ALL  \n  \n    -- CORTEX SEARCH SERVICE  \n    SELECT  \n        TO_DATE(START_TIME) AS USAGE_DATE,  \n        'SECOND_LEVEL_DETAIL' as SERVICE_GROUP,  \n        'CORTEX_SEARCH_SERVING' AS SERVICE_NAME,  \n        DATABASE_NAME,  \n        SUM(CREDITS) AS CREDITS_USED,  \n        SUM(CREDITS) * << your credit price here >> AS COST,  \n        0 as TOKENS  \n    FROM SNOWFLAKE.ACCOUNT_USAGE.CORTEX_SEARCH_SERVING_USAGE_HISTORY  \n    WHERE TO_DATE(START_TIME) >=\nSection Title: Cortex AI Cost Queries in Snowflake > `APPENDIX III — Second-Level Cost Details`\nContent:\nDATE_TRUNC('MONTH',DATEADD(day, -60, CURRENT_DATE))  \n    GROUP BY TO_DATE(START_TIME), DATABASE_NAME  \n  \n)  \nSELECT  \n    USAGE_DATE,  \n    SERVICE_GROUP,  -- SECOND_LEVEL_DETAIL  \n    SERVICE_NAME,  \n    CREDITS_USED,  \n    COST, -- Adjust multiplier as needed  \n    TOKENS  \nFROM second_level_details  \nORDER BY   \n;\n```"],"full_content":null},{"url":"https://docs.snowflake.com/en/user-guide/snowflake-cortex/aisql","title":"Snowflake Cortex AI Functions (including LLM functions) | Snowflake Documentation","publish_date":null,"excerpts":["[DOCUMENTATION](https://docs.snowflake.com)\n/\nEN\nEnglish\nFrançais\nDeutsch\n日本語\n한국어\nPortuguês\nGet started\nGuides\nDeveloper\nReference\nRelease notes\nTutorials\n[Status](https://status.snowflake.com)\nOverview\nSnowflake Horizon Catalog\nApplications and tools for connecting to Snowflake\nVirtual warehouses\nDatabases, Tables, & Views\nData types\nData Integration\nSnowflake Openflow\nApache Iceberg™\nApache Iceberg™ Tables\nSnowflake Open Catalog\nData engineering\nData loading\nDynamic tables\nStreams and tasks\nRow timestamps\ndbt Projects on Snowflake\nData Unloading\nStorage lifecycle policies\nMigrations\nQueries\nListings\nCollaboration\nSnowflake AI & ML\nSnowflake Postgres\nAlerts & Notifications\nSecurity\nData Governance\nPrivacy\nOrganizations & Accounts\nBusiness continuity & data recovery\nPerformance optimization\nCost & Billing\nGuides Snowflake AI & ML Cortex AI Functions\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶\nContent:\nRegional Availability\nAvailable to accounts in select regions .\nSome individual Cortex AI Functions are Preview Features . Check\nthe status of each function before using it in production. Functions not marked as preview features are generally\navailable (GA) and can be used in production.\nUse Cortex AI Functions in Snowflake to run unstructured analytics on text and images with industry-leading LLMs from OpenAI, Anthropic, Meta, Mistral AI, and DeepSeek.\nAI Functions support use cases such as:\nExtracting entities to enrich metadata and streamline validation\nAggregating insights across customer tickets\nFiltering and classifying content by natural language\nSentiment and aspect-based analysis for service improvement\nTranslating and localizing multilingual content\nParsing documents for analytics and RAG pipelines\nAll models are fully hosted in Snowflake, ensuring performance, scalability, and governance while keeping your data secure and in place.\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Available functions ¶\nContent:\nSnowflake Cortex features are provided as SQL functions and are also available in Python .\nCortex AI Functions can be grouped into the following categories:\nCortex AI functions\nHelper functions\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Available functions ¶ > Cortex AI functions ¶\nContent:\nThese task-specific functions are purpose-built managed functions that automate routine tasks, like simple summaries and\nquick translations, that don’t require any customization.\n ... \nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Available functions ¶ > Helper functions ¶\nContent:\nHelper functions are purpose-built managed functions that reduce cases of failures when running other Cortex AI Functions, for example by\ngetting the count of tokens in an input prompt to ensure the call doesn’t exceed a model limit.\nTO_FILE : Creates a reference to a file in an internal or external stage for use with\nAI_COMPLETE and other functions that accept files.\nAI_COUNT_TOKENS : Given an input text, returns the token count based on the model or Cortex\nfunction specified.\nAI_COUNT_TOKENS is the updated version of COUNT_TOKENS (SNOWFLAKE.CORTEX) .\nPROMPT : Helps you build prompt objects for use with AI_COMPLETE and other functions.\nTRY_COMPLETE (SNOWFLAKE.CORTEX) : Works like the COMPLETE function, but returns NULL\nwhen the function could not execute instead of an error code.\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Available functions ¶ > Cortex Guard ¶\nContent:\nCortex Guard is an option of the AI_COMPLETE (or SNOWFLAKE.CORTEX.COMPLETE) function designed to filter possible unsafe and harmful responses from a\nlanguage model. Cortex Guard is currently built with Meta’s Llama Guard 3. Cortex Guard works by evaluating the responses of a language\nmodel before that output is returned to the application. Once you activate Cortex Guard, language model responses which may be associated\nwith violent crimes, hate, sexual content, self-harm, and more are automatically filtered. See COMPLETE arguments for syntax and examples.\nNote\nUsage of Cortex Guard incurs compute charges based on the number of input tokens processed ,\nin addition to the charges for the AI_COMPLETE function.\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Performance considerations ¶\nContent:\nCortex AI Functions are optimized for throughput. We recommend using these functions to process numerous inputs such as text from large SQL tables. Batch processing is typically better suited for AI Functions. For more interactive use cases where latency is important, use the REST API. These are available for simple inference (Complete API), embedding (Embed API) and agentic applications (Agents API).\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Cortex LLM privileges ¶\nContent:\nThis section describes the privileges required for users to access Snowflake Cortex AI Functions. It covers how to control and grant access to these functions using roles and account-level privileges.\n ... \nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Control model access ¶\nContent:\nSnowflake Cortex provides two independent mechanisms to enforce access to models:\nAccount-level allowlist parameter (simple, broad control)\nRole-based access control (RBAC) (fine-grained control)\nYou can use the account-level allowlist to control model access across your entire account, or you can use RBAC to control model access on a per-role basis.\nFor maximum flexibility, you can also use both mechanisms together , if you can accept additional management complexity.\n ... \nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Control model access ¶ > Role-based access control (RBAC) ¶\nContent:\nAlthough Cortex models are not themselves Snowflake objects, Snowflake lets you create model objects in the SNOWFLAKE.MODELS schema that *represent* the Cortex models. By applying RBAC to these objects, you can control access to models the same way you would any other Snowflake object. Supported features accept the identifiers of objects in SNOWFLAKE.MODELS wherever a model can be specified.\nTip\nTo use RBAC exclusively, set CORTEX_MODELS_ALLOWLIST to `'None'` .\n ... \nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > ... > Role-based access control (RBAC) ¶ > Use model objects with supported features ¶\nContent:\nTo use model objects with supported Cortex features, specify the identifier of the model object in SNOWFLAKE.MODELS as the model argument.\nYou can use a fully-qualified identifier, a partial identifier, or a simple model name that will be automatically resolved to SNOWFLAKE.MODELS.\nUsing a fully-qualified identifier:Copy\nUsing a partial identifier:Copy\nUsing automatic lookup with a simple model name:Copy\n ... \nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Control model access ¶ > Supported features ¶\nContent:\nModel access controls are supported by the following features:\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Control model access ¶ > Supported features ¶\nContent:\n| Feature | Account-level allowlist | Role-based access control | Notes |\n| AI_COMPLETE | ✔ | ✔ |  |\n| AI_CLASSIFY | ✔ | ✔ | If the model powering this function is not allowed, the error message contains information about how to modify the allowlist. |\n| AI_FILTER | ✔ | ✔ | If the model powering this function is not allowed, the error message contains information about how to modify the allowlist. |\n| AI_AGG | ✔ | ✔ | If the model powering this function is not allowed, the error message contains information about how to modify the allowlist. |\n| AI_SUMMARIZE_AGG | ✔ | ✔ | If the model powering this function is not allowed, the error message contains information about how to modify the allowlist. |\n| COMPLETE (SNOWFLAKE.CORTEX) | ✔ | ✔ |  |\n| TRY_COMPLETE (SNOWFLAKE.CORTEX) | ✔ | ✔ |  |\n| Cortex REST API | ✔ | ✔ |  |\n| Cortex Playground | ✔ | ✔ |  |\n ... \nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Create stage for media files ¶ > Cortex AI Functions storage best practices ¶\nContent:\nYou may find the following best practices helpful when working with media files in stages with Cortex AI Functions:\nEstablish a scheme for organizing media files in stages. For example, create a separate stage for each team or\nproject, and store the different types of media files in subdirectories.\nEnable directory listings on stages to allow querying and programmatic access to its files.TipTo automatically refresh the directory table for the external stage when new or updated files are available, set\nAUTO_REFRESH = TRUE when creating the stage.\nFor external stages, use fine-grained policies on the cloud provider side (for example, AWS IAM policies)\nto restrict the storage integration’s access to only what is necessary.\nAlways use encryption, such as AWS_SSE or SNOWFLAKE_SSE, to protect your data at rest.\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Cost considerations ¶\nContent:\nSnowflake Cortex AI functions incur compute cost based on the number of tokens processed. Refer to the [Snowflake Service Consumption Table](https://www.snowflake.com/legal-files/CreditConsumptionTable.pdf) for each function’s cost in credits per million tokens.\nA token is the smallest unit of text processed by Snowflake Cortex AI functions. An industry convention for text is that a token is approximately equal to four\ncharacters, although this can vary by model, as can token equivalence for media files.\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Cost considerations ¶\nContent:\nFor functions that generate new text using provided text (AI_COMPLETE, AI_CLASSIFY, AI_FILTER, AI_AGG, AI_SUMMARIZE, and\nAI_TRANSLATE, and their previous versions in the SNOWFLAKE.CORTEX schema), both input and output tokens are billable. For Cortex Guard, only input tokens are counted. The number of input tokens is based on the number of tokens output from AI_COMPLETE (or COMPLETE). Cortex Guard usage is billed in addition to the cost of the AI_COMPLETE (or COMPLETE) function. For AI_SIMILARITY, AI_EMBED, and the SNOWFLAKE.CORTEX.EMBED_* functions, only input tokens are counted. For EXTRACT_ANSWER, the number of billable tokens is the sum of the number of tokens in the `from_text` and `question` fields. AI_CLASSIFY, AI_FILTER, AI_AGG, AI_SENTIMENT, AI_SUMMARIZE_AGG, SUMMARIZE, TRANSLATE, AI_TRANSLATE, EXTRACT_ANSWER,\nENTITY_SENTIMENT, and SENTIMENT add a prompt to the input text in order to generate the response. As a result, the\nbilled token count is higher than the number of tokens in the text you provide. AI_CLASSIFY labels, descriptions, and examples are counted as input tokens for each record processed, not just once for each AI_CLASSIFY call. For AI_PARSE_DOCUMENT (or SNOWFLAKE.CORTEX.PARSE_DOCUMENT), billing is based on the number of document pages processed. TRY_COMPLETE (SNOWFLAKE.CORTEX) does not incur costs for error handling.\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Cost considerations ¶\nContent:\nIf the TRY_COMPLETE(SNOWFLAKE.CORTEX) function returns NULL, no cost\nis incurred. For AI_EXTRACT, both input and output tokens are counted. The `responseFormat` argument is counted as input tokens. For document formats consisting of pages, the number of pages processed is counted as input tokens. Each page in a document is counted as 970 tokens. AI_COUNT_TOKENS incurs only compute cost to run the function. No additional token-based costs are incurred.\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Cost considerations ¶\nContent:\nFor models that support media files such as images or audio:\nAudio files are billed at 50 tokens per second of audio.\nThe token equivalence of images is determined by the model used. For more information, see AI Image cost considerations .\nSnowflake recommends executing queries that call a Snowflake Cortex AI Function with a smaller\nwarehouse (no larger than MEDIUM). Larger warehouses do not increase performance. The cost associated with keeping a warehouse active\ncontinues to apply when executing a query that calls a Snowflake Cortex LLM Function. For general information on\ncompute costs, see Understanding compute cost .\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Cost considerations ¶ > Warehouse sizing ¶\nContent:\nSnowflake recommends using a warehouse size no larger than MEDIUM when calling Snowflake Cortex AI\nFunctions. Using a larger warehouse than necessary does not increase performance, but can result in unnecessary costs.\nThis recommendation may change in the future as we continue to evolve Cortex AI Functions.\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Cost considerations ¶ > Track costs for AI services ¶\nContent:\nTo track credits used for AI Services including LLM Functions in your account, use the METERING_HISTORY view :\n```\nSELECT * \n  FROM SNOWFLAKE . ACCOUNT_USAGE . METERING_DAILY_HISTORY \n  WHERE SERVICE_TYPE = 'AI_SERVICES' ;\n```\nCopy\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Cost considerations ¶ > Track credit consumption for Cortex AI Functions ¶\nContent:\nTo view the credit and token consumption for each AI Function call, use the CORTEX_FUNCTIONS_USAGE_HISTORY view :\n```\nSELECT * \n  FROM SNOWFLAKE . ACCOUNT_USAGE . CORTEX_FUNCTIONS_USAGE_HISTORY ;\n```\nCopy\nYou can also view the credit and token consumption for each query within your Snowflake account. Viewing the credit and token consumption for each query helps you identify queries that are consuming the most credits and tokens.\nThe following example query uses the CORTEX_FUNCTIONS_QUERY_USAGE_HISTORY view to show the credit and token consumption for all of your queries within your account.\n```\nSELECT * FROM SNOWFLAKE . ACCOUNT_USAGE . CORTEX_FUNCTIONS_QUERY_USAGE_HISTORY ;\n```\nCopy\nYou can also use the same view to see the credit and token consumption for a specific query.\n```\nSELECT * FROM SNOWFLAKE . ACCOUNT_USAGE . CORTEX_FUNCTIONS_QUERY_USAGE_HISTORY \n WHERE query_id = '<query-id>' ;\n```\nCopy\nNote\nYou can’t get granular usage information for requests made with the REST API.\nThe query usage history is grouped by the models used in the query. For example, if you ran:\n```\nSELECT AI_COMPLETE ( 'mistral-7b' , 'Is a hot dog a sandwich' ), AI_COMPLETE ( 'mistral-large' , 'Is a hot dog a sandwich' );\n```\nCopy\nThe query usage history would show two rows, one for `mistral-7b` and one for `mistral-large` .\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Model restrictions ¶\nContent:\nModels used by Snowflake Cortex have limitations on size as described in the table below. Sizes are given in tokens.\nTokens generally represent about four characters of text, so the number of words corresponding to a limit is\nless than the number of tokens. Inputs exceeding the context window limit result in an error. Output which would exceed the\ncontext window limit is truncated.\nThe maximum size of the output that a model can produce is limited by the following:\nThe model’s output token limit.\nThe space available in the context window after the model consumes the input tokens.\nFor example, `claude-3-5-sonnet` has a context window of 200,000 tokens. If 100,000 tokens are used for the input, the model can generate up to 8,192 tokens. However, if 195,000 tokens are used as input, then the model can only generate up to 5,000 tokens for a total of 200,000 tokens.\nImportant\nIn the AWS AP Southeast 2 (Sydney) region:\nthe context window for `llama3-8b` and `mistral-7b` is 4,096 tokens.\nthe context window for `llama3.1-8b` is 16,384 tokens.\nthe context window for the Snowflake managed model from the SUMMARIZE function is 4,096 tokens.\nIn the AWS Europe West 1 (Ireland) region:\nthe context window for `llama3.1-8b` is 16,384 tokens.\nthe context window for `mistral-7b` is 4,096 tokens.\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Model restrictions ¶\nContent:\n| Function | Model | Context window (tokens) | Max output (tokens) |\n| COMPLETE | `llama4-maverick` | 128,000 | 8,192 |\n|  | `llama4-scout` | 128,000 | 8,192 |\n|  | `snowflake-arctic` | 4,096 | 8,192 |\n|  | `deepseek-r1` | 32,768 | 8,192 |\n|  | `claude-sonnet-4-5` | 200,000 | 64,000 |\n|  | `claude-haiku-4-5` | 200,000 | 64,000 |\n|  | `claude-opus-4-5` | 200,000 | 64,000 |\n|  | `claude-4-sonnet` | 200,000 | 32,000 |\n|  | `claude-3-7-sonnet` | 200,000 | 32,000 |\n|  | `claude-3-5-sonnet` | 200,000 | 8,192 |\n|  | `gemini-3-pro` | 200,000 | 64,000 |\n|  | `mistral-large` | 32,000 | 8,192 |\n|  | `mistral-large2` | 128,000 | 8,192 |\n|  | `openai-gpt-4.1` | 128,000 | 32,000 |\n|  | `openai-o4-mini` | 200,000 | 32,000 |\n|  | `openai-gpt-5` | 272,000 | 8,192 |\n|  | `openai-gpt-5-mini` | 272,000 | 8,192 |\n|  | `openai-gpt-5-nano` | 272,000 | 8,192 |\n|  | `openai-gpt-5-chat` | 128,000 | 8,192 |\n|  | `openai-gpt-oss-120b` | 128,000 | 8,192 |\n|  | `openai-gpt-oss-20b` | 128,000 | 8,192 |\n|  | `mixtral-8x7b` | 32,000 | 8,192 |\n|  | `llama3-8b` | 8,000 | 8,192 |\n|  | `llama3-70b` | 8,000 | 8,192 |\n|  | `llama3.1-8b` | 128,000 | 8,192 |\n|  | `llama3.1-70b` | 128,000 | 8,192 |\n|  | `llama3.3-70b` | 128,000 | 8,192 |\n|  | `snowflake-llama-3.3-70b` | 128,000 | 8,192 |\n|  | `llama3.1-405b` | 128,000 | 8,192 |\n|  | `snowflake-llama-3.1-405b` | 8,000 | 8,192 |\n|  | `mistral-7b` | 32,000 | 8,192 |\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Model restrictions ¶\nContent:\n| Function | Model | Context window (tokens) | Max output (tokens) |\n| COMPLETE | `llama4-maverick` | 128,000 | 8,192 |\n|  | `llama4-scout` | 128,000 | 8,192 |\n|  | `snowflake-arctic` | 4,096 | 8,192 |\n|  | `deepseek-r1` | 32,768 | 8,192 |\n| EMBED_TEXT_768 | `e5-base-v2` | 512 | n/a |\n|  | `snowflake-arctic-embed-m` | 512 | n/a |\n| EMBED_TEXT_1024 | `nv-embed-qa-4` | 512 | n/a |\n|  | `multilingual-e5-large` | 512 | n/a |\n|  | `voyage-multilingual-2` | 32,000 | n/a |\n| AI_EXTRACT | `arctic-extract` | 128,000 | 51,200 |\n| AI_FILTER | Snowflake managed model | 128,000 | n/a |\n| AI_CLASSIFY | Snowflake managed model | 128,000 | n/a |\n| AI_AGG | Snowflake managed model | 128,000 per row |  |\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Model restrictions ¶\nContent:\ncan be used across multiple rows |8,192 |\n|AI_SENTIMENT |Snowflake managed model |2,048 |n/a |\n|AI_SUMMARIZE_AGG |Snowflake managed model |128,000 per row\ncan be used across multiple rows |8,192 |\n|ENTITY_SENTIMENT |Snowflake managed model |2,048 |n/a |\n|EXTRACT_ANSWER |Snowflake managed model |2,048 for text\n64 for question |n/a |\n|SENTIMENT |Snowflake managed model |512 |n/a |\n|SUMMARIZE |Snowflake managed model |32,000 |4,096 |\n|TRANSLATE |Snowflake managed model |4,096 |n/a |\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Choosing a model ¶\nContent:\nThe Snowflake Cortex AI_COMPLETE function supports multiple models of varying capability, latency, and cost. These models\nhave been carefully chosen to align with common customer use cases. To achieve the best performance per credit , choose a model that’s a good match for the content size and\ncomplexity of your task. Here are brief overviews of the available models.\n ... \nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Choosing a model ¶ > Large models ¶\nContent:\n`snowflake-llama3.1-405b` is a model derived from the open source llama3.1 model. It uses the [SwiftKV optimizations](https://www.snowflake.com/en/blog/up-to-75-lower-inference-cost-llama-meta-llm/) developed by the Snowflake AI research team to deliver up to a 75% inference cost reduction. SwiftKV achieves higher throughput performance with minimal accuracy loss.\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Choosing a model ¶ > Medium models ¶\nContent:\n`llama3.1-70b` is an open source model that demonstrates state-of-the-art performance ideal for chat applications,\ncontent creation, and enterprise applications. It is a highly performant, cost effective model that enables diverse use\ncases with a context window of 128K. `llama3-70b` is still supported and has a context window of 8K.\n`snowflake-llama3.3-70b` is a model derived from the open source llama3.3 model. It uses the [SwiftKV optimizations](https://www.snowflake.com/en/blog/up-to-75-lower-inference-cost-llama-meta-llm/) developed by the Snowflake AI research team to deliver up to a 75% inference cost reduction. SwiftKV achieves higher throughput performance with minimal accuracy loss.\n`snowflake-arctic` is Snowflake’s top-tier enterprise-focused LLM. Arctic excels at enterprise tasks such as SQL\ngeneration, coding and instruction following benchmarks.\n`mixtral-8x7b` is ideal for text generation, classification, and question answering. Mistral models are optimized\nfor low latency with low memory requirements, which translates into higher throughput for enterprise use cases.\n ... \nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > ... > Call Cortex AI Functions in Snowpark Python ¶\nContent:\nYou can use Snowflake Cortex AI Functions in the Snowpark Python API. These functions include the following. Note that the functions in Snowpark Python have names in Pythonic “snake_case”\nformat, with words separated by underscores and all letters in lowercase.\n[ai_agg](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.functions.ai_agg)\n[ai_classify](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.functions.ai_classify)\n[ai_complete](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.functions.ai_complete)\n[ai_filter](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.functions.ai_filter)\n[ai_similarity](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.functions.ai_similarity)\n[ai_summarize_agg](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/snowpark/api/snowflake.snowpark.functions.ai_summarize_agg)\n ... \nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > ... > Call Cortex AI Functions in Snowflake ML ¶\nContent:\nSnowflake ML contains the older AI Functions, those with names that don’t\nbegin with “AI”. These functions are supported in version 1.1.2 and later of Snowflake ML. The names are rendered in Pythonic\n“snake_case” format, with words separated by underscores and all letters in lowercase.\nIf you run your Python script outside of Snowflake, you must create a Snowpark session to use these functions. See Connecting to Snowflake for instructions.\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > ... > Call Cortex AI Functions in Snowflake ML ¶ > Process single values ¶\nContent:\nThe following Python example illustrates calling Snowflake Cortex AI functions on single values:\n```\nfrom snowflake.cortex import complete , extract_answer , sentiment , summarize , translate \n\n text = \"\"\" \n    The Snowflake company was co-founded by Thierry Cruanes, Marcin Zukowski, \n    and Benoit Dageville in 2012 and is headquartered in Bozeman, Montana. \n \"\"\" \n\n print ( complete ( \"llama3.1-8b\" , \"how do snowflakes get their unique patterns?\" )) \n print ( extract_answer ( text , \"When was snowflake founded?\" )) \n print ( sentiment ( \"I really enjoyed this restaurant. Fantastic service!\" )) \n print ( summarize ( text )) \n print ( translate ( text , \"en\" , \"fr\" ))\n```\nCopy\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > ... > Call Cortex AI Functions in Snowflake ML ¶ > Pass hyperparameter options ¶\nContent:\nYou can pass options that affect the model’s hyperparameters when using the `complete` function. The following\nPython example illustrates modifying the maximum number of output tokens that the model can generate:\n```\nfrom snowflake.cortex import complete , CompleteOptions \n\n model_options1 = CompleteOptions ( \n    { 'max_tokens' : 30 } \n ) \n\n print ( complete ( \"llama3.1-8b\" , \"how do snowflakes get their unique patterns?\" , options = model_options1 ))\n```\nCopy\n ... \nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Using Snowflake Cortex AI functions with Snowflake CLI ¶\nContent:\nSnowflake Cortex AI Functions are available in Snowflake CLI version 2.4.0\nand later. See Introducing Snowflake CLI for more information about using Snowflake CLI.\nThe functions are the old-style functions, those with names that don’t begin with “AI”.\nThe following examples illustrate using the `snow cortex` commands on single values. The `-c` parameter specifies which connection to use.\nNote\nThe advanced chat-style (multi-message) form of COMPLETE is not currently supported in Snowflake CLI.\n```\nsnowcortex complete \"Is 5 more than 4? Please answer using one word without a period.\" -c \"snowhouse\"\n```\nCopy\n```\nsnowcortexextract-answer \"what is snowflake?\" \"snowflake is a company\" -c \"snowhouse\"\n```\nCopy\n```\nsnowcortexsentiment \"Mary had a little Lamb\" -c \"snowhouse\"\n```\nCopy\n```\nsnowcortexsummarize \"John has a car. John's car is blue. John's car is old and John is thinking about buying a new car. There are a lot of cars to choose from and John cannot sleep because it's an important decision for John.\"\n```\nCopy\n```\nsnowcortextranslateherb--topl\n```\nCopy\nYou can also use files that contain the text you want to use for the commands. For this example, assume that the file `about_cortex.txt` contains the following content:\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Using Snowflake Cortex AI functions with Snowflake CLI ¶\nContent:\n```\nSnowflake Cortex gives you instant access to industry-leading large language models (LLMs) trained by researchers at companies like Anthropic, Mistral, Reka, Meta, and Google, including Snowflake Arctic, an open enterprise-grade model developed by Snowflake. \n\n Since these LLMs are fully hosted and managed by Snowflake, using them requires no setup. Your data stays within Snowflake, giving you the performance, scalability, and governance you expect. \n\n Snowflake Cortex features are provided as SQL functions and are also available in Python. The available functions are summarized below. \n\n COMPLETE: Given a prompt, returns a response that completes the prompt. This function accepts either a single prompt or a conversation with multiple prompts and responses. \n EMBED_TEXT_768: Given a piece of text, returns a vector embedding that represents that text. \n EXTRACT_ANSWER: Given a question and unstructured data, returns the answer to the question if it can be found in the data. \n SENTIMENT: Returns a sentiment score, from -1 to 1, representing the detected positive or negative sentiment of the given text. \n SUMMARIZE: Returns a summary of the given text. \n TRANSLATE: Translates given text from any supported language to any other.\n```\nYou can then execute the `snow cortex summarize` command by passing in the filename using the `--file` parameter, as shown:\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Using Snowflake Cortex AI functions with Snowflake CLI ¶\nContent:\n```\nsnowcortexsummarize--fileabout_cortex.txt\n```\nCopy\n```\nSnowflake Cortex offers instant access to industry-leading language models, including Snowflake Arctic, with SQL functions for completing prompts (COMPLETE), text embedding (EMBED\\_TEXT\\_768), extracting answers (EXTRACT\\_ANSWER), sentiment analysis (SENTIMENT), summarizing text (SUMMARIZE), and translating text (TRANSLATE).\n```\nFor more information about these commands, see snow cortex commands .\n ... \nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Legal notices ¶\nContent:\n| Input data classification | Output data classification | Designation |\n| Usage Data | Customer Data | Generally available functions are Covered AI Features. Preview functions are Preview AI Features. [[ 1 ]]() |\nSection Title: Snowflake Cortex AI Functions (including LLM functions) ¶ > Legal notices ¶\nContent:\n[1 ]\nRepresents the defined term used in the AI Terms and Acceptable Use Policy.\nFor additional information, refer to Snowflake AI and ML .\nWas this page helpful?\nYes No\n[Visit Snowflake](https://www.snowflake.com)\n[Join the conversation](https://community.snowflake.com/s/)\n[Develop with Snowflake](https://developers.snowflake.com)\nShare your feedback\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n[Get your own certification](https://learn.snowflake.com)\nOn this page\nAvailable functions\nCortex AI functions\nHelper functions\nCortex Guard\nPerformance considerations\nCortex LLM privileges\nUSE AI FUNCTIONS on the account privilege\nCORTEX_USER database role\nCORTEX_EMBED_USER database role\nUsing AI Functions in stored procedures with EXECUTE AS RESTRICTED CALLER\nControl model access\nAccount-level allowlist parameter\nRole-based access control (RBAC)\nCommon pitfalls\nSupported features\nRegional availability\nCreate stage for media files\nCortex AI Functions storage best practices\nCost considerations\nWarehouse sizing\nTrack costs for AI services\nTrack credit consumption for Cortex AI Functions\nModel restrictions\nChoosing a model\nLarge models\nMedium models\nSmall models\nPrevious model versions\nUsing Snowflake Cortex AI Functions with Python\nCall Cortex AI Functions in Snowpark Python\nCall Cortex AI Functions in Snowflake ML\nUsing Snowflake Cortex AI functions with Snowflake CLI\nLegal notices"],"full_content":null}],"errors":[],"warnings":null,"usage":[{"name":"sku_extract_excerpts","count":5}]}
