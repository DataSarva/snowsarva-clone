{"search_id":"search_d6630bfa797e463d9df57bf335149098","results":[{"url":"https://docs.snowflake.com/en/user-guide/ui-snowsight-tasks","title":"Viewing tasks and task graphs in Snowsight | Snowflake Documentation","excerpts":["[DOCUMENTATION](https://docs.snowflake.com)\n/\nGet started\nGuides\nDeveloper\nReference\nRelease notes\nTutorials\n[Status](https://status.snowflake.com)\nOverview\nSnowflake Horizon Catalog\nApplications and tools for connecting to Snowflake\nVirtual warehouses\nDatabases, Tables, & Views\nData types\nData Integration\nSnowflake Openflow\nApache Iceberg™\nApache Iceberg™ Tables\nSnowflake Open Catalog\nData engineering\nData loading\nDynamic Tables\nStreams and Tasks\ndbt Projects on Snowflake\nData Unloading\nStorage Lifecycle Policies\nMigrations\nQueries\nListings\nCollaboration\nSnowflake AI & ML\nAlerts & Notifications\nSecurity\nData Governance\nPrivacy\nOrganizations & Accounts\nBusiness continuity & data recovery\nPerformance optimization\nCost & Billing\nGuides Data engineering Streams and Tasks Tasks Tasks in Snowsight\nSection Title: Viewing tasks and task graphs in Snowsight ¶\nContent:\nTasks let you schedule the execution of SQL code. A task is associated with a specific database and schema. You can use\nSnowsight to view and manage your tasks and task graphs. Using Snowsight, you can also view the execution history for\ntasks and tasks graphs and retry failed tasks.\nSection Title: Viewing tasks and task graphs in Snowsight ¶ > View and manage individual tasks ¶\nContent:\nTo view and manage a task in Snowsight, perform the following steps:\nIn the navigation menu, select Catalog » Database Explorer .\nFor a specific database and schema, select Tasks and select the task you want to manage.\nWhen viewing the task in Snowsight, you can perform the following steps:\nIn the Details section, review the task ID, warehouse used by the task, schedule, state, parameters, and any conditions.\nReview the SQL statement used to create the task and any task graph configurations in the Task Definition section.\nManage privileges on the task. For information, see Manage object privileges with Snowsight .\nTo edit the task, clone the task, drop the task, or transfer ownership of the task to another role, select the … actions button.\nSection Title: Viewing tasks and task graphs in Snowsight ¶ > View and manage individual tasks ¶\nContent:\nWhen you edit a task in Snowsight, the task is automatically suspended, and then resumed when you finish editing the task. For more\ninformation about suspending and resuming tasks, see Versioning of task runs .\nSection Title: Viewing tasks and task graphs in Snowsight ¶ > View and manage task graphs ¶\nContent:\nReview a task graph to see a root task, its dependent tasks, and finalizer task in the format of a task graph. For more information about task graphs, see Create a sequence of tasks with a task graph . When you review a task graph, you can perform the following steps in Snowsight:\nView task information.\nExamine the task graph.\nSelect a task on the graph to view additional details, such as predecessor tasks, the warehouse used to run the task, and the role that\nowns the task.\nYou can also edit the root task to change parameters for the task graph. When you edit a task in Snowsight, the task is\nautomatically suspended and resumed when you finish editing the task. For more information about suspending and resuming tasks, see Versioning of task runs .\nTo view a task graph for a specific database schema, perform the following steps:\nSection Title: Viewing tasks and task graphs in Snowsight ¶ > View and manage task graphs ¶\nContent:\nIn the navigation menu, select Catalog » Database Explorer .\nUse the object explorer to locate the database and schema that contain the tasks that you want to view.\nFor the selected schema, select Tasks .\nSelect a specific task.The task details appear, with additional Graph , and Run History tabs.\nSelect the Graph tab to view the task graph.The task graph appears, displaying a hierarchy of tasks.\nSelect a task to view details in the context of the graph.\nNote\nTask history data is only available if the task has been executed in the last 7 days.\nSection Title: Viewing tasks and task graphs in Snowsight ¶ > View task history ¶\nContent:\nTo view task history, perform the following steps:\nIn the navigation menu, select Transformation » Tasks .\nFrom the Tasks page, you can see task execution history. For example:\nReview all tasks that have run in your account to help identify critical tasks that failed to run, long-running tasks, or tasks that have increasing costs.\nReview specific tasks to gather more information about the task.\nReview task graphs to observe, monitor, and help identify problems with a specific task graph.\nYou can also review task history in SQL by using a table function TASK_HISTORY or a\nview TASK_HISTORY view .\nSection Title: Viewing tasks and task graphs in Snowsight ¶ > ... > Required privileges for viewing task history ¶\nContent:\nTo view task history in Snowsight, you need the same privileges required to run the TASK_HISTORY function. That is, you must use a role that includes one of the following roles or privileges on the task:\nThe ACCOUNTADMIN role.The role with the OWNERSHIP privilege on the task (that is, the task owner).The MONITOR or OPERATE privilege on the task.The global MONITOR EXECUTION privilege.\nThe role that you use must be able to query the Account Usage TASK_HISTORY view. You can grant the USAGE_VIEWER database role in the shared SNOWFLAKE database to the role that you use.\nFor example, to view the history for a specific task `mytask` , you can grant OWNERSHIP privileges on the task and the USAGE_VIEWER database role on the shared Snowflake database by running the following SQL commands:\n```\nGRANT OWNERSHIP ON TASK mytask TO ROLE myrole ; \n GRANT DATABASE ROLE USAGE_VIEWER TO ROLE myrole ;\n```\nSection Title: Viewing tasks and task graphs in Snowsight ¶ > ... > Required privileges for viewing task history ¶\nContent:\nCopy\nFor details, see:\nACCOUNT_USAGE schema SNOWFLAKE database roles\nGRANT DATABASE ROLE\nSection Title: Viewing tasks and task graphs in Snowsight ¶ > ... > Review the run history for a task ¶\nContent:\nTask run history includes details about each execution of a given task. You\ncan view the scheduled run time, status, return value, duration of a task, and other information.\nFor each instance, you can view the following:\nScheduled run time: When the scheduled task was run.\nStatus: Status of the most recent attempt of the task run.\nDuration: Amount of time, in seconds, for the task run.\nTo view the run history:\nIn the navigation menu, select Catalog » Database Explorer .\nIn the right pane, using the object explorer, navigate to a database and schema.\nFor the selected schema, select and expand Tasks .\nSelect a task. Task information is displayed, including Task Details , Graph , and Run History sub-tabs.\nSelect the Run History tab.\nNote\nTask history data is only available if the task has been executed in the last 7 days.\nSection Title: Viewing tasks and task graphs in Snowsight ¶ > ... > Review account-level task history ¶\nContent:\nReview the account-level history for task runs to identify failing tasks, long-running tasks,\nand other monitoring and debugging cases for an entire account, rather than for one specific task.\nTo view account-level history for tasks, perform the following steps:\nIn the navigation menu, select Transformation » Tasks .\nTo view individual task runs, select View » Task Runs from the filters.\nAfter you select the history of task runs, you can filter the page to display relevant information.\nSelect the Date Range filter to show task history from the last day through the last 12 months, or a custom range.\nSelect the Task status filter to display task history for one or more status, such as Succeeded , Failed , Cancelled , or Skipped .\nFilter on the name of the task to see patterns in status or duration over time for specific tasks.\nFilter on the name of the database or schema that contain the tasks.\nSection Title: Viewing tasks and task graphs in Snowsight ¶ > ... > Review account-level task history ¶\nContent:\nFor example, to identify long-running tasks, select the Status filter to show only successful tasks,\nand sort the Duration field in descending order. For advanced debugging, you can open the filtered and sorted table in worksheets\nusing the Open in worksheets button. You could then modify the SQL statement with LIMIT / FETCH and GROUP BY arguments to identify the databases and schemas with the top 25 most long-running tasks.\nYou can also select a specific task to drill down for more details.\nSection Title: Viewing tasks and task graphs in Snowsight ¶ > View task graph history ¶ > Viewing the Tasks page ¶\nContent:\nTo identify failing tasks, long-running tasks, and other monitoring and debugging cases, review the history of your task graph runs on the Tasks page.\nNote\nWith the Tasks page, you can view the task graph runs based on your specific role privileges.\nTo view task graph runs, take the following steps:\nIn the navigation menu, select Transformation » Tasks .\nOn the Task Graphs tab, you can perform the following:\nSection Title: Viewing tasks and task graphs in Snowsight ¶ > View task graph history ¶ > Viewing the Tasks page ¶\nContent:\nHover over the Previous Runs counter to display the status of the most recent runs in chronological order.\nThe Duration Trend graph visualizes task run durations over time (based on the selected date range) by highlighting a median line within a min-max range. This can help you quickly assess whether task durations are stable, fluctuating, or trending, and identify individual outliers.\nUse the ellipsis menu to manually run the graph, edit the root task (for example, modify the schedule or parameters), or suspend/resume the graph.\nYou can filter the page to display relevant information. It is recommended to filter by database and schema to reduce load times on large accounts.\n ... \nSection Title: Viewing tasks and task graphs in Snowsight ¶ > ... > Considerations and limitations ¶\nContent:\nTo view a task graph within this function, you’ll need a role with at least one of the following privileges:The role must also have the USAGE privilege on the database and schema that store the task, otherwise the DATABASE_NAME and SCHEMA_NAME values in the output are NULL.\nOWNERSHIP privilege on the task (that is, the task owner).\nMONITOR or OPERATE privileges on the task.\nThe global MONITOR EXECUTION privilege.\nThe ACCOUNTADMIN role.\n ... \nSection Title: Viewing tasks and task graphs in Snowsight ¶ > Retry failed tasks ¶\nContent:\nAny previous failed or canceled attempts are shown next to the run status. You can select the task to see the scheduled timestamp, status, and error messages for each attempt.\nNote\nThe Retry action is disabled if any of the following is true,\nA retry is already in progress.\nThe selected run is not the most recent run.\nThe task graph has been modified after the run.\nThe run is longer than 14 days.\nThe Retry action is not available if no tasks in the graph failed or were canceled.\nWas this page helpful?\nYes No\n[Visit Snowflake](https://www.snowflake.com)\n[Join the conversation](https://community.snowflake.com/s/)\n[Develop with Snowflake](https://developers.snowflake.com)\nShare your feedback\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n[Get your own certification](https://learn.snowflake.com)\nOn this page"]},{"url":"https://docs.snowflake.com/en/developer-guide/native-apps/container-cost-governance","title":"Costs associated with apps with containers | Snowflake Documentation","excerpts":["[DOCUMENTATION](https://docs.snowflake.com)\n\n/\n\nGet started\n\nGuides\n\nDeveloper\n\nReference\n\nRelease notes\n\nTutorials\n\n[Status](https://status.snowflake.com)\n\nDeveloper Snowflake Native App Framework Costs associated with apps with containers\n\n# Costs associated with apps with containers ¶\n\n Feature — Generally Available\n\nThe Snowflake Native App Framework is generally available on supported cloud platforms. For additional information, see Support for private connectivity, VPS, and government regions .\n\nThis topic describes the costs associated with developing, publishing and using a\nSnowflake Native App with Snowpark Container Services. It contains information for both providers and consumers.\n\n## Costs to consumers ¶\n\nA Snowflake Native App may incur costs in the consumer account. The total cost of running\na Snowflake Native App with Snowpark Container Services is determined by the following:\n\n* Costs determined by the provider\n* Infrastructure costs\n\n### Costs determined by the provider ¶\n\nA provider may monetize a Snowflake Native App using any of the paid listing pricing models that are available in the Snowflake Marketplace. These models include subscription based and usage based plans.\n\nThis cost to the consumer is determined by the provider. Consumers pay for provider software via the Snowflake Marketplace in addition to costs associated with running Snowflake\ninfrastructure, including warehouses and compute pools.\n\n### Infrastructure costs ¶\n\nAll infrastructure costs, including those related to compute pools, warehouse compute, storage, and\ndata transfer are the responsibility of the consumer of a Snowflake Native App.\n\nA consumer can use the IN ACCOUNT clause of the SHOW COMPUTE POOLS command to see all compute pools in their account\nand the current state of the compute pool. Costs are not incurred when a compute pool is suspended.\n\nA Snowflake Native App with Snowpark Container Services requires at least one compute pool and might require multiple compute pools to run as\nintended. A consumer has full control over the compute resources that the app requires, and may suspend a\ncompute pool or drop an application at any time.\n\nSeparate charges for compute pool compute related to the Snowflake Native App with Snowpark Container Services appear on the customer billing\nstatement. A consumer can determine the compute pool billing charges for a Snowflake Native App with Snowpark Container Services using the ACCOUNT USAGE views provided by\nSnowpark Container Services.\n\nFor more details, such as the consumption table for compute pools, contact your account representative.\n\n## Costs to providers ¶\n\nProviders can also incur costs when developing and maintaining a Snowflake Native App with Snowpark Container Services, including the\nfollowing:\n\n* Providers incur Snowpark Container Services compute costs associated with both initial development and\n  ongoing testing and support for their Snowflake Native App. The compute cost may be controlled through\n  orchestration of compute pools during provider-side development and testing.\n* The storage of container images can incur costs when a provider creates a new version or patch of\n  a Snowflake Native App with Snowpark Container Services. In this context, the Docker images that the app requires are copied into an image\n  repository that is not directly accessible or observable by the provider or the consumer.\n  \n  Services in the consumer account are created from the versioned images that are stored in this\n  repository. Providers are responsible for the storage costs for the images in this stage, which\n  appear on their Snowflake bill. These costs are aggregated with other storage costs that their account incurs.\n\nWas this page helpful?\n\nYes No\n\n[Visit Snowflake](https://www.snowflake.com)\n\n[Join the conversation](https://community.snowflake.com/s/)\n\n[Develop with Snowflake](https://developers.snowflake.com)\n\nShare your feedback\n\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n\n[Get your own certification](https://learn.snowflake.com)\n\nOn this page\n\n1. Costs to consumers\n2. Costs to providers\n\nRelated content\n\n1. About the Snowflake Native App Framework\n\nLanguage: **English**\n\n* English\n* Français\n* Deutsch\n* 日本語\n* 한국어\n* Português\n\n## Snowflake's Use of Cookies\n\n## Privacy Preference Center\n\nYour Opt Out Preference Signal is Honored\n\n* ### Your Privacy\n* ### Strictly Necessary Cookies\n* ### Performance Cookies\n* ### Functional Cookies\n* ### Targeting Cookies\n\n#### Your Privacy\n\nWhen you visit any website, it may store or retrieve information on your browser, mostly in the form of cookies. This information might be about you, your preferences or your device and is mostly used to make the site work as you expect it to. The information does not usually directly identify you, but it can give you a more personalized web experience. Because we respect your right to privacy, you can choose not to allow some types of cookies. Click on the different category headings to find out more and change our default settings. However, blocking some types of cookies may impact your experience of the site and the services we are able to offer.  \n[More information](https://cookiepedia.co.uk/giving-consent-to-cookies)\n\n#### Strictly Necessary Cookies\n\nAlways Active\n\nThese cookies are necessary for the website to function and cannot be switched off. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.\n\nCookies Details‎\n\n#### Performance Cookies\n\nPerformance Cookies\n\nThese cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site.    All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance.\n\nCookies Details‎\n\n#### Functional Cookies\n\nFunctional Cookies\n\nThese cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages.    If you do not allow these cookies then some or all of these services may not function properly.\n\nCookies Details‎\n\n#### Targeting Cookies\n\nTargeting Cookies\n\nThese cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly identifiable personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising.\n\nCookies Details‎\n\n### Cookie List\n\nConsent Leg.Interest\n\ncheckbox label label\n\ncheckbox label label\n\ncheckbox label label\n\nClear\n\ncheckbox label label\n\nApply Cancel\n\nConfirm My Choices\n\nAllow All\n\n[](https://www.onetrust.com/products/cookie-consent/)"]},{"url":"https://docs.snowflake.com/ko/sql-reference/account-usage/warehouse_metering_history","title":"WAREHOUSE_METERING_HISTORY 뷰 | Snowflake Documentation","excerpts":["[DOCUMENTATION](https://docs.snowflake.com)\n\n/\n\n시작하기\n\n가이드\n\n개발자\n\n참조\n\n릴리스 정보\n\n자습서\n\n[상태](https://status.snowflake.com)\n\n1. 개요\n2. SQL 데이터 타입 참조\n3. SQL 명령 참조\n4. 함수 및 저장 프로시저 참조\n5. 클래스 참조\n6. Scripting 참조\n7. 일반 참조\n   \n        - 매개 변수\n        - 참조\n        - 3진 논리\n        - 데이터 정렬 지원\n        - SQL 형식 모델\n        - 오브젝트 식별자\n        - 제약 조건\n        - SQL 변수\n        - 바인드 변수\n        - 트랜잭션\n        - 테이블 리터럴\n        - SNOWFLAKE 데이터베이스\n             \n                        + Account Usage\n                               \n                        * ACCESS\\_HISTORY\n                        * AGGREGATE\\_ACCESS\\_HISTORY\n                        * AGGREGATE\\_QUERY\\_HISTORY\n                        * AGGREGATION\\_POLICIES\n                        * ALERT\\_HISTORY\n                        * ANOMALIES\\_DAILY\n                        * APPLICATION\\_DAILY\\_USAGE\\_HISTORY\n                        * APPLICATION\\_SPECIFICATION\\_STATUS\\_HISTORY\n                        * APPLICATION\\_SPECIFICATIONS\n                        * ARCHIVE\\_STORAGE\\_DATA\\_RETRIEVAL\\_USAGE\\_HISTORY\n                        * AUTOMATIC\\_CLUSTERING\\_HISTORY\n                        * BLOCK\\_STORAGE\\_HISTORY\n                        * BLOCK\\_STORAGE\\_SNAPSHOTS\n                        * CLASS\\_INSTANCES\n                        * CLASSES\n                        * COLUMNS\n                        * COLUMN\\_QUERY\\_PRUNING\\_HISTORY\n                        * COMPLETE\\_TASK\\_GRAPHS\n                        * COMPUTE\\_POOLS\n                        * CONTACT\\_REFERENCES\n                        * CONTACTS\n                        * COPY\\_FILES\\_HISTORY\n                        * COPY\\_HISTORY\n                        * CORTEX\\_ANALYST\\_USAGE\\_HISTORY\n                        * CORTEX\\_DOCUMENT\\_PROCESSING\\_USAGE\\_HISTORY\n                        * CORTEX\\_FINE\\_TUNING\\_USAGE\\_HISTORY\n                        * CORTEX\\_FUNCTIONS\\_QUERY\\_USAGE\\_HISTORY\n                        * CORTEX\\_FUNCTIONS\\_USAGE\\_HISTORY\n                        * CORTEX\\_PROVISIONED\\_THROUGHPUT\\_USAGE\\_HISTORY\n                        * CORTEX\\_SEARCH\\_DAILY\\_USAGE\\_HISTORY\n                        * CORTEX\\_SEARCH\\_SERVING\\_USAGE\\_HISTORY\n                        * CREDENTIALS\n                        * DATA\\_CLASSIFICATION\\_LATEST\n                        * DATA\\_METRIC\\_FUNCTION\\_EXPECTATIONS\n                        * DATA\\_METRIC\\_FUNCTION\\_REFERENCES\n                        * DATA\\_QUALITY\\_MONITORING\\_USAGE\\_HISTORY\n                        * DATA\\_TRANSFER\\_HISTORY\n                        * DATABASE\\_REPLICATION\\_USAGE\\_HISTORY\n                        * DATABASE\\_STORAGE\\_USAGE\\_HISTORY\n                        * DATABASES\n                        * DOCUMENT\\_AI\\_USAGE\\_HISTORY\n                        * DYNAMIC\\_TABLE\\_REFRESH\\_HISTORY\n                        * ELEMENT\\_TYPES\n                        * EVENT\\_USAGE\\_HISTORY\n                        * EXTERNAL\\_ACCESS\\_HISTORY\n                        * FEATURE\\_POLICIES\n                        * FIELDS\n                        * FILE\\_FORMATS\n                        * FUNCTIONS\n                        * GRANTS\\_TO\\_ROLES\n                        * GRANTS\\_TO\\_USERS\n                        * HYBRID\\_TABLES\n                        * HYBRID\\_TABLE\\_USAGE\\_HISTORY\n                        * ICEBERG\\_STORAGE\\_OPTIMIZATION\\_HISTORY\n                        * INDEX\\_COLUMNS\n                        * INDEXES\n                        * INGRESS\\_NETWORK\\_ACCESS\\_HISTORY\n                        * INTERNAL\\_DATA\\_TRANSFER\\_HISTORY\n                        * INTERNAL\\_STAGE\\_NETWORK\\_ACCESS\\_HISTORY\n                        * JOIN\\_POLICIES\n                        * LOAD\\_HISTORY\n                        * LOCK\\_WAIT\\_HISTORY\n                        * LOGIN\\_HISTORY\n                        * MASKING\\_POLICIES\n                        * MATERIALIZED\\_VIEW\\_REFRESH\\_HISTORY\n                        * METERING\\_DAILY\\_HISTORY\n                        * METERING\\_HISTORY\n                        * NETWORK\\_POLICIES\n                        * NETWORK\\_RULE\\_REFERENCES\n                        * NETWORK\\_RULES\n                        * NOTEBOOKS\\_CONTAINER\\_RUNTIME\\_HISTORY\n                        * OBJECT\\_ACCESS\\_REQUEST\\_HISTORY\n                        * OBJECT\\_DEPENDENCIES\n                        * OPENFLOW\\_USAGE\\_HISTORY\n                        * ONLINE\\_FEATURE\\_TABLE\\_REFRESH\\_HISTORY\n                        * OUTBOUND\\_PRIVATELINK\\_ENDPOINTS\n                        * PASSWORD\\_POLICIES\n                        * PIPE\\_USAGE\\_HISTORY\n                        * PIPES\n                        * POLICY\\_REFERENCES\n                        * PRIVACY\\_BUDGETS\n                        * PRIVACY\\_POLICIES\n                        * PROCEDURES\n                        * PROJECTION\\_POLICIES\n                        * QUERY\\_ACCELERATION\\_ELIGIBLE\n                        * QUERY\\_ACCELERATION\\_HISTORY\n                        * QUERY\\_ATTRIBUTION\\_HISTORY\n                        * QUERY\\_HISTORY\n                        * QUERY\\_INSIGHTS\n                        * REFERENTIAL\\_CONSTRAINTS\n                        * REPLICATION\\_GROUP\\_REFRESH\\_HISTORY\n                        * REPLICATION\\_GROUP\\_USAGE\\_HISTORY\n                        * REPLICATION\\_GROUPS\n                        * REPLICATION\\_USAGE\\_HISTORY\n                        * RESOURCE\\_MONITORS\n                        * ROLES\n                        * ROW\\_ACCESS\\_POLICIES\n                        * SCHEMATA\n                        * SEARCH\\_OPTIMIZATION\\_BENEFITS\n                        * SEARCH\\_OPTIMIZATION\\_HISTORY\n                        * SECRETS\n                        * SEMANTIC\\_DIMENSIONS\n                        * SEMANTIC\\_FACTS\n                        * SEMANTIC\\_METRICS\n                        * SEMANTIC\\_RELATIONSHIPS\n                        * SEMANTIC\\_TABLES\n                        * SEMANTIC\\_VIEWS\n                        * SEQUENCES\n                        * SERVERLESS\\_ALERT\\_HISTORY\n                        * SERVERLESS\\_TASK\\_HISTORY\n                        * SERVICES\n                        * SESSION\\_POLICIES\n                        * SESSIONS\n                        * SNAPSHOT\\_OPERATION\\_HISTORY\n                        * SNAPSHOT\\_POLICIES\n                        * SNAPSHOT\\_SETS\n                        * SNAPSHOT\\_STORAGE\\_USAGE\n                        * SNAPSHOTS\n                        * SNOWPARK\\_CONTAINER\\_SERVICES\\_HISTORY\n                        * SNOWPIPE\\_STREAMING\\_CHANNEL\\_HISTORY\n                        * SNOWPIPE\\_STREAMING\\_CLIENT\\_HISTORY\n                        * SNOWPIPE\\_STREAMING\\_FILE\\_MIGRATION\\_HISTORY\n                        * STAGE\\_STORAGE\\_USAGE\\_HISTORY\n                        * STAGES\n                        * STORAGE\\_LIFECYCLE\\_POLICIES\n                        * STORAGE\\_LIFECYCLE\\_POLICY\\_HISTORY\n                        * STORAGE\\_USAGE\n                        * TABLE\\_CONSTRAINTS\n                        * TABLE\\_DML\\_HISTORY\n                        * TABLE\\_PRUNING\\_HISTORY\n                        * TABLE\\_QUERY\\_PRUNING\\_HISTORY\n                        * TABLE\\_STORAGE\\_METRICS\n                        * TABLES\n                        * TAG\\_REFERENCES\n                        * TAGS\n                        * TASK\\_HISTORY\n                        * TASK\\_VERSIONS\n                        * TRUST\\_CENTER\\_FINDINGS\n                        * USERS\n                        * VIEWS\n                        * WAREHOUSE\\_EVENTS\\_HISTORY\n                        * WAREHOUSE\\_LOAD\\_HISTORY\n                        * WAREHOUSE\\_METERING\\_HISTORY\n                + 청구\n                + 데이터 공유 사용\n                + 로컬\n                + 모니터링\n                + 조직 사용\n                + 원격 분석\n                + Trust Center\n                + SNOWFLAKE 데이터베이스 역할\n                + Snowflake 클래스\n        - Snowflake Information Schema\n        - 메타데이터 필드\n        - 규칙\n        - 예약된 키워드\n8. API 참조\n\n참조 일반 참조 SNOWFLAKE 데이터베이스 Account Usage WAREHOUSE\\_METERING\\_HISTORY\n\n스키마:\n    ACCOUNT\\_USAGE , READER\\_ACCOUNT\\_USAGE\n\n# WAREHOUSE\\_METERING\\_HISTORY 뷰 ¶\n\n이 Account Usage 뷰는 지난 365일(1년) 내에서 단일 웨어하우스(또는 계정의 모든 웨어하우스)에 대한 시간당 크레딧 사용량을 반환하는 데 사용할 수 있습니다.\n\n## 열 ¶\n\n|열 이름 |데이터 타입 |설명 |\n| --- | --- | --- |\n|READER\\_ACCOUNT\\_NAME |VARCHAR |웨어하우스 사용이 발생한 독자 계정의 이름입니다. READER\\_ACCOUNT\\_USAGE 스키마의 뷰에만 포함된 열입니다. |\n|START\\_TIME |TIMESTAMP\\_LTZ |웨어하우스 사용이 발생한 날짜 및 시간 단위의 시작(현지 타임존)입니다. |\n|END\\_TIME |TIMESTAMP\\_LTZ |웨어하우스 사용이 발생한 날짜 및 시간 단위의 끝(현지 타임존)입니다. |\n|WAREHOUSE\\_ID |NUMBER |웨어하우스의 내부/시스템 생성 식별자입니다. |\n|WAREHOUSE\\_NAME |VARCHAR |웨어하우스의 이름입니다. |\n|CREDITS\\_USED |NUMBER |웨어하우스에 사용된 시간당 총 크레딧 수입니다. 이는 CREDITS\\_USED\\_COMPUTE 및 CREDITS\\_USED\\_CLOUD\\_SERVICES 의 합계입니다. 이 값은 클라우드 서비스 조정 을 고려하지 않으므로 청구되는 크레딧보다 클 수 있습니다. 실제로 청구된 크레딧 수를 확인하려면 METERING\\_DAILY\\_HISTORY 뷰 에 대해 쿼리를 실행하십시오. |\n|CREDITS\\_USED\\_COMPUTE |NUMBER |웨어하우스에 사용된 시간당 크레딧 수입니다. |\n|CREDITS\\_USED\\_CLOUD\\_SERVICES |NUMBER |클라우드 서비스에 사용된 시간당 크레딧 수입니다. |\n|CREDITS\\_ATTRIBUTED\\_COMPUTE\\_QUERIES |NUMBER |해당 시간 동안 쿼리에 특성화된 크레딧 수입니다. . . 쿼리 실행에 대한 크레딧 사용량만 포함되며 웨어하우스 유휴 시간 사용량은 포함되지 않습니다. |\n\n## 사용법 노트 ¶\n\n* ACCOUNT\\_USAGE 스키마에서 뷰의 대기 시간은 CREDITS\\_USED\\_CLOUD\\_SERVICES 열을 제외하고 최대 180분(3시간)입니다. CREDITS\\_USED\\_CLOUD\\_SERVICES 의 대기 시간 최대 6시간입니다.\n* READER\\_ACCOUNT\\_USAGE 스키마에서 뷰의 대기 시간은 최대 24시간입니다.\n* CREDITS\\_ATTRIBUTED\\_COMPUTE\\_QUERIES 열에서 웨어하우스 유휴 시간은 포함되지 않습니다.\n  \n  유휴 시간 비용을 계산하는 쿼리는 예제 를 참조하십시오.\n\n* 이 뷰의 데이터를 ORGANIZATION USAGE 스키마 의 해당 뷰와 조정하려는 경우, 먼저 세션의 시간대를 UTC로 설정해야 합니다. Account Usage 뷰를 쿼리하기 전에 다음을 실행하십시오.\n  \n  > ```\n  > ALTER SESSION SET TIMEZONE = UTC ;\n  > ```\n  > \n  > Copy\n  > \n  >\n\n## 예 ¶\n\n예를 들어, 지난 10일 동안 각 웨어하우스의 유휴 시간 비용을 계산하려면 다음 문을 실행합니다.\n\n```\nSELECT \n  ( SUM ( credits_used_compute ) - \n    SUM ( credits_attributed_compute_queries )) AS idle_cost , \n  warehouse_name \n FROM SNOWFLAKE . ACCOUNT_USAGE . WAREHOUSE_METERING_HISTORY \n WHERE start_time >= DATEADD ( 'days' , - 10 , CURRENT_DATE ()) \n  AND end_time < CURRENT_DATE () \n GROUP BY warehouse_name ;\n```\n\nCopy\n\n이 페이지가 도움이 되었습니까?\n\n예 아니요\n\n[Snowflake 방문하기](https://www.snowflake.com)\n\n[대화에 참여하기](https://community.snowflake.com/s/)\n\n[Snowflake로 개발하기](https://developers.snowflake.com)\n\n피드백 공유하기\n\n[블로그에서 최신 게시물 읽기](https://www.snowflake.com/blog/)\n\n[자체 인증 받기](https://learn.snowflake.com)\n\n이 페이지에서\n\n1. 열\n2. 사용법 노트\n3. 예\n\n언어: **한국어**\n\n* English\n* Français\n* Deutsch\n* 日本語\n* 한국어\n* Português"]},{"url":"https://docs.snowflake.com/en/user-guide/alerts","title":"Setting up alerts based on data in Snowflake | Snowflake Documentation","excerpts":["Section Title: Setting up alerts based on data in Snowflake ¶\nContent:\nThis topic explains how to set up an alert that periodically performs an action under specific conditions, based on data within\nSnowflake.\nSection Title: Setting up alerts based on data in Snowflake ¶ > Introduction ¶\nContent:\nIn some cases, you might want to be notified or take action when data in Snowflake meets certain conditions. For example, you\nmight want to receive a notification when:\nThe warehouse credit usage increases by a specified percentage of your current quota.\nThe resource consumption for your pipelines, tasks, materialized views, etc. increases beyond a specified amount.\nYour data fails to comply with a particular business rule that you have set up.\nTo do this, you can set up a Snowflake alert. A Snowflake alert is a schema-level object that specifies:\nA condition that triggers the alert (e.g. the presence of queries that take longer than a second to complete).\nThe action to perform when the condition is met (e.g. send an email notification, capture some data in a table, etc.).\nWhen and how often the condition should be evaluated (e.g. every 24 hours, every Sunday at midnight, etc.).\nSection Title: Setting up alerts based on data in Snowflake ¶ > Introduction ¶\nContent:\nFor example, suppose that you want to send an email notification when the credit consumption exceeds a certain limit for a\nwarehouse. Suppose that you want to check for this every 30 minutes. You can create an alert with the following properties:\nCondition: The credit consumption for a warehouse (the sum of the `credits_used` column in the WAREHOUSE_METERING_HISTORY view in the ACCOUNT_USAGE ) schema exceeds a specified limit.\nAction: Email the administrator.\nFrequency / schedule: Check for this condition every 30 minutes.\nSection Title: Setting up alerts based on data in Snowflake ¶ > Choosing the type of alert ¶\nContent:\nYou can create the following types of alerts:\nAlert on a schedule : Snowflake evaluates the condition against the existing data on a\nscheduled basis.For example, you can set up a alert on a schedule to check if any of the existing rows in a table has a column value that\nexceeds a specified amount.\nAlert on new data : Snowflake evaluates the condition against any new rows in a specified\ntable or a view.For example, you can set up an alert on new data to notify you when new rows for error messages are inserted into the event table for your account. Because dynamic table refreshes\nand task executions log events to the event table, you can set up an alert on new data to:\nMonitor dynamic table refreshes .\nMonitor task executions .\nSection Title: Setting up alerts based on data in Snowflake ¶ > ... > Alerts on a schedule ¶\nContent:\nWith an alert on a schedule, you can set up an alert to execute every `_n_` minutes or on a schedule specified by a cron\nexpression.\nThe condition of the alert is evaluated on all of the data (as opposed to alerts on new data, where conditions are evaluated\nagainst only the new rows that have been inserted).\n ... \nSection Title: ... > Using the serverless compute model (serverless alerts) ¶\nContent:\nAlerts that use the serverless compute model called *serverless alerts* . If you use the serverless compute model, Snowflake\nautomatically resizes and scales the compute resources required for the alert. Snowflake determines the ideal size of the compute\nresources for a given run based on a dynamic analysis of statistics for the most recent previous runs of the same alert. The\nmaximum size for a serverless alert run is equivalent to an XXLARGE warehouse. Multiple workloads in your account share a common\nset of compute resources.\nBilling is similar to other serverless features (such as serverless tasks). See Understanding the costs of alerts .\nNote\nIf you are creating an alert on new data that is added infrequently, consider\nconfiguring this as a serverless alert. If you configure the alert to use a warehouse instead, even a simple action that sends\nan email notification incurs at least one minute of warehouse cost.\n ... \nSection Title: Setting up alerts based on data in Snowflake ¶ > Understanding the costs of alerts ¶\nContent:\nThe costs associated with running an alert to execute SQL code differ depending on the compute resources used for the alert:\nSection Title: Setting up alerts based on data in Snowflake ¶ > Understanding the costs of alerts ¶\nContent:\nFor serverless alerts, Snowflake bills your account based on compute resource usage. Charges are calculated based on your\ntotal usage of the resources, including cloud service usage, measured in *compute-hours* credit usage. The compute-hours cost\nchanges based on warehouse size and query runtime. For more information, see Serverless credit usage .To learn how many credits are consumed by alerts, refer to the “Serverless Feature Credit Table” in\nthe [Snowflake Service Consumption Table](https://www.snowflake.com/legal-files/CreditConsumptionTable.pdf) .To view the usage history of serverless alerts, you can:\nCall the SERVERLESS_ALERT_HISTORY function. Query the SERVERLESS_ALERT_HISTORY view . For alerts that use a virtual warehouse that you specify, Snowflake bills your account for credit usage based on the warehouse usage when an alert is running.\nSection Title: Setting up alerts based on data in Snowflake ¶ > Understanding the costs of alerts ¶\nContent:\nThis is\nsimilar to the warehouse usage for executing the same SQL statements in a client or Snowsight. Per-second credit\nbilling and warehouse auto-suspend give you the flexibility to start with larger warehouse sizes and then adjust the size to\nmatch your alert workloads.\nSection Title: Setting up alerts based on data in Snowflake ¶ > Understanding the costs of alerts ¶\nContent:\nTip\nIf you want to set up an alert that evaluates new rows added to a table or view, use an alert on new data , rather than an alert on a schedule. An alert on a schedule will\nexecute at a scheduled time, regardless of whether or not new rows have been inserted.\n ... \nSection Title: Setting up alerts based on data in Snowflake ¶ > ... > Creating an alert on new data ¶\nContent:\nFind the name of the active event table for your account:Copy\nEnable change tracking on the table or view that you plan to query in the alert\ncondition.Copy\nSet up a notification integration for sending email . Verify that you are using a role that has the privileges to create an alert .If you are not using that role, execute the USE ROLE command to use that role. Verify that you are using database and schema in which you plan to create the alert.If you are not using that database and schema, execute the USE DATABASE and USE SCHEMA commands to use that database and schema. Execute the CREATE ALERT command to create the alert, and omit the SCHEDULE parameter.For example, the following example creates an alert on new data that monitors the event table for errors in dynamic table\nrefreshes and sends a notification to a Slack channel.\n ... \nSection Title: Setting up alerts based on data in Snowflake ¶ > Specifying timestamps based on alert schedules ¶\nContent:\nIn some cases, you might need to define a condition or action based on the alert schedule.\nFor example, suppose that a table has a timestamp column that represents when a row was added, and you want to send an alert\nif any new rows were added between the last alert that was successfully evaluated and the current scheduled alert. In other\nwords, you want to evaluate:\n```\n<now> - <last_execution_of_the_alert>\n```\nCopy\nIf you use CURRENT_TIMESTAMP and the scheduled time of the alert to calculate this range of\ntime, the calculated range does not account for latency between the time that the alert is scheduled and the time when the\nalert condition is actually evaluated.\nInstead, when you need the timestamps of the current schedule alert and the last alert that was successfully evaluated, use the\nfollowing functions:\nSection Title: Setting up alerts based on data in Snowflake ¶ > Specifying timestamps based on alert schedules ¶\nContent:\nSCHEDULED_TIME returns the timestamp representing when the current alert was scheduled.\nLAST_SUCCESSFUL_SCHEDULED_TIME returns the timestamp representing when the last successfully\nevaluated alert was scheduled.\nThese functions are defined in the SNOWFLAKE.ALERT schema . To call these functions, you need\nto use a role that has been granted the SNOWFLAKE.ALERT_VIEWER database role . To\ngrant this role to another role, use the GRANT DATABASE ROLE command. For example, to grant this role\nto the custom role `alert_role` , execute:\n```\nGRANT DATABASE ROLE SNOWFLAKE . ALERT_VIEWER TO ROLE alert_role ;\n```\nCopy\nThe following example sends an email message if any new rows were added to `my_table` between the time that the last\nsuccessfully evaluated alert was scheduled and the time when the current alert has been scheduled:\nSection Title: Setting up alerts based on data in Snowflake ¶ > Specifying timestamps based on alert schedules ¶\nContent:\n```\nCREATE OR REPLACE ALERT alert_new_rows \n  WAREHOUSE = my_warehouse \n  SCHEDULE = '1 MINUTE' \n  IF ( EXISTS ( \n      SELECT * \n      FROM my_table \n      WHERE row_timestamp BETWEEN SNOWFLAKE.ALERT.LAST_SUCCESSFUL_SCHEDULED_TIME () \n       AND SNOWFLAKE.ALERT.SCHEDULED_TIME () \n  )) \n  THEN CALL SYSTEM$SEND_EMAIL (...);\n```\nCopy\n ... \nSection Title: Setting up alerts based on data in Snowflake ¶ > Viewing details about an alert ¶\nContent:\nTo list the alerts that have been created in an account, database, or schema, execute the SHOW ALERTS command. For example, to list the alerts that were created in the current schema, run the following command:\n```\nSHOW ALERTS ;\n```\nCopy\nThis command lists the alerts that you own and the alerts that you have the MONITOR or OPERATE privilege on.\nTo view the details about a specific alert, execute the DESCRIBE ALERT command. For example:\n```\nDESC ALERT my_alert ;\n```\nCopy\nNote\nIf you are not the owner of the alert, you must have the MONITOR or OPERATE privilege on the alert to view the details of the\nalert.\n ... \nSection Title: Setting up alerts based on data in Snowflake ¶ > Monitoring the execution of alerts ¶\nContent:\nTo monitor the execution of the alerts, you can:\nCheck the results of the action that was specified for the alert. For example, if the action inserted rows into a table, you can\ncheck the table for new rows.\nView the history of alert executions by using one of the following:\nThe ALERT_HISTORY table function in the INFORMATION_SCHEMA schema.For example, to view the executions of alerts over the past hour, execute the following statement:Copy\nThe ALERT_HISTORY view in the ACCOUNT_USAGE schema in the shared\nSNOWFLAKE database.\nIn the query history, the name of the user who executed the query will be SYSTEM. (The alerts are run by the system service .)\nSection Title: Setting up alerts based on data in Snowflake ¶ > Viewing the query history of a serverless alert ¶\nContent:\nTo view the query history of a serverless alert, you must be the owner of the alert, or you must use a role that has the\nMONITOR or OPERATE privilege on the alert itself. (This differs from alerts that use one your warehouses, which require the\nMONITOR or OPERATOR privilege on the warehouse.)\nFor example, suppose that you want to use the `my_alert_role` role when viewing the query history of the alert `my_alert` .\nIf `my_alert_role` is not the owner of `my_alert` , you must grant that role the\nMONITOR or OPERATE privilege on the alert:\n```\nGRANT MONITOR ON ALERT my_alert TO ROLE my_alert_role ;\n```\nCopy\nAfter the role is granted this privilege, you can use the role to view the query history of the alert:\n```\nUSE ROLE my_alert_role ;\n```\nCopy"]},{"url":"https://docs.snowflake.com/en/user-guide/cost-controlling","title":"Controlling cost - Snowflake Documentation","excerpts":["[DOCUMENTATION](https://docs.snowflake.com)\n\n/\n\nGet started\n\nGuides\n\nDeveloper\n\nReference\n\nRelease notes\n\nTutorials\n\n[Status](https://status.snowflake.com)\n\nGuides Cost & Billing Control\n\n# Controlling cost ¶\n\nYou can use budgets to control credit usage for compute costs, including those incurred by serverless features. If you are only concerned\nwith controlling the costs of warehouses, you can also use resource monitors to monitor and suspend warehouses. In addition, Snowflake\nprovides cost controls you can configure to help avoid unexpected costs.\n\n## Use budgets to control credit usage ¶\n\nA _budget_ allows you to set a monthly spending limit and monitor the credit usage of all supported objects and serverless features in your account. In addition to your account budget,\nyou can create custom budgets to monitor credit usage of groups of specified objects and the serverless features used by those objects.\nFor example, you can create a custom budget for each department in your organization. Each budget sends a notification if the\ncredit usage is expected to exceed its spending limit for the month. You can configure the budget to send this notification to a\nlist of email addresses, a queue provided by a cloud service (Amazon SNS, Azure Event Grid, or Google Cloud PubSub), or a webhook\nfor a third-party system (for example, Slack, Microsoft Teams, or PagerDuty).\n\nFor information about budgets, see Monitor credit usage with budgets .\n\n## Use resource monitors to control credit usage ¶\n\nA _resource monitor_ lets you monitor credit usage by user-managed virtual warehouses. You can set a spending limit that resets on a\nmonthly basis or on a custom schedule. A resource monitor can\nsend an email notification when your credit usage reaches a percentage (threshold) of the spending limit. You can customize up to five\nnotification thresholds. To help avoid unexpected credit usage, you can optionally suspend a warehouse when its credit usage reaches\na threshold.\n\nFor background information about how virtual warehouses incur costs, see Understanding compute cost .\n\nFor information about resource monitors, see Working with resource monitors .\n\n## Cost controls for warehouses ¶\n\nFor a set of best practices that act as cost controls for virtual warehouses, see Cost controls for warehouses .\n\nWas this page helpful?\n\nYes No\n\n[Visit Snowflake](https://www.snowflake.com)\n\n[Join the conversation](https://community.snowflake.com/s/)\n\n[Develop with Snowflake](https://developers.snowflake.com)\n\nShare your feedback\n\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n\n[Get your own certification](https://learn.snowflake.com)\n\nOn this page\n\n1. Use budgets to control credit usage\n2. Use resource monitors to control credit usage\n3. Cost controls for warehouses\n\nRelated content\n\n1. Managing cost in Snowflake\n\nLanguage: **English**\n\n* English\n* Français\n* Deutsch\n* 日本語\n* 한국어\n* Português"]},{"url":"https://docs.snowflake.com/en/sql-reference/account-usage/warehouse_metering_history","title":"WAREHOUSE_METERING_HISTORY view | Snowflake Documentation","excerpts":["[DOCUMENTATION](https://docs.snowflake.com)\n/\nGet started\nGuides\nDeveloper\nReference\nRelease notes\nTutorials\n[Status](https://status.snowflake.com)\nReference General reference SNOWFLAKE database Account Usage WAREHOUSE_METERING_HISTORY\nSchemas:\nACCOUNT_USAGE , READER_ACCOUNT_USAGE\nSection Title: WAREHOUSE_ METERING_ HISTORY view ¶\nContent:\nThis Account Usage view can be used to return the hourly credit usage for a single warehouse (or all the warehouses in your account) within the last 365 days (1 year).\nSection Title: WAREHOUSE_ METERING_ HISTORY view ¶ > Columns ¶\nContent:\n| Column Name | Data Type | Description |\n| READER_ACCOUNT_NAME | VARCHAR | Name of the reader account where the warehouse usage took place. Column only included in view in READER_ACCOUNT_USAGE schema. |\n| START_TIME | TIMESTAMP_LTZ | The date and beginning of the hour (in the local time zone) in which the warehouse usage took place. |\n| END_TIME | TIMESTAMP_LTZ | The date and end of the hour (in the local time zone) in which the warehouse usage took place. |\n| WAREHOUSE_ID | NUMBER | Internal/system-generated identifier for the warehouse. |\n| WAREHOUSE_NAME | VARCHAR | Name of the warehouse. |\n ... \nSection Title: WAREHOUSE_ METERING_ HISTORY view ¶ > Usage notes ¶\nContent:\nIn the ACCOUNT_USAGE schema, latency for the view is up to 180 minutes (3 hours), except for the CREDITS_USED_CLOUD_SERVICES column. Latency for\nCREDITS_USED_CLOUD_SERVICES is up to 6 hours.\nIn the READER_ACCOUNT_USAGE schema, latency for the view is up to 24 hours.\nWarehouse idle time is not included in the CREDITS_ATTRIBUTED_COMPUTE_QUERIES column.See Examples for a query that calculates the cost of idle time.\nIf you want to reconcile the data in this view with a corresponding view in the ORGANIZATION USAGE schema , you must first set the timezone of the session to UTC. Before querying the Account Usage view, execute:Copy\nSection Title: WAREHOUSE_ METERING_ HISTORY view ¶ > Examples ¶\nContent:\nFor example, to determine the cost of idle time for each warehouse for the last 10 days, execute the following statement:\n```\nSELECT \n  ( SUM ( credits_used_compute ) - \n    SUM ( credits_attributed_compute_queries )) AS idle_cost , \n  warehouse_name \n FROM SNOWFLAKE . ACCOUNT_USAGE . WAREHOUSE_METERING_HISTORY \n WHERE start_time >= DATEADD ( 'days' , - 10 , CURRENT_DATE ()) \n  AND end_time < CURRENT_DATE () \n GROUP BY warehouse_name ;\n```\nCopy\nWas this page helpful?\nYes No\n[Visit Snowflake](https://www.snowflake.com)\n[Join the conversation](https://community.snowflake.com/s/)\n[Develop with Snowflake](https://developers.snowflake.com)\nShare your feedback\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n[Get your own certification](https://learn.snowflake.com)\nOn this page\nColumns\nUsage notes\nExamples\nLanguage: **English**\nEnglish\nFrançais\nDeutsch\n日本語\n한국어\nPortuguês\n ... \nSection Title: WAREHOUSE_ METERING_ HISTORY view ¶ > ... > Your Privacy > Strictly Necessary Cookies\nContent:\nAlways Active\nThese cookies are necessary for the website to function and cannot be switched off. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.\nCookies Details‎\nSection Title: WAREHOUSE_ METERING_ HISTORY view ¶ > Privacy Preference Center > Your Privacy > Performance Cookies\nContent:\nPerformance Cookies\nThese cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site.    All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance.\nCookies Details‎"]},{"url":"https://www.rst.software/blog/snowflake-cost-monitoring","title":"Snowflake cost monitoring: how to avoid skyrocketing bills? | RST Software","publish_date":"2024-06-20","excerpts":["Section Title: Expertise > Location-based Services\nContent:\nWant to build an app based on maps or optimize your current solution?\nMobility (MaaS) Development Logistics Software Development GIS Services Geospatial Mapping Spatial Data Visualization OpenStreetMap Consulting Mapbox Consulting\nSection Title: Expertise > Location-based Services > Chat app development\nContent:\nWant to build scalable chat and messaging apps?\nChat App Development\nSection Title: Expertise > Location-based Services > Chat app development > Video streaming app development\nContent:\nWant to build scalable video streaming apps or systems?\nVideo Streaming Development\nCase Studies Resources Blog About Us Career Contact Us\nEstimate my project\nMagdalena Jackiewicz\nEditorial Expert\nReviewed by a tech expert\nSection Title: ... > Snowflake cost monitoring: how to avoid skyrocketing bills?\nContent:\n\\\n\\\n\\\n\\\nRead this articles in:\nEN PL\nTable of contents\nExample H2\nThe [Snowflake Data Cloud](https://www.rst.software/blog/snowflake-data-platform-what-is-it-how-much-does-it-cost-and-how-to-get-started) is a robust platform that empowers businesses to extract greater value from their data. However, if businesses do not diligently monitor their usage costs, the overall expense of this leading data cloud solution can escalate rapidly. Fortunately, there are a number of Snowflake cost monitoring mechanisms you can implement to avoid this grim scenario.\nIn this blog post, I will help you understand the Snowflake pricing model, establish an effective budgeting strategy, explore the creation of resource monitors, and leverage Snowflake's alert system to ensure that your utilization of the platform remains efficient and cost-effective.\n ... \nSection Title: Snowflake cost monitoring: how to avoid skyrocketing bills? > ... > Alerts\nContent:\nAlerts in Snowflake are a relatively recent feature that allow users to receive notifications when data in a table changes. This can be particularly useful for Snowflake cost management, as alerts can be set up to monitor data, enabling a more granular level of resource monitoring.\nFor instance, an alert can be configured to notify administrators when a warehouse's size has been modified. In Snowflake, each doubling of a warehouse's size corresponds to a doubling of the credits consumed. Therefore, being alerted to potentially unauthorized changes in warehouse size can be critical for maintaining cost control.\nSection Title: Snowflake cost monitoring: how to avoid skyrocketing bills? > ... > Alerts\nContent:\nUsing Alerts for Snowflake cost monitoring involves setting up relevant thresholds based on your budget and usage patterns, and then configuring the relevant alerts accordingly directly in Snowflake. You can choose to receive these alerts via email, PagerDuty, Slack, or any other communication channel that keeps your relevant stakeholders informed.\nTo make the most of these cost alerts, customize the notification content to include information such as the current cost, the cost threshold, and the specific resource (account, warehouse, or database) that triggered the alert."]},{"url":"https://docs.snowflake.com/en/user-guide/tasks-intro","title":"Introduction to tasks | Snowflake Documentation","excerpts":["Section Title: Introduction to tasks ¶ > Task creation workflow overview ¶\nContent:\nCreate a task administrator role that can run the commands in the following steps.\nDefine a new task using CREATE TASK .\nDefine compute resources\nDefine schedules or triggers\nDefine what happens when a task fails\nDefine additional session parameters\nManually test tasks using EXECUTE TASK .\nAllow the task to run continuously using ALTER TASK … RESUME .\nMonitor task costs\nRefine the task as needed using ALTER TASK .\nFor information about running tasks, see:\nVersioning of task runsViewing the task history for your accountTask costs\n ... \nSection Title: Introduction to tasks ¶ > Task costs ¶\nContent:\nSnowflake analyzes task runs in the task history to dynamically determine the correct size and number of the serverless compute\nresources. As Snowflake automatically scales up and down resources to manage your task runs, the cost to run the task runs scales\nproportionally.\nTo learn how many credits are consumed by tasks, refer to the “Serverless\nFeature Credit Table” in the [Snowflake Service Consumption Table](https://www.snowflake.com/legal-files/CreditConsumptionTable.pdf) .\nConsider the following best practices to optimize for cost when you create tasks:\nSet the SCHEDULE to run less frequently.\nUse the auto-suspend and auto-retry parameters to prevent resource waste on failing tasks.\nSet up Triggered tasks for tasks that only need to run under certain conditions, such as when a data stream has new data.\nCreate a budget and alert on spend limits for serverless features. For more information, see Monitor credit usage with budgets .\n ... \nSection Title: Introduction to tasks ¶ > Task costs ¶\nContent:\n```\nSELECT start_time , \n  end_time , \n  task_id , \n  task_name , \n  credits_used , \n  schema_id , \n  schema_name , \n  database_id , \n  database_name \n FROM snowflake . account_usage . serverless_task_history \n ORDER BY start_time , task_id ;\n```\nCopy\nSection Title: Introduction to tasks ¶ > Monitoring cost ¶\nContent:\nServerless tasks incur compute cost when in use.\nYou can use cost-related views in the ACCOUNT_USAGE and ORGANIZATION_USAGE schemas to track the costs associated with serverless tasks.\nWhen querying these views, filter on the `service_type` column to find `SERVERLESS_TASK` or `SERVERLESS_TASK_FLEX` values.\nSection Title: Introduction to tasks ¶ > Monitoring cost ¶\nContent:\n| View | Schema | `service_type` | Roles with required privileges |\n| METERING_HISTORY | ACCOUNT_USAGE | SERVERLESS_TASK | ACCOUNTADMIN role |\n| USAGE_VIEWER database role |  |  |  |\n| METERING_DAILY_HISTORY | ACCOUNT_USAGE | SERVERLESS_TASK | ACCOUNTADMIN role |\n| USAGE_VIEWER database role |  |  |  |\n| METERING_DAILY_HISTORY | ORGANIZATION_USAGE | SERVERLESS_TASK | ACCOUNTADMIN role |\n| USAGE_VIEWER database role |  |  |  |\n| USAGE_IN_CURRENCY_DAILY | ORGANIZATION_USAGE | SERVERLESS_TASK | ORGADMIN role |\n| GLOBALORGADMIN role |  |  |  |\n| ORGANIZATION_USAGE_VIEWER database role |  |  |  |\nSection Title: Introduction to tasks ¶ > Monitoring cost ¶\nContent:\n**Example:** View the total account cost that serverless tasks incurred across the organization.\nExample: View the total account cost that serverless task incurred between December 1, 2024 and December 31, 2024.\n```\nSELECT \n name , \n SUM ( credits_used_compute ) AS total_credits \n FROM \n  SNOWFLAKE . ACCOUNT_USAGE . METERING_HISTORY \n WHERE \n service_type ILIKE '%SERVERLESS_TASK%' \n AND start_time >= '2024-12-01' \n AND end_time <= '2024-12-31' \n GROUP BY \n name \n ORDER BY \n name ASC ;\n```\nCopy\n**Example:** View the total account cost that serverless tasks incurred across the organization.\n```\nSELECT \n  usage_date AS date , \n  account_name , \n  SUM ( usage ) AS credits , \n  currency , \n  SUM ( usage_in_currency ) AS usage_in_currency \n FROM \n  SNOWFLAKE . ORGANIZATION_USAGE . USAGE_IN_CURRENCY_DAILY \n WHERE \n  USAGE_TYPE ILIKE '%SERVERLESS_TASK%' \n GROUP BY \n  usage_date , account_name , currency \n ORDER BY \n  USAGE_DATE DESC ;\n```\nCopy"]},{"url":"https://saurabhsahus.medium.com/production-ready-snowflake-cost-alerts-using-sql-and-slack-webhooks-10292606c7ad","title":"Production-Ready Snowflake Cost Alerts Using SQL and Slack ...","publish_date":"2025-12-30","excerpts":["A SQL-only, Snowflake-native approach to cost monitoring, weekly reporting, and FinOps alerting with a step-by-step guide to sending ..."]},{"url":"https://docs.snowflake.com/ko/sql-reference/account-usage","title":"Account Usage - Snowflake Documentation","excerpts":["Section Title: Account Usage ¶\nContent:\nSNOWFLAKE 데이터베이스에서 ACCOUNT_USAGE 및 READER_ACCOUNT_USAGE 스키마를 사용하면 계정, 그리고 계정과 연결된 모든 독자 계정(있는 경우)에 대한 오브젝트 메타데이터와 과거 사용 데이터를 쿼리하는 것이 가능합니다.\n**이 항목의 내용:**\nAccount Usage 스키마 개요\nAccount Usage와 Information Schema의 차이점\n삭제된 오브젝트 레코드\n데이터 대기 시간\n과거 데이터 보존\nACCOUNT_USAGE 뷰\nAccount Usage 테이블 함수\nREADER_ACCOUNT_USAGE 뷰\nSNOWFLAKE 데이터베이스의 스키마를 사용할 다른 역할 활성화\nACCOUNT_USAGE 스키마 SNOWFLAKE 데이터베이스 역할\nACCOUNT_USAGE 뷰에 액세스하는 데 필요한 데이터베이스 역할\nREADER_ACCOUNT_USAGE 스키마 SNOWFLAKE 데이터베이스 역할\nAccount Usage 뷰 쿼리\n열 선택하기\n비용 뷰 조정\n예\n ... \nSection Title: Account Usage ¶ > ACCOUNT_USAGE 뷰 ¶\nContent:\nACCOUNT_USAGE 스키마에는 다음과 같은 뷰가 있습니다.\n ... \nSection Title: Account Usage ¶ > ACCOUNT_USAGE 뷰 ¶\nContent:\n| 뷰 | 타입 | 대기 시간 [1] | 에디션 [3] | 참고 |\n| ACCESS_HISTORY | 과거 | 3시간 | Enterprise Edition 이상 필요 | 데이터는 1년간 보존됩니다. |\n| AGGREGATE_ACCESS_HISTORY | 과거 | 3시간 | Enterprise Edition 이상 필요 | 데이터는 1년간 보존됩니다. |\n| AGGREGATE_QUERY_HISTORY | 과거 | 3시간 |  |  |\n| AGGREGATION_POLICIES | 오브젝트 | 2시간 |  |  |\n| TABLE_QUERY_PRUNING_HISTORY | 과거 | 4시간 |  | 데이터는 1년간 보존됩니다. |\n| TABLE_STORAGE_METRICS | 오브젝트 | 90분 |  |  |\n| TAG_REFERENCES | 오브젝트 | 2시간 |  |  |\n| TAGS | 오브젝트 | 2시간 |  |  |\n| TASK_HISTORY | 과거 | 45분 |  |  |\n| TASK_VERSIONS | 오브젝트 | 3시간 |  |  |\n| USERS | 오브젝트 | 2시간 |  |  |\n| VIEWS | 오브젝트 | 90분 |  |  |\n| WAREHOUSE_EVENTS_HISTORY | 과거 | 3시간 |  | 데이터는 1년간 보존됩니다. |\n| WAREHOUSE_LOAD_HISTORY | 과거 | 3시간 |  | 데이터는 1년간 보존됩니다. |\n| WAREHOUSE_METERING_HISTORY | 과거 | 3시간 |  | 데이터는 1년간 보존됩니다. |\n ... \nSection Title: Account Usage ¶ > ACCOUNT_USAGE 뷰 ¶ > Account Usage 테이블 함수 ¶\nContent:\n현재, Snowflake는 다음 한 가지 ACCOUNT_USAGE 테이블 함수를 지원합니다.\n ... \nSection Title: Account Usage ¶ > READER_ACCOUNT_USAGE 뷰 ¶\nContent:\n| 뷰 | 타입 | 대기 시간 [1] | 참고 |\n| LOGIN_HISTORY | 과거 | 2시간 | 데이터는 1년간 보존됩니다. |\n| QUERY_HISTORY | 과거 | 45분 | 데이터는 1년간 보존됩니다. |\n| RESOURCE_MONITORS | 오브젝트 | 2시간 |  |\n| STORAGE_USAGE | 과거 | 24시간 | 모든 데이터베이스 테이블과 내부 스테이지에 걸친 총 사용량입니다. 데이터는 1년간 보존됩니다. |\n| WAREHOUSE_METERING_HISTORY | 과거 | 24시간 | 데이터는 1년간 보존됩니다. |\n ... \nSection Title: Account Usage ¶ > SNOWFLAKE 데이터베이스의 스키마를 사용할 다른 역할 활성화 ¶ > ACCOUNT_USAGE 뷰에 액세스하는 데 필요한 데이터베이스 역할 ¶\nContent:\n| 뷰 | 데이터베이스 역할 |\n| ACCESS_HISTORY 뷰 | GOVERNANCE_VIEWER |\n| AGGREGATE_ACCESS_HISTORY 뷰 | GOVERNANCE_VIEWER |\n| AGGREGATE_QUERY_HISTORY 뷰 | GOVERNANCE_VIEWER |\n| AGGREGATION_POLICIES 뷰 | GOVERNANCE_VIEWER |\n| WAREHOUSE_METERING_HISTORY 뷰 | USAGE_VIEWER |\n ... \nSection Title: Account Usage ¶ > ... > READER_ACCOUNT_USAGE 스키마 SNOWFLAKE 데이터베이스 역할 ¶\nContent:\n| 뷰 |\n| LOGIN_HISTORY 뷰 |\n| QUERY_HISTORY 뷰 |\n| RESOURCE_MONITORS 뷰 |\n| STORAGE_USAGE 뷰 |\n| WAREHOUSE_METERING_HISTORY 뷰 |\n ... \nSection Title: Account Usage ¶ > Account Usage 뷰 쿼리 ¶ > 비용 뷰 조정 ¶\nContent:\n컴퓨팅 리소스, 저장소 및 데이터 전송 비용과 관련된 데이터가 포함된 Account Usage 뷰가 여러 개 있습니다. ORGANIZATION_USAGE 스키마 의 해당 뷰에 대해 이러한 뷰를 조정하려는 경우, 먼저 세션의 시간대를 UTC로 설정해야 합니다.\n예를 들어 ORGANIZATION_USAGE.WAREHOUSE_METERING_HISTORY에서 계정의 데이터에 맞춰 ACCOUNT_USAGE.WAREHOUSE_METERING_HISTORY를 조정하려는 경우 다음 명령을 실행한 후 Account Usage 뷰를 쿼리해야 합니다.\n```\nALTER SESSION SET TIMEZONE = UTC ;\n```\nCopy\nSection Title: Account Usage ¶ > Account Usage 뷰 쿼리 ¶ > 예 ¶\nContent:\n다음 예제에서는 ACCOUNT_USAGE 스키마의 뷰를 사용하는 몇 가지 전형적이고 유용한 쿼리를 보여줍니다.\n참고\n이러한 예에서는 SNOWFLAKE 데이터베이스와 ACCOUNT_USAGE 스키마가 현재 세션에 사용 중인 것으로 가정합니다. 또한, 이들 예에서는 ACCOUNTADMIN 역할(또는 데이터베이스에서 IMPORTED PRIVILEGES가 부여된 역할)이 사용 중이라고 간주합니다. 이들이 사용 중이지 않는 경우에는 다음 명령을 실행한 후에 예제의 쿼리를 실행하십시오.Copy"]}],"usage":[{"name":"sku_search","count":1}]}