{"extract_id":"extract_8ead56f0477649c9a575827ce275212e","results":[{"url":"https://docs.snowflake.com/en/developer-guide/native-apps/event-manage-provider","title":"Set up and manage an event table in the provider account | Snowflake Documentation","publish_date":"2026-01-01","excerpts":["Developer Snowflake Native App Framework Configure logging and event tracing for an app Set up and manage event sharing in the provider organization\nSection Title: Set up and manage an event table in the provider account ¶\nContent:\nFeature — Generally Available\nThe Snowflake Native App Framework is generally available on supported cloud platforms. For additional information, see Support for private connectivity, VPS, and government regions .\nThis topic describes how providers can set up an event table and manage event sharing for an app.\nSection Title: ... > Set up an event table in the provider organization in every region ¶\nContent:\nTo collect the log messages and trace events that a consumer shares, a provider must set up an event\ntable by performing the following:\nSet an account as the event account .\nCreate an event table in the event account .\nSet the event table as the active event table in event account .\nImportant\nIf a provider does not have an event account and active event table withing the region where the app is installed\nbefore the consumer installs an app, trace events and log messages are discarded.\nSection Title: ... > Set an account as the events account ¶\nContent:\nTo store shared logs and events, a provider must select an account to hold an event table. This can be any\naccount that a provider can access. However, if an organization has multiple providers publishing\napplication packages, consider using a Snowflake account that is dedicated to storing shared events from the\nconsumer.\nThe following restrictions apply to accounts used to store shared events:\nYou must use an organization administrator role to set an account as the account used\nto store events.\nThe account must have an active event table.\nThe specified account cannot be any of the following:\nA locked or suspended account.\nA reader account.\nA trial account.\nA Snowflake managed account.\nNote\nA provider can collect logs and shared events only in the same region where a consumer installs an app.\nProviders must set up an event account to store shared events in every region where consumers configure event\nsharing for an app.\nSection Title: ... > Set an account as the events account ¶\nContent:\nTo set an account to be the events account for a region, call the SYSTEM$SET_EVENT_SHARING_ACCOUNT_FOR_REGION system function as shown in the following example:\n```\nSELECT SYSTEM$SET_EVENT_SHARING_ACCOUNT_FOR_REGION ( '<snowflake_region>' , '<region_group>' , '<account_name>' )\n```\nCopy\nWhere:\n`_snowflake_region_`\nSpecifies the region where the account is located, for example: `AWS_US_WEST_2, AWS_US_EAST_1` . `_region_group_`\nSpecifies the region group, for example: `PUBLIC` . Refer to Region groups for details. `_account_name_`\nSpecifies the account name. If another account is already set as the events account in the\nspecified region, running this command changes the events account to be the account\nspecified here.\nSection Title: ... > Create an event table in the event account ¶\nContent:\nTo create an event table, run the CREATE EVENT TABLE command as shown in the\nfollowing example:\n```\nCREATE EVENT TABLE event_db . event_schema . my_event_table ;\n```\nCopy\nThis command specifies the database and schema that contain the event table.\nSection Title: ... > Set the event table as the active event table ¶\nContent:\nAn account can have multiple event tables, but only one can be set as the active event table in a\nSnowflake account at a time. Without an active event table, log messages and trace events that the consumer\nshares are discarded.\nAfter creating the event table, use ALTER ACCOUNT … SET EVENT_TABLE to specify that the event table is the active table for the account:\n```\nALTER ACCOUNT SET EVENT_TABLE = event_db . event_schema . my_event_table ;\n```\nCopy\nSection Title: ... > Unset an account as the events account ¶\nContent:\nTo unset an account to be the events account for a region, call the SYSTEM$UNSET_EVENT_SHARING_ACCOUNT_FOR_REGION system function:\n```\nSELECT SYSTEM$UNSET_EVENT_SHARING_ACCOUNT_FOR_REGION ( '<snowflake_region>' , '<region_group>' , '<account_name>' )\n```\nCopy\nWhere:\n`_snowflake_region_`\nSpecifies the region where the account is located, for example: `AWS_US_WEST_2` . `_region_group_`\nSpecifies the region group, for example: `PUBLIC` . `_account_name_`\nSpecifies the account name.\nSection Title: ... > View the event accounts in an organization ¶\nContent:\nTo show events accounts in a provider’s organization, call the SYSTEM$SHOW_EVENT_SHARING_ACCOUNTS system function:\n```\nSELECT SYSTEM$SHOW_EVENT_SHARING_ACCOUNTS ()\n```\nCopy\nNote\nYou must use an organization administrator role to call this function.\nThis system function returns a string in JSON format containing a list of event accounts within the organization.\nBecause the metadata takes some time to propagate to all regions, this function might have a short delay before\nshowing the most current events account after the user sets or unsets the event account for the organization.\nSection Title: ... > View the logging and trace event levels defined in an application package ¶\nContent:\nUse the SHOW VERSIONS IN APPLICATION PACKAGE command to view the logging level of the app versions\ndefined in an application package, as shown in the following example:\n```\nSHOW VERSIONS \n  IN APPLICATION PACKAGE HelloSnowflake ;\n```\nCopy\nSection Title: ... > View the logs and events in the event table ¶\nContent:\nTo view the logs and events stored in the event table, use the SELECT command as shown\nin the following example:\n```\nSELECT * FROM EVENT_DB . EVENT_SCHEMA . MY_EVENT_TABLE\n```\nCopy\nFor more information on querying the event table, see the following:\nViewing log messages\nViewing trace data\nSee Event table columns for information on the columns\nin the event table.\nSection Title: ... > Shared event information available to the provider ¶\nContent:\nThe following sections describe the information that the Native Apps Framework shares with providers.\nSection Title: ... > App event context shared with the provider ¶\nContent:\nTo help providers easily identify the source of the shared events, the following fields are populated into the `RESOURCE_ATTRIBUTES` column of the event table when they are shared with the provider:\n`snow.application.package.name`\n`snow.application.consumer.organization`\n`snow.application.consumer.name`\n`snow.listing.name`\n`snow.listing.global_name`\nSection Title: ... > Fields that are not shared with the provider ¶\nContent:\nTo protect consumer information, the following fields from the `RESOURCE_ATTRIBUTES` column are\nnot shared with provider:\n`snow.database.id`\n`snow.database.name`\n`snow.schema.id`\n`snow.executable.id`\n`snow.owner.name`\n`snow.owner.id`\n`snow.warehouse.name`\n`snow.warehouse.id`\n`snow.query.id`\n`snow.session.id`\n`snow.session.role.primary.name`\n`snow.session.role.primary.id`\n`snow.user.name`\n`snow.user.id`\n`db.user`\nInstead of directly sharing the `snow.database.name` and `snow.query.id` fields with the provider, Snowflake\nshares the hash values (SHA-1) of these two fields as the following fields:\n`snow.database.hash`\n`snow.query.hash`\nSnowflake provides the SHA-1 function used to mask these attributes.\nConsumers can calculate the hash values for the database name and query id, and use them as reference values when\ncontacting the provider.\nWas this page helpful?\nYes No\n[Visit Snowflake](https://www.snowflake.com)\nSection Title: ... > Fields that are not shared with the provider ¶\nContent:\n[Join the conversation](https://community.snowflake.com/s/)\n[Develop with Snowflake](https://developers.snowflake.com)\nShare your feedback\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n[Get your own certification](https://learn.snowflake.com)\nOn this page\nSet up an event table in the provider organization in every region\nSet the event table as the active event table\nUnset an account as the events account\nView the event accounts in an organization\nView the logging and trace event levels defined in an application package\nView the logs and events in the event table\nShared event information available to the provider\nRelated content\nLogging, tracing, and metrics\nSection Title: Set up and manage an event table in the provider account ¶ > Privacy Preference Center\nContent:\nYour Opt Out Preference Signal is Honored\nYour Privacy\nStrictly Necessary Cookies\nPerformance Cookies\nFunctional Cookies\nTargeting Cookies\nSection Title: Set up and manage an event table in the provider account ¶ > ... > Your Privacy\nContent:\nWhen you visit any website, it may store or retrieve information on your browser, mostly in the form of cookies. This information might be about you, your preferences or your device and is mostly used to make the site work as you expect it to. The information does not usually directly identify you, but it can give you a more personalized web experience. Because we respect your right to privacy, you can choose not to allow some types of cookies. Click on the different category headings to find out more and change our default settings. However, blocking some types of cookies may impact your experience of the site and the services we are able to offer.\n[More information](https://cookiepedia.co.uk/giving-consent-to-cookies)\nSection Title: Set up and manage an event table in the provider account ¶ > ... > Strictly Necessary Cookies\nContent:\nAlways Active\nThese cookies are necessary for the website to function and cannot be switched off. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.\nCookies Details‎\nSection Title: Set up and manage an event table in the provider account ¶ > ... > Performance Cookies\nContent:\nPerformance Cookies\nThese cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site.    All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance.\nCookies Details‎\nSection Title: Set up and manage an event table in the provider account ¶ > ... > Your Privacy > Functional Cookies\nContent:\nFunctional Cookies\nThese cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages.    If you do not allow these cookies then some or all of these services may not function properly.\nCookies Details‎\nSection Title: Set up and manage an event table in the provider account ¶ > ... > Your Privacy > Targeting Cookies\nContent:\nTargeting Cookies\nThese cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly identifiable personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising.\nCookies Details‎\nSection Title: Set up and manage an event table in the provider account ¶ > Privacy Preference Center > Cookie List\nContent:\nConsent Leg.Interest\ncheckbox label label\ncheckbox label label\ncheckbox label label\nClear\ncheckbox label label\nApply Cancel\nConfirm My Choices\nAllow All\n[](https://www.onetrust.com/products/cookie-consent/)"],"full_content":null},{"url":"https://docs.snowflake.com/en/developer-guide/builders/observability","title":"Observability in Snowflake apps | Snowflake Documentation","publish_date":null,"excerpts":["Section Title: Observability in Snowflake apps ¶\nContent:\nThrough observability built into Snowflake, you can ensure that your applications are running as efficiently as possible.\nUsing the practices and features described in this topic, you can make the most of observability features that show you where you\ncan improve your code.\nSection Title: Observability in Snowflake apps ¶ > What is observability? ¶\nContent:\nIn an observable system, you can understand what’s happening internally through external evidence generated by the system—evidence\nthat includes telemetry data, alerts, and notifications.\nThrough the evidence of internal functioning it provides, observability makes it easier for you to troubleshoot hard-to-understand behaviors\non a production system. This is especially true in a distributed system, where evidence collected from observation provides a view of\nbehavior across multiple components. Rather than disrupting a production environment to diagnose issues, you can analyze the collected\ndata from it.\nWith an observable system, you can start to answer questions such as the following:\nHow well is the system performing?\nWhere is there latency and what’s causing it?\nWhy is a particular component or process not working as it should?\nWhat improvements can be made?\nSection Title: Observability in Snowflake apps ¶ > Observability in Snowflake ¶\nContent:\nSnowflake supports a model that provides built-in observable data while also giving you ways to add more instrumentation where you need it.\nWhile Snowflake provides support for telemetry data such as logs, metrics, and traces (which are typical of observability), it also\nincludes other features you can use to keep track of system usage and performance.\nThe following lists features you can use to receive and analyze system performance and usage.\n|Collected telemetry data |As your application generates logs, metrics, and traces, Snowflake collects that telemetry data in an event table. Using\nSnowsight, you can explore the data, looking for patterns.\nYou can emit custom telemetry into the event table to provide contextual, domain-specific information to expedite debugging. |\n| --- | --- |\n|History Tables |Use the following views and their associated tables to monitor all usage in your account.\nSection Title: Observability in Snowflake apps ¶ > Observability in Snowflake ¶\nContent:\nQuery History\nCopy History\nTasks |\n|Alerts and notifications |Alerts allow for customizable triggering conditions, actions, and a schedule, in combination with notification integrations for proactive monitoring. |\n|Extensibility with third-party tools |The Snowflake event table adopts [OpenTelemetry](https://opentelemetry.io/docs/) standards, so your\nSnowflake telemetry can easily be consumed by other ecosystem tools. |\nSection Title: Observability in Snowflake apps ¶ > Telemetry data collected for analysis ¶\nContent:\nAs code in your application executes, you can have Snowflake collect data from the code that tells you about the application’s internal\nstate. Using this telemetry data—collected in a Snowflake event table (your account has one by default )—you can look for bottlenecks and other opportunities to optimize.\nTelemetry data must be emitted as your code executes. Snowflake emits some of this data on your code’s behalf without\nyou needing to instrument your code. You can use also APIs included with Snowflake to emit telemetry data from specific parts of your code.\nAs described below, you can analyze the collected data by querying the event table or using the visualizations that capture the data\nin Snowsight.\nSection Title: Observability in Snowflake apps ¶ > ... > Types of telemetry data ¶\nContent:\nTo ensure that the telemetry data you collect is broadly useful, Snowflake telemetry is built on the standard [OpenTelemetry](https://opentelemetry.io/docs/) (sometimes called OTel) framework, an incubating project of the Cloud Native Compute Foundation. Through this framework (and APIs and\ntools designed for it), you can reuse collected data with tools besides Snowflake .\nThrough OpenTelemetry, you can instrument application code to add observability where you want it.\nSnowflake event tables collect log, span, and metrics data in the OpenTelemetry data model. The following describes each type of telemetry\ndata collected in an event table.\n|Logs |Logs record individual operations performed by code. Each log message is generated at\na discrete point during the execution of the code.\nSection Title: Observability in Snowflake apps ¶ > ... > Types of telemetry data ¶\nContent:\n**Instrumenting code** You can log from your code using libraries standard for the language you’re using, as listed in Logging from handler code .\n**Viewing data** You can view log messages for analysis\neither by querying the event table or looking at the visualizations provided in Snowsight.\nThe following image from Snowsight shows a list of collected log messages for a two-hour period in a single database.\n|\n| --- | --- |\n|Metrics |Metrics are measurements calculated over a time period. These values include CPU and memory measurements.\n**Instrumenting code** Snowflake emits metrics data automatically as your code executes, so you don’t need to instrument your code.\n**Viewing data** You can view metrics data for analysis either by\nquerying the event table or looking at the visualizations provided in Snowsight.\nSection Title: Observability in Snowflake apps ¶ > ... > Types of telemetry data ¶\nContent:\nThe following image from Snowsight shows changes in collected metrics data for the execution of a user-defined function.\n|\n|Traces |Traces show distributed events as data flows through a system. In a trace, you can see where time is spent as processing flows\nfrom component to component.\nYou can emit trace events—both within the default span Snowflake creates or from a custom span you create—using libraries\nstandard for the language you’re using, as listed in Logging from handler code .\n**Instrumenting code** You can emit trace events from your code using libraries standard for the language you’re using, as listed in Event tracing from handler code .\n**Viewing data** You can view trace events for analysis either by\nquerying the event table or looking at the visualizations provided in Snowsight.\nThe following image from Snowsight shows the spans resulting as a UDF executes.\n|\nSection Title: Observability in Snowflake apps ¶ > Telemetry best practices ¶\nContent:\nUse the following best practices to get the most out of observablity in Snowflake.\nSet up your environment to capture telemetry data before you need it\nOptimize procedures with query telemetry\nCache redundant DataFrame operations\nManage the amount of telemetry data received for UDFs\nOptimize user-defined functions with query telemetry\nSection Title: ... > Set up your environment to capture telemetry data before you need it ¶\nContent:\nYou can’t analyze data that you haven’t collected, so it’s best to start collecting telemetry data so you’ll have it when you need it.\nAs your deployment grows, your need to understand how your code is performing grows.\nUse the following best practices:\nSection Title: ... > Set up your environment to capture telemetry data before you need it ¶\nContent:\nEnable telemetry data collection for your Snowflake environment.To collect the data you’ll need, ensure that you have an active event table. To ensure you’re collecting telemetry data you want, set telemetry levels to\nuseful thresholds.At first, you’ll want to set these levels to ensure that you’re collecting data. For example, set log levels to at least WARN for any\nproduction or business critical jobs. Over time, you might adjust these levels to meet changing needs.Organize your production stored procedures, UDFs, and other objects under a database or schema so you can simply enable warning logs\nfor that database or schema. This saves the trouble of managing settings for separate objects.\nSection Title: ... > Set up your environment to capture telemetry data before you need it ¶\nContent:\nTo generate data for troubleshooting, add log statements or trace events to your production jobs.When you use standard logging libraries such as Java’s SLF4J or Python’s logging libraries, Snowflake routes logs from those packages to\nyour event table automatically.For tracing, you can use telemetry libraries included with Snowflake. To include in trace data parts of the handler’s processing that you want to measure, add custom spans to your stored procedure handler code.Along with the built-in spans from Snowflake objects, Snowflake represents custom spans you create in the trace diagram. With custom\nspans, you can capture data about arbitrary parts of your code’s processing to see how long those parts take to execute. You can also\nattach arbitrary metadata to custom spans to add descriptions to the data for troubleshooting and optimizing.\nSection Title: Observability in Snowflake apps ¶ > ... > Optimize procedures with query telemetry ¶\nContent:\nIn the Query Telemetry trace diagram, you’ll find data about all the spans emitted from a query.\nThe horizontal axis displays duration. A span that appears longer horizontally took longer to complete than a shorter\nspan.\nThe vertical axis displays the call hierarchy. In that hierarchy, any span that is directly under another span is a “child” of\nthe “parent” span above it.\nYou can use this diagram to find opportunities for optimization in stored procedures. Using what you see in the diagram as a starting\nplace, you can take steps to optimize your code.\nFor example, you might organize sequential operations so they execute in parallel using libraries like joblib. [Joblib](https://joblib.readthedocs.io/en/stable/) is a set of\ntools for adding pipelining to Python code. With it, you can more easily write parallel code.\n ... \nSection Title: Observability in Snowflake apps ¶ > ... > Cache redundant DataFrame operations ¶\nContent:\n```\ncached_df = session . table ( ... ) . select () . filter () . join () . cache_result () \n count = cached_df . count () \n\n if count > 0 : \n  cached_df . write . save_as_table () # reuses the cached DF \n else : \n  cached_df\n```\nCopy\nSection Title: Observability in Snowflake apps ¶ > ... > Manage the amount of telemetry data received for UDFs ¶\nContent:\nWhen adding code to collect telemetry data with UDFs, remember that the UDF execution model can mean many more rows in the event table\nthan for a procedure.\nWhen a UDF is called on every input row, your handler code emits logging statements or span events for every row of the input dataset.\nFor example, a dataset of 10 million rows passed to a UDF would emit 10 million log entries.\nConsider using the following patterns when adding logs and span events to UDFs:\nSection Title: Observability in Snowflake apps ¶ > ... > Manage the amount of telemetry data received for UDFs ¶\nContent:\nInitially, use logging levels designed to reduce the number of entries recorded.Use DEBUG- or INFO-level logging statements and set the logging level to WARN in production. If an issue is found, you can lower the\nlogging level to DEBUG or INFO for the duration of the debugging session.\nUse try/catch blocks to isolate the code from which you want to emit logging data.Using try/catch can be useful to catch any unexpected UDF input, log it as a WARN-level log for awareness, and return a default value.\nUse condition statements to log only for scenarios that are meaningful to you.With if/else statements or other constraints, you can control the volume of logging output.\nSection Title: Observability in Snowflake apps ¶ > ... > Optimize user-defined functions with query telemetry ¶\nContent:\nWhen a UDF is called, Snowflake executes it in parallel by creating an instance of the handler code for each input row. You’ll see each of\nthese instances represented as its own span in a trace diagram.\nYou can use these spans to troubleshoot slow queries and find opportunities to improve performance. For example, you might see scenarios\nsuch as the following:\nOne or more instances of your UDF code might receive a row with data that is significantly larger or otherwise unlike the rest of your\ndata. When this happens, that instance might take much longer to complete, and therefore its span is much longer.\nDepending on your query’s input partitioning and preceding clauses, a minority of the instances might receive an outsized amount of\ninput data.\nSection Title: Observability in Snowflake apps ¶ > ... > Optimize user-defined functions with query telemetry ¶\nContent:\nThe following image shows a span for each row passed to a UDF, where one span’s longer duration suggests that the row might have larger\ndata than the others.\nSection Title: Observability in Snowflake apps ¶ > Alerts and notifications for time-sensitive response ¶\nContent:\nYou can use Snowflake alerts and notifications to have your system reveal what’s going on inside, then take action or send information\nabout system state. Unlike telemetry data, which you collect and analyze later, alerts and notifications are useful when you want an\nimmediate response to what’s happening in the system.\nSection Title: Observability in Snowflake apps ¶ > Alerts and notifications for time-sensitive response ¶\nContent:\nWith an alert , you can specify a condition, action, and schedule, then specify that the action should take\nplace when the condition and schedule details are met.For example, you might use an alert to monitor complex conditions that you specify in SQL. The most common action after an alert\ncondition is met is to send a notification. Snowflake supports sending notifications to email, cloud service provider queues, Slack,\nPagerDuty, and Microsoft Teams.\nWith a notification , you can use included stored procedures to send messages to\ndestinations such as email addresses , webhooks (for client tool integrations such as a chat tool), or to a queue hosted by a cloud service .\nSection Title: Observability in Snowflake apps ¶ > ... > Alerts and notifications best practices ¶\nContent:\nUse the following practices to improve observability by refining and increasing the amount of information you receive from the system.\nSection Title: Observability in Snowflake apps ¶ > ... > Alerts and notifications best practices ¶\nContent:\nAvoid duplicating event evaluation.You can avoid duplicating evaluation on events by accounting for the latency between the alert schedule and execution. To do this,\nspecify alert timestamps using SCHEDULED_TIME and LAST_SUCCESSFUL_SCHEDULED_TIME instead of using CURRENT_TIMESTAMP .For more information, see Specifying timestamps based on alert schedules . Enrich an alert action or notification with query results.You can check the results from the SQL statement specified by an alert condition. To obtain the query results, do the following:\nRetrieve the query ID for the alert condition’s SQL statement by calling GET_CONDITION_QUERY_UUID . Pass the query ID to RESULT_SCAN to obtain the query results. Log a result or take automated action in addition to sending a notification.You can specify that an alert action runs a task or logs a new row to a table whenever an alert\ncondition is met.\nSection Title: Observability in Snowflake apps ¶ > ... > Alerts and notifications best practices ¶\nContent:\nFor example, you might do this if you’ll take an action in Snowflake each time the alert condition is met.If you intend to perform a complex action after a condition is met, ensure that your warehouse is an appropriate size.\nSection Title: Observability in Snowflake apps ¶ > Tools for analysis and visualization ¶\nContent:\nYou can use the telemetry data collected in your event table with other tools that support the OpenTelemetry data model.\nThrough Snowflake support of OpenTelemetry, you can use APIs, SDKs, and other tools to instrument, generate, collect, and export telemetry\ndata. Using these tools, you can more thoroughly analyze software performance and behavior. Because a Snowflake event table uses this\nwidely-adopted standard, you might also be able to integrate your organization’s observability tools with event tables with little overhead.\nConsider integrating your external tools in one of the following ways:\nIf your observability tools can read from external sources, point them to the event table.\nIf your tools use a push model—in which telemetry data must be sent to the tool—consider using a stored procedure with external access to regularly read telemetry data from\nthe event table and emit it to your tool.\nSection Title: Observability in Snowflake apps ¶ > Tools for analysis and visualization ¶\nContent:\nThe following lists tools you might integrate with Snowflake event tables:\n[Snowflake integration for Datadog](https://docs.datadoghq.com/integrations/snowflake_web/)\nSnowflake integration for Grafana dashboardFor an introduction to using Grafana with Snowflake, see [How to monitor Snowflake with Grafana Cloud](https://grafana.com/blog/2023/05/24/how-to-monitor-snowflake-with-grafana-cloud/) .\n[Snowflake data source for Grafana](https://grafana.com/docs/plugins/grafana-snowflake-datasource/latest/)\n[Snowflake integration for Grafana Cloud](https://grafana.com/docs/grafana-cloud/monitor-infrastructure/integrations/integration-reference/integration-snowflake/)\n[Observe for Snowflake](https://app.snowflake.com/marketplace/listing/GZTYZY3AR0U/observe-inc-observe-for-snowflake) , Observe’s native app for observability\nWas this page helpful?\nYes No\n[Visit Snowflake](https://www.snowflake.com)\nSection Title: Observability in Snowflake apps ¶ > Tools for analysis and visualization ¶\nContent:\n[Join the conversation](https://community.snowflake.com/s/)\n[Develop with Snowflake](https://developers.snowflake.com)\nShare your feedback\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n[Get your own certification](https://learn.snowflake.com)\nSection Title: Observability in Snowflake apps ¶ > Privacy Preference Center\nContent:\nYour Opt Out Preference Signal is Honored\nYour Privacy\nStrictly Necessary Cookies\nPerformance Cookies\nFunctional Cookies\nTargeting Cookies\n ... \nSection Title: Observability in Snowflake apps ¶ > Privacy Preference Center > Your Privacy > Performance Cookies\nContent:\nPerformance Cookies\nThese cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site.    All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance.\nCookies Details‎\nSection Title: Observability in Snowflake apps ¶ > Privacy Preference Center > Your Privacy > Functional Cookies\nContent:\nFunctional Cookies\nThese cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages.    If you do not allow these cookies then some or all of these services may not function properly.\nCookies Details‎\n ... \nSection Title: Observability in Snowflake apps ¶ > Privacy Preference Center > Cookie List\nContent:\nConsent Leg.Interest\ncheckbox label label\ncheckbox label label\ncheckbox label label\nClear\ncheckbox label label\nApply Cancel\nConfirm My Choices\nAllow All\n[](https://www.onetrust.com/products/cookie-consent/)"],"full_content":null},{"url":"https://docs.snowflake.com/en/developer-guide/native-apps/monitoring","title":"Use monitoring for an app | Snowflake Documentation","publish_date":null,"excerpts":["Developer Snowflake Native App Framework Monitoring\nSection Title: Use monitoring for an app ¶\nContent:\nFeature — Generally Available\nThe Snowflake Native App Framework is generally available on supported cloud platforms. For additional information, see Support for private connectivity, VPS, and government regions .\nThis topic describes how providers can monitor consumer app health for a Snowflake Native App.\nSection Title: Use monitoring for an app ¶ > Monitor consumer application health ¶\nContent:\nYour application can report its health status to Snowflake, which allows you to\nmonitor the health of consumer instances of your app.\nTo report health status, your app uses the system-defined `SYSTEM$REPORT_HEALTH_STATUS(VARCHAR)` function, passing in the health status\nas an enum value:\n`OK` : The consumer instance is healthy.\n`FAILED` : The consumer instance is in an error state.\n`PAUSED` : The consumer manually paused the app.\nYou can use the `LAST_HEALTH_STATUS` and `LAST_HEALTH_STATUS_UPDATED_ON` fields\nof the APPLICATION_STATE view to monitor the health of consumer instances of your app. The `LAST_HEALTH_STATUS` field has the most recent value passed in by the app running in the consumer account.\nThe following code sample demonstrates using the APPLICATION_STATE view\nto retrieve the health status of all consumer instances of your app:\nSection Title: Use monitoring for an app ¶ > Monitor consumer application health ¶\nContent:\n```\nSELECT \n    CONSUMER_ORGANIZATION_NAME , \n    CONSUMER_ACCOUNT_NAME , \n    LAST_HEALTH_STATUS , \n    LAST_HEALTH_STATUS_UPDATE_TIME \n FROM \n    SNOWFLAKE . ACCOUNT_USAGE . APPLICATION_STATE \n WHERE \n    PROVIDER_ORG_NAME = '<your_provider_org_name>' \n    AND APPLICATION_NAME = '<your_app_name>' \n ORDER BY \n    LAST_HEALTH_STATUS_UPDATE_TIME DESC ;\n```\nCopy\nThe preceding query may return results similar to the following:\n```\nCONSUMER_ORG_NAME    CONSUMER_ACCOUNT_NAME    LAST_HEALTH_STATUS    LAST_HEALTH_STATUS_UPDATE_TIME \n ------------------   ---------------------    ------------------    ------------------------------- \n consumer_org_1       consumer_account_1       OK                    2024-01-15 10:30:00.000 \n consumer_org_2       consumer_account_2       FAILED                2024-01-15 09:45:00.000 \n consumer_org_3       consumer_account_3       PAUSED                2024-01-14 16:20:00.000\n```\nSection Title: Use monitoring for an app ¶ > Monitor consumer application health ¶\nContent:\nWas this page helpful?\nYes No\n[Visit Snowflake](https://www.snowflake.com)\n[Join the conversation](https://community.snowflake.com/s/)\n[Develop with Snowflake](https://developers.snowflake.com)\nShare your feedback\n[Read the latest on our blog](https://www.snowflake.com/blog/)\n[Get your own certification](https://learn.snowflake.com)\nOn this page\nMonitor consumer application health\nRelated content\nLogging, tracing, and metrics\nSection Title: Use monitoring for an app ¶ > Privacy Preference Center\nContent:\nYour Opt Out Preference Signal is Honored\nYour Privacy\nStrictly Necessary Cookies\nPerformance Cookies\nFunctional Cookies\nTargeting Cookies\nSection Title: Use monitoring for an app ¶ > Privacy Preference Center > Your Privacy\nContent:\nWhen you visit any website, it may store or retrieve information on your browser, mostly in the form of cookies. This information might be about you, your preferences or your device and is mostly used to make the site work as you expect it to. The information does not usually directly identify you, but it can give you a more personalized web experience. Because we respect your right to privacy, you can choose not to allow some types of cookies. Click on the different category headings to find out more and change our default settings. However, blocking some types of cookies may impact your experience of the site and the services we are able to offer.\n[More information](https://cookiepedia.co.uk/giving-consent-to-cookies)\nSection Title: Use monitoring for an app ¶ > Privacy Preference Center > Your Privacy > Strictly Necessary Cookies\nContent:\nAlways Active\nThese cookies are necessary for the website to function and cannot be switched off. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.\nCookies Details‎\nSection Title: Use monitoring for an app ¶ > Privacy Preference Center > Your Privacy > Performance Cookies\nContent:\nPerformance Cookies\nThese cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site.    All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance.\nCookies Details‎\nSection Title: Use monitoring for an app ¶ > Privacy Preference Center > Your Privacy > Functional Cookies\nContent:\nFunctional Cookies\nThese cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages.    If you do not allow these cookies then some or all of these services may not function properly.\nCookies Details‎\nSection Title: Use monitoring for an app ¶ > Privacy Preference Center > Your Privacy > Targeting Cookies\nContent:\nTargeting Cookies\nThese cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly identifiable personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising.\nCookies Details‎\nSection Title: Use monitoring for an app ¶ > Privacy Preference Center > Cookie List\nContent:\nConsent Leg.Interest\ncheckbox label label\ncheckbox label label\ncheckbox label label\nClear\ncheckbox label label\nApply Cancel\nConfirm My Choices\nAllow All\n[](https://www.onetrust.com/products/cookie-consent/)"],"full_content":null}],"errors":[],"warnings":null,"usage":[{"name":"sku_extract_excerpts","count":3}]}
